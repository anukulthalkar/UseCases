import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import static org.apache.spark.sql.functions.*;

/*
Get the revenue generated by each customer for the month of 2014 January
 * Tables - orders, order_items and customers
 * Data should be sorted in descending order by revenue and then ascending order by customer_id
 * Output should contain customer_id, customer_first_name, customer_last_name, customer_revenue.
 * If there are no orders placed by customer, then the corresponding revenue for a give customer should be 0.
 * Consider only COMPLETE and CLOSED orders
 */

public class UseCase3 {
    static final Logger logger = Logger.getLogger(UseCase3.class);

    public static Dataset<Row> getOrders() {
        String ordersPath = "C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\orders\\part-00000";
        Dataset<Row> orders = util.getSparkSession().read().format("csv").option("header", true).option("inferSchema", true).load(ordersPath);
        return orders;
    }

    public static Dataset<Row> getCustomers() {
        String customersPath = "C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\customers\\part-00000";
        Dataset<Row> customers = util.getSparkSession().read().format("csv").option("header", true).option("inferSchema", true).load(customersPath);
        return customers;
    }

    public static Dataset<Row> getOrder_items() {
        String order_itemsPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\order_items\\part-00000";
        Dataset<Row>order_items=util.getSparkSession().read().format("csv").option("header",true).option("inferschema",true).load(order_itemsPath);
        return order_items;
    }

    public static Dataset<Row> getUseCase3Result() {
        Dataset<Row> orders = getOrders();
        Dataset<Row> customers = getCustomers();
        Dataset<Row> order_items = getOrder_items();
        Dataset<Row>join1=orders.join(customers, orders.col("order_customer_id").equalTo(customers.col("customer_id")),"right_outer");
        Dataset<Row>result=join1.join(order_items, join1.col("order_id").equalTo(order_items.col("order_item_order_id"))).
                where(orders.col("order_date").like("2014-01%").and(join1.col("order_status").isin("COMPLETE","CLOSED"))).
                groupBy(join1.col("customer_id"),
                        join1.col("customer_fname").alias("customer_first_name"),
                        join1.col("customer_lname").alias("customer_last_name")).
                agg(coalesce(round(sum(order_items.col("order_item_subtotal")),2),lit(0)).alias("customer_revenue")).
                orderBy(col("customer_revenue").desc(),join1.col("customer_id"));
        return result;
    }

    public static long getOrdersCount(){
       long ordersCount = getOrders().count();
        return ordersCount;

    }

    public static long getCustomersCount() {
        long customersCount = getCustomers().count();
        return customersCount;
    }

    public static long getOrder_itemsCount() {
        long order_itemsCount = getOrder_items().count();
        return order_itemsCount;
    }

    public static long getResultCount() {
       long resultCount = getUseCase3Result().count();
        return resultCount;
    }

    public static void main(String[] args){

        logger.info("------------------------------------------running UseCase 3------------------------------------------------------");

        SparkSession spark = SparkSession.builder().master("local").getOrCreate();

        logger.info("------------------------------------------spark session created--------------------------------------------------");

        getOrders().show();
        getOrders().printSchema();
        getCustomers().show();
        getCustomers().printSchema();
        getOrder_items().show();
        getOrder_items().printSchema();

        getUseCase3Result().show();

        logger.info("------------------------------------------Write Result--------------------------------------------------");


        getUseCase3Result().coalesce(1).write().option("header",true).mode("overwrite").csv("C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\outputs\\UseCase3");

        logger.info("--------------------------------------------Completed---------------------------------------------------");





    }
}

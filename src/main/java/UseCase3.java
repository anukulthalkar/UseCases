import org.apache.log4j.Logger;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import static org.apache.spark.sql.functions.*;

/*
Get the revenue generated by each customer for the month of 2014 January
 * Tables - orders, order_items and customers
 * Data should be sorted in descending order by revenue and then ascending order by customer_id
 * Output should contain customer_id, customer_first_name, customer_last_name, customer_revenue.
 * If there are no orders placed by customer, then the corresponding revenue for a give customer should be 0.
 * Consider only COMPLETE and CLOSED orders
 */

public class UseCase3 {
    static final Logger logger = Logger.getLogger(UseCase3.class);

    public static long getOrdersCount(){
        SparkSession spark = SparkSession.builder().master("local").getOrCreate();
        String ordersPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\orders\\part-00000";
        Dataset<Row> orders = spark.read().format("csv").option("header",true).option("inferSchema",true).load(ordersPath);
        long ordersCount = orders.count();
        return ordersCount;

    }

    public static long getCustomersCount() {
        SparkSession spark = SparkSession.builder().master("local").getOrCreate();
        String customersPath = "C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\customers\\part-00000";
        Dataset<Row> customers = spark.read().format("csv").option("header", true).option("inferSchema", true).load(customersPath);
        long customersCount = customers.count();
        return customersCount;
    }

    public static long getOrder_itemsCount() {
        SparkSession spark = SparkSession.builder().master("local").getOrCreate();
        String order_itemsPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\order_items\\part-00000";
        Dataset<Row>order_items=spark.read().format("csv").option("header",true).option("inferschema",true).load(order_itemsPath);
        long order_itemsCount = order_items.count();
        return order_itemsCount;
    }

    public static long getResultCount() {
        SparkSession spark = SparkSession.builder().master("local").getOrCreate();
        String ordersPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\orders\\part-00000";
        String customersPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\customers\\part-00000";
        String order_itemsPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\order_items\\part-00000";
        Dataset<Row>orders=spark.read().format("csv").option("header",true).option("inferschema",true).load(ordersPath);
        Dataset<Row>customers=spark.read().format("csv").option("header",true).option("inferschema",true).load(customersPath);
        Dataset<Row>order_items=spark.read().format("csv").option("header",true).option("inferschema",true).load(order_itemsPath);
        Dataset<Row>join1=orders.join(customers, orders.col("order_customer_id").equalTo(customers.col("customer_id")),"right_outer");
        Dataset<Row>result=join1.join(order_items, join1.col("order_id").equalTo(order_items.col("order_item_order_id"))).
                where(orders.col("order_date").like("2014-01%").and(join1.col("order_status").isin("COMPLETE","CLOSED"))).
                groupBy(join1.col("customer_id"),
                        join1.col("customer_fname"),
                        join1.col("customer_lname")).
                agg(coalesce(round(sum(order_items.col("order_item_subtotal")),2),lit(0)).alias("customer_revenue")).
                orderBy(col("customer_revenue").desc(),join1.col("customer_id"));
        long Result = result.count();
        return Result;
    }

    public static void main(String[] args){
        logger.info("------------------------------------------running UseCase 3------------------------------------------------------");

        SparkSession spark = SparkSession.builder().master("local").getOrCreate();

        logger.info("------------------------------------------spark session created--------------------------------------------------");

        String ordersPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\orders\\part-00000";
        String customersPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\customers\\part-00000";
        String order_itemsPath="C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\retail_db\\order_items\\part-00000";
        Dataset<Row>orders=spark.read().format("csv").option("header",true).option("inferschema",true).load(ordersPath);
        Dataset<Row>customers=spark.read().format("csv").option("header",true).option("inferschema",true).load(customersPath);
        Dataset<Row>order_items=spark.read().format("csv").option("header",true).option("inferschema",true).load(order_itemsPath);
        orders.show();
        customers.show();
        order_items.show();
        Dataset<Row>join1=orders.join(customers, orders.col("order_customer_id").equalTo(customers.col("customer_id")),"right_outer");
        join1.show();
        Dataset<Row>result=join1.join(order_items, join1.col("order_id").equalTo(order_items.col("order_item_order_id"))).
                where(orders.col("order_date").like("2014-01%").and(join1.col("order_status").isin("COMPLETE","CLOSED"))).
                groupBy(join1.col("customer_id"),
                        join1.col("customer_fname"),
                        join1.col("customer_lname")).
                agg(coalesce(round(sum(order_items.col("order_item_subtotal")),2),lit(0)).alias("customer_revenue")).
                orderBy(col("customer_revenue").desc(),join1.col("customer_id"));

        result.show();

        logger.info("------------------------------------------Write Result--------------------------------------------------");


        result.coalesce(1).write().option("header",true).mode("overwrite").csv("C:\\Users\\Anukul Thalkar\\IdeaProjects\\UseCases\\src\\main\\resources\\outputs\\UseCase3");

        logger.info("--------------------------------------------Completed---------------------------------------------------");





    }
}

2022-02-09 13:09:09 INFO  SparkContext:54 - Running Spark version 2.4.8
2022-02-09 13:09:09 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of successful kerberos logins and latency (milliseconds)], valueName=Time)
2022-02-09 13:09:09 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[Rate of failed kerberos logins and latency (milliseconds)], valueName=Time)
2022-02-09 13:09:09 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, value=[GetGroups], valueName=Time)
2022-02-09 13:09:09 DEBUG MetricsSystemImpl:231 - UgiMetrics, User and group related metrics
2022-02-09 13:09:09 DEBUG KerberosName:88 - Kerberos krb5 configuration not found, setting default realm to empty
2022-02-09 13:09:09 DEBUG Groups:291 -  Creating new Groups object
2022-02-09 13:09:09 DEBUG NativeCodeLoader:46 - Trying to load the custom-built native-hadoop library...
2022-02-09 13:09:09 DEBUG NativeCodeLoader:50 - Loaded the native-hadoop library
2022-02-09 13:09:09 DEBUG JniBasedUnixGroupsMapping:50 - Using JniBasedUnixGroupsMapping for Group resolution
2022-02-09 13:09:09 DEBUG JniBasedUnixGroupsMappingWithFallback:45 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMapping
2022-02-09 13:09:09 ERROR Shell:396 - Failed to locate the winutils binary in the hadoop binary path
java.io.IOException: Could not locate executable C:\Users\Anukul Thalkar\hadoop\bin\bin\winutils.exe in the Hadoop binaries.
	at org.apache.hadoop.util.Shell.getQualifiedBinPath(Shell.java:378)
	at org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:393)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:386)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:116)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:73)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:293)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:283)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:260)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:789)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:774)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:647)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2422)
	at org.apache.spark.util.Utils$$anonfun$getCurrentUserName$1.apply(Utils.scala:2422)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2422)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:293)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2526)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:930)
	at org.apache.spark.sql.SparkSession$Builder$$anonfun$7.apply(SparkSession.scala:921)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at UseCase5Test.validateResult(UseCase5Test.java:12)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:59)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:56)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.BlockJUnit4ClassRunner$1.evaluate(BlockJUnit4ClassRunner.java:100)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:366)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:103)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:63)
	at org.junit.runners.ParentRunner$4.run(ParentRunner.java:331)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:79)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:329)
	at org.junit.runners.ParentRunner.access$100(ParentRunner.java:66)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:293)
	at org.junit.runners.ParentRunner$3.evaluate(ParentRunner.java:306)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:413)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:137)
	at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:69)
	at com.intellij.rt.junit.IdeaTestRunner$Repeater.startRunnerWithArgs(IdeaTestRunner.java:33)
	at com.intellij.rt.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:220)
	at com.intellij.rt.junit.JUnitStarter.main(JUnitStarter.java:53)
2022-02-09 13:09:09 DEBUG Groups:103 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
2022-02-09 13:09:09 DEBUG UserGroupInformation:221 - hadoop login
2022-02-09 13:09:09 DEBUG UserGroupInformation:156 - hadoop login commit
2022-02-09 13:09:09 DEBUG UserGroupInformation:186 - using local user:NTUserPrincipal: Anukul Thalkar
2022-02-09 13:09:09 DEBUG UserGroupInformation:192 - Using user: "NTUserPrincipal: Anukul Thalkar" with name Anukul Thalkar
2022-02-09 13:09:09 DEBUG UserGroupInformation:202 - User entry: "Anukul Thalkar"
2022-02-09 13:09:09 DEBUG UserGroupInformation:825 - UGI loginUser:Anukul Thalkar (auth:SIMPLE)
2022-02-09 13:09:09 INFO  SparkContext:54 - Submitted application: 0fec4636-54d4-4e7c-aa97-c7efda21f562
2022-02-09 13:09:09 INFO  SecurityManager:54 - Changing view acls to: Anukul Thalkar
2022-02-09 13:09:09 INFO  SecurityManager:54 - Changing modify acls to: Anukul Thalkar
2022-02-09 13:09:09 INFO  SecurityManager:54 - Changing view acls groups to: 
2022-02-09 13:09:09 INFO  SecurityManager:54 - Changing modify acls groups to: 
2022-02-09 13:09:09 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Anukul Thalkar); groups with view permissions: Set(); users  with modify permissions: Set(Anukul Thalkar); groups with modify permissions: Set()
2022-02-09 13:09:09 DEBUG InternalLoggerFactory:45 - Using SLF4J as the default logging framework
2022-02-09 13:09:09 DEBUG InternalThreadLocalMap:56 - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
2022-02-09 13:09:09 DEBUG InternalThreadLocalMap:59 - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
2022-02-09 13:09:09 DEBUG MultithreadEventLoopGroup:44 - -Dio.netty.eventLoopThreads: 16
2022-02-09 13:09:10 DEBUG NioEventLoop:106 - -Dio.netty.noKeySetOptimization: false
2022-02-09 13:09:10 DEBUG NioEventLoop:107 - -Dio.netty.selectorAutoRebuildThreshold: 512
2022-02-09 13:09:10 DEBUG PlatformDependent:1003 - Platform: Windows
2022-02-09 13:09:10 DEBUG PlatformDependent0:396 - -Dio.netty.noUnsafe: false
2022-02-09 13:09:10 DEBUG PlatformDependent0:852 - Java version: 8
2022-02-09 13:09:10 DEBUG PlatformDependent0:121 - sun.misc.Unsafe.theUnsafe: available
2022-02-09 13:09:10 DEBUG PlatformDependent0:145 - sun.misc.Unsafe.copyMemory: available
2022-02-09 13:09:10 DEBUG PlatformDependent0:183 - java.nio.Buffer.address: available
2022-02-09 13:09:10 DEBUG PlatformDependent0:244 - direct buffer constructor: available
2022-02-09 13:09:10 DEBUG PlatformDependent0:314 - java.nio.Bits.unaligned: available, true
2022-02-09 13:09:10 DEBUG PlatformDependent0:379 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
2022-02-09 13:09:10 DEBUG PlatformDependent0:386 - java.nio.DirectByteBuffer.<init>(long, int): available
2022-02-09 13:09:10 DEBUG PlatformDependent:1046 - sun.misc.Unsafe: available
2022-02-09 13:09:10 DEBUG PlatformDependent:1165 - -Dio.netty.tmpdir: C:\Users\ANUKUL~1\AppData\Local\Temp (java.io.tmpdir)
2022-02-09 13:09:10 DEBUG PlatformDependent:1244 - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2022-02-09 13:09:10 DEBUG PlatformDependent:177 - -Dio.netty.maxDirectMemory: 3758096384 bytes
2022-02-09 13:09:10 DEBUG PlatformDependent:184 - -Dio.netty.uninitializedArrayAllocationThreshold: -1
2022-02-09 13:09:10 DEBUG CleanerJava6:92 - java.nio.ByteBuffer.cleaner(): available
2022-02-09 13:09:10 DEBUG PlatformDependent:204 - -Dio.netty.noPreferDirect: false
2022-02-09 13:09:10 DEBUG PlatformDependent:907 - org.jctools-core.MpscChunkedArrayQueue: available
2022-02-09 13:09:10 DEBUG ResourceLeakDetector:130 - -Dio.netty.leakDetection.level: simple
2022-02-09 13:09:10 DEBUG ResourceLeakDetector:131 - -Dio.netty.leakDetection.targetRecords: 4
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:156 - -Dio.netty.allocator.numHeapArenas: 16
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:157 - -Dio.netty.allocator.numDirectArenas: 16
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:159 - -Dio.netty.allocator.pageSize: 8192
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:164 - -Dio.netty.allocator.maxOrder: 11
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:168 - -Dio.netty.allocator.chunkSize: 16777216
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:169 - -Dio.netty.allocator.tinyCacheSize: 512
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:170 - -Dio.netty.allocator.smallCacheSize: 256
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:171 - -Dio.netty.allocator.normalCacheSize: 64
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:172 - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:173 - -Dio.netty.allocator.cacheTrimInterval: 8192
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:174 - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:175 - -Dio.netty.allocator.useCacheForAllThreads: true
2022-02-09 13:09:10 DEBUG PooledByteBufAllocator:176 - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
2022-02-09 13:09:10 DEBUG DefaultChannelId:79 - -Dio.netty.processId: 3296 (auto-detected)
2022-02-09 13:09:10 DEBUG NetUtil:139 - -Djava.net.preferIPv4Stack: false
2022-02-09 13:09:10 DEBUG NetUtil:140 - -Djava.net.preferIPv6Addresses: false
2022-02-09 13:09:10 DEBUG NetUtil:224 - Loopback interface: lo (Software Loopback Interface 1, 127.0.0.1)
2022-02-09 13:09:10 DEBUG NetUtil:289 - Failed to get SOMAXCONN from sysctl and file \proc\sys\net\core\somaxconn. Default: 200
2022-02-09 13:09:10 DEBUG DefaultChannelId:101 - -Dio.netty.machineId: 7c:70:db:ff:fe:41:5e:f6 (auto-detected)
2022-02-09 13:09:10 DEBUG ByteBufUtil:86 - -Dio.netty.allocator.type: pooled
2022-02-09 13:09:10 DEBUG ByteBufUtil:95 - -Dio.netty.threadLocalDirectBufferSize: 0
2022-02-09 13:09:10 DEBUG ByteBufUtil:98 - -Dio.netty.maxThreadLocalCharBufferSize: 16384
2022-02-09 13:09:10 DEBUG TransportServer:141 - Shuffle server started on port: 52082
2022-02-09 13:09:10 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 52082.
2022-02-09 13:09:10 DEBUG SparkEnv:58 - Using serializer: class org.apache.spark.serializer.JavaSerializer
2022-02-09 13:09:10 INFO  SparkEnv:54 - Registering MapOutputTracker
2022-02-09 13:09:10 DEBUG MapOutputTrackerMasterEndpoint:58 - init
2022-02-09 13:09:10 INFO  SparkEnv:54 - Registering BlockManagerMaster
2022-02-09 13:09:10 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2022-02-09 13:09:10 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2022-02-09 13:09:10 INFO  DiskBlockManager:54 - Created local directory at C:\Users\Anukul Thalkar\AppData\Local\Temp\blockmgr-ee2d2e72-1692-408d-b067-b081bccef968
2022-02-09 13:09:10 DEBUG DiskBlockManager:58 - Adding shutdown hook
2022-02-09 13:09:10 DEBUG ShutdownHookManager:58 - Adding shutdown hook
2022-02-09 13:09:10 INFO  MemoryStore:54 - MemoryStore started with capacity 1970.4 MB
2022-02-09 13:09:10 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2022-02-09 13:09:10 DEBUG OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:58 - init
2022-02-09 13:09:10 DEBUG SecurityManager:58 - Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2022-02-09 13:09:10 DEBUG log:159 - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.spark_project.jetty.util.log) via org.spark_project.jetty.util.log.Slf4jLog
2022-02-09 13:09:10 INFO  log:169 - Logging initialized @3156ms to org.spark_project.jetty.util.log.Slf4jLog
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5f2606b
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2b62442c{/,null,STOPPED} added {ServletHandler@4fcee388{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@4fcee388{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0==org.apache.spark.ui.JettyUtils$$anon$3@9ed39b61{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@4fcee388{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4b6579e8
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6fff253c{/,null,STOPPED} added {ServletHandler@6c6357f9{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@6c6357f9{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-591e58fa==org.apache.spark.ui.JettyUtils$$anon$3@23155c82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@6c6357f9{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-591e58fa,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@64bc21ac
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@493dfb8e{/,null,STOPPED} added {ServletHandler@5d25e6bb{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5d25e6bb{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e==org.apache.spark.ui.JettyUtils$$anon$3@ff588d09{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5d25e6bb{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@9d157ff
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2f162cc0{/,null,STOPPED} added {ServletHandler@5df417a7{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5df417a7{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-7c041b41==org.apache.spark.ui.JettyUtils$$anon$3@9c34dc8a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5df417a7{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-7c041b41,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@314b8f2d
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@664a9613{/,null,STOPPED} added {ServletHandler@5118388b{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5118388b{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-15a902e7==org.apache.spark.ui.JettyUtils$$anon$3@ff71f2fc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5118388b{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-15a902e7,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7876d598
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@4a3e3e8b{/,null,STOPPED} added {ServletHandler@5af28b27{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5af28b27{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-71104a4==org.apache.spark.ui.JettyUtils$$anon$3@8ebbb6a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5af28b27{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-71104a4,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@72f46e16
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3c9168dc{/,null,STOPPED} added {ServletHandler@332a7fce{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@332a7fce{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-549621f3==org.apache.spark.ui.JettyUtils$$anon$3@25a530f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@332a7fce{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-549621f3,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@54361a9
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@32232e55{/,null,STOPPED} added {ServletHandler@5217f3d0{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5217f3d0{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8==org.apache.spark.ui.JettyUtils$$anon$3@422d3277{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5217f3d0{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2416a51
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6fa590ba{/,null,STOPPED} added {ServletHandler@6e9319f{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@6e9319f{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-72e34f77==org.apache.spark.ui.JettyUtils$$anon$3@d687b307{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@6e9319f{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-72e34f77,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7bf9b098
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@389adf1d{/,null,STOPPED} added {ServletHandler@77307458{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@77307458{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e==org.apache.spark.ui.JettyUtils$$anon$3@226e2d85{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@77307458{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@209775a9
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@18e7143f{/,null,STOPPED} added {ServletHandler@f9b7332{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@f9b7332{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-74cec793==org.apache.spark.ui.JettyUtils$$anon$3@3fbfbcb9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@f9b7332{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-74cec793,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@6fefce9e
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@4f8969b0{/,null,STOPPED} added {ServletHandler@1bdf8190{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@1bdf8190{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-192f2f27==org.apache.spark.ui.JettyUtils$$anon$3@8552e241{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@1bdf8190{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-192f2f27,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@c65a5ef
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6b5176f2{/,null,STOPPED} added {ServletHandler@b672aa8{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@b672aa8{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff==org.apache.spark.ui.JettyUtils$$anon$3@89a8bd2e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@b672aa8{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@ec0c838
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@6e46d9f4{/,null,STOPPED} added {ServletHandler@5cc69cfe{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5cc69cfe{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b==org.apache.spark.ui.JettyUtils$$anon$3@40e7975b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5cc69cfe{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@460f76a6
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@55f3c410{/,null,STOPPED} added {ServletHandler@11acdc30{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@11acdc30{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-770d4269==org.apache.spark.ui.JettyUtils$$anon$3@8747bec1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@11acdc30{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-770d4269,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4a8ab068
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1922e6d{/,null,STOPPED} added {ServletHandler@76a82f33{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@76a82f33{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-6bab2585==org.apache.spark.ui.JettyUtils$$anon$3@5592eff9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@76a82f33{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-6bab2585,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7cbee484
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7f811d00{/,null,STOPPED} added {ServletHandler@62923ee6{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@62923ee6{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-4089713==org.apache.spark.ui.JettyUtils$$anon$3@eebaed90{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@62923ee6{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4089713,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@f19c9d2
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7807ac2c{/,null,STOPPED} added {ServletHandler@b91d8c4{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@b91d8c4{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa==org.apache.spark.ui.JettyUtils$$anon$3@39bf8e35{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@b91d8c4{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4fd4cae3
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@4a067c25{/,null,STOPPED} added {ServletHandler@a1217f9{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@a1217f9{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff==org.apache.spark.ui.JettyUtils$$anon$3@233a05b8{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@a1217f9{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@523424b5
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2baa8d82{/,null,STOPPED} added {ServletHandler@319dead1{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@319dead1{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-791cbf87==org.apache.spark.ui.JettyUtils$$anon$3@f2d0a2e3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@319dead1{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-791cbf87,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@754777cd
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2b52c0d6{/,null,STOPPED} added {ServletHandler@372ea2bc{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG PreEncodedHttpField:61 - HttpField encoders loaded: []
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@372ea2bc{STOPPED} added {org.spark_project.jetty.servlet.DefaultServlet-f415a95==org.spark_project.jetty.servlet.DefaultServlet@25daa4dc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@372ea2bc{STOPPED} added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-f415a95,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@37eeec90
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@32fe9d0a{/,null,STOPPED} added {ServletHandler@c9413d8{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@c9413d8{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$4-64da2a7==org.apache.spark.ui.JettyUtils$$anon$4@f61d61a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@c9413d8{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-64da2a7,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@2c715e84
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@47428937{/,null,STOPPED} added {ServletHandler@3b9d6699{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@3b9d6699{STOPPED} added {org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@3b9d6699{STOPPED} added {[/*]=>org.glassfish.jersey.servlet.ServletContainer-53499d85,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@5ae81e1
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2fd1731c{/,null,STOPPED} added {ServletHandler@5ae76500{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5ae76500{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$4-6063d80a==org.apache.spark.ui.JettyUtils$$anon$4@a904e007{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@5ae76500{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-6063d80a,POJO}
2022-02-09 13:09:10 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@54709809
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2a2da905{/,null,STOPPED} added {ServletHandler@24f360b2{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@24f360b2{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7==org.apache.spark.ui.JettyUtils$$anon$4@f8898a92{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - ServletHandler@24f360b2{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7,POJO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[qtp813131188]@307765b4{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY] added {org.spark_project.jetty.util.thread.ThreadPoolBudget@388ffbc2,POJO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - Server@4de025bf{STOPPED}[9.4.z-SNAPSHOT] added {QueuedThreadPool[SparkUI]@307765b4{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY],AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - Server@4de025bf{STOPPED}[9.4.z-SNAPSHOT] added {ErrorHandler@3ec11999{STOPPED},AUTO}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - Server@4de025bf{STOPPED}[9.4.z-SNAPSHOT] added {ContextHandlerCollection@740abb5{STOPPED},MANAGED}
2022-02-09 13:09:10 DEBUG AbstractLifeCycle:201 - starting Server@4de025bf{STOPPED}[9.4.z-SNAPSHOT]
2022-02-09 13:09:10 INFO  Server:375 - jetty-9.4.z-SNAPSHOT; built: unknown; git: unknown; jvm 1.8.0_281-b09
2022-02-09 13:09:10 DEBUG AbstractHandler:94 - starting Server@4de025bf{STARTING}[9.4.z-SNAPSHOT]
2022-02-09 13:09:10 DEBUG AbstractLifeCycle:201 - starting QueuedThreadPool[SparkUI]@307765b4{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:10 DEBUG ReservedThreadExecutor:85 - ReservedThreadExecutor@58c540cf{s=0/8,p=0}
2022-02-09 13:09:10 DEBUG ContainerLifeCycle:412 - QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=0<=200,i=0,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}] added {ReservedThreadExecutor@58c540cf{s=0/8,p=0},AUTO}
2022-02-09 13:09:10 DEBUG AbstractLifeCycle:201 - starting ReservedThreadExecutor@58c540cf{s=0/8,p=0}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3291ms ReservedThreadExecutor@58c540cf{s=0/8,p=0}
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-27,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-28,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-29,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=2<=200,i=2,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-30,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=3<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-31,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=4<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=5<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-32,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=6<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-33,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=7<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:784 - Starting Thread[SparkUI-34,5,main]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3297ms QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG QueuedThreadPool:980 - Runner started for QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ErrorHandler@3ec11999{STOPPED}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ErrorHandler@3ec11999{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3297ms ErrorHandler@3ec11999{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ContextHandlerCollection@740abb5{STOPPED}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ContextHandlerCollection@740abb5{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3298ms ContextHandlerCollection@740abb5{STARTED}
2022-02-09 13:09:11 INFO  Server:415 - Started @3298ms
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3298ms Server@4de025bf{STARTED}[9.4.z-SNAPSHOT]
2022-02-09 13:09:11 DEBUG JettyUtils:58 - Using requestHeaderSize: 8192
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - HttpConnectionFactory@52350abb[HTTP/1.1] added {HttpConfiguration@681aad3b{32768/8192,8192/8192,https://:0,[]},POJO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{null, ()}{0.0.0.0:0} added {Server@4de025bf{STARTED}[9.4.z-SNAPSHOT],UNMANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{null, ()}{0.0.0.0:0} added {QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}],UNMANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{null, ()}{0.0.0.0:0} added {ScheduledExecutorScheduler@41394595{STOPPED},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{null, ()}{0.0.0.0:0} added {org.spark_project.jetty.io.ArrayByteBufferPool@3a0807b7,POJO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{null, (http/1.1)}{0.0.0.0:0} added {HttpConnectionFactory@52350abb[HTTP/1.1],AUTO}
2022-02-09 13:09:11 DEBUG AbstractConnector:484 - ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added HttpConnectionFactory@52350abb[HTTP/1.1]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:0} added {SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:0},MANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[/0:0:0:0:0:0:0:0:4040],POJO}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ScheduledExecutorScheduler@41394595{STOPPED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3331ms ScheduledExecutorScheduler@41394595{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting HttpConnectionFactory@52350abb[HTTP/1.1]
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3331ms HttpConnectionFactory@52350abb[HTTP/1.1]
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.071+05:30 added {SelectorProducer@384fc774,POJO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}],UNMANAGED}
2022-02-09 13:09:11 DEBUG EatWhatYouKill:93 - EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 created
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ManagedSelector@750fe12e{STOPPED} id=0 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30,MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@750fe12e{STOPPED} id=0 keys=-1 selected=-1 updates=0,AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {SelectorProducer@3e587920,POJO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}],UNMANAGED}
2022-02-09 13:09:11 DEBUG EatWhatYouKill:93 - EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 created
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ManagedSelector@2ef8a8c3{STOPPED} id=1 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30,MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@2ef8a8c3{STOPPED} id=1 keys=-1 selected=-1 updates=0,AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {SelectorProducer@63fd4873,POJO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}],UNMANAGED}
2022-02-09 13:09:11 DEBUG EatWhatYouKill:93 - EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 created
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ManagedSelector@1e11bc55{STOPPED} id=2 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30,MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@1e11bc55{STOPPED} id=2 keys=-1 selected=-1 updates=0,AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {SelectorProducer@70e0accd,POJO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 added {QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}],UNMANAGED}
2022-02-09 13:09:11 DEBUG EatWhatYouKill:93 - EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 created
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ManagedSelector@7957dc72{STOPPED} id=3 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30,MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {ManagedSelector@7957dc72{STOPPED} id=3 keys=-1 selected=-1 updates=0,AUTO}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@750fe12e{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3370ms EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30
2022-02-09 13:09:11 DEBUG QueuedThreadPool:719 - queue org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@82c57b3 startThread=0
2022-02-09 13:09:11 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@82c57b3 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$Start@5be82d43 on ManagedSelector@750fe12e{STARTING} id=0 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG EatWhatYouKill:141 - EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.087+05:30 tryProduce false
2022-02-09 13:09:11 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:11 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$Start@5be82d43
2022-02-09 13:09:11 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:11 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 waiting with 0 keys
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3376ms ManagedSelector@750fe12e{STARTED} id=0 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@2ef8a8c3{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.103+05:30
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3377ms EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30
2022-02-09 13:09:11 DEBUG QueuedThreadPool:719 - queue org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@600b0b7 startThread=0
2022-02-09 13:09:11 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@600b0b7 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$Start@345e5a17 on ManagedSelector@2ef8a8c3{STARTING} id=1 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG EatWhatYouKill:141 - EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30 tryProduce false
2022-02-09 13:09:11 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:11 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$Start@345e5a17
2022-02-09 13:09:11 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:11 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 waiting with 0 keys
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3380ms ManagedSelector@2ef8a8c3{STARTED} id=1 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@1e11bc55{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3381ms EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30
2022-02-09 13:09:11 DEBUG QueuedThreadPool:719 - queue org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@5ea502e0 startThread=0
2022-02-09 13:09:11 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@5ea502e0 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$Start@443dbe42 on ManagedSelector@1e11bc55{STARTING} id=2 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG EatWhatYouKill:141 - EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30 tryProduce false
2022-02-09 13:09:11 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:11 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$Start@443dbe42
2022-02-09 13:09:11 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:11 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 waiting with 0 keys
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3384ms ManagedSelector@1e11bc55{STARTED} id=2 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ManagedSelector@7957dc72{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3385ms EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30
2022-02-09 13:09:11 DEBUG QueuedThreadPool:719 - queue org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@1734f68 startThread=0
2022-02-09 13:09:11 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@1734f68 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$Start@77b7ffa4 on ManagedSelector@7957dc72{STARTING} id=3 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG EatWhatYouKill:141 - EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:11.104+05:30 tryProduce false
2022-02-09 13:09:11 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:11 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$Start@77b7ffa4
2022-02-09 13:09:11 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3388ms ManagedSelector@7957dc72{STARTED} id=3 keys=0 selected=0 updates=0
2022-02-09 13:09:11 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc waiting with 0 keys
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3388ms SelectorManager@ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} added {acceptor-0@5bbc9f97,POJO}
2022-02-09 13:09:11 DEBUG QueuedThreadPool:719 - queue acceptor-0@5bbc9f97 startThread=0
2022-02-09 13:09:11 DEBUG QueuedThreadPool:1035 - run acceptor-0@5bbc9f97 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:11 INFO  AbstractConnector:331 - Started ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3391ms ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:11 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - Server@4de025bf{STARTED}[9.4.z-SNAPSHOT] added {Spark@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040},UNMANAGED}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@781e7326{STOPPED,min=32,inflate=-1} mime types IncludeExclude@22680f52{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@781e7326{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@781e7326{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@781e7326{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@781e7326{STARTING,min=32,inflate=-1} added {DeflaterPool@1fc793c2{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@781e7326{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@4fcee388{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0==org.apache.spark.ui.JettyUtils$$anon$3@9ed39b61{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0=org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0==org.apache.spark.ui.JettyUtils$$anon$3@9ed39b61{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@4fcee388{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3428ms ServletHandler@4fcee388{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0==org.apache.spark.ui.JettyUtils$$anon$3@9ed39b61{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3434ms org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0==org.apache.spark.ui.JettyUtils$$anon$3@9ed39b61{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-3f23a3a0
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3436ms o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1fc793c2{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3437ms DeflaterPool@1fc793c2{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3437ms GzipHandler@781e7326{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@58a55449{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5949eba8{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@58a55449{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@58a55449{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@58a55449{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@58a55449{STARTING,min=32,inflate=-1} added {DeflaterPool@6e0ff644{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@58a55449{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6c6357f9{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-591e58fa[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-591e58fa==org.apache.spark.ui.JettyUtils$$anon$3@23155c82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-591e58fa=org.apache.spark.ui.JettyUtils$$anon$3-591e58fa==org.apache.spark.ui.JettyUtils$$anon$3@23155c82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@6c6357f9{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3443ms ServletHandler@6c6357f9{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-591e58fa==org.apache.spark.ui.JettyUtils$$anon$3@23155c82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3443ms org.apache.spark.ui.JettyUtils$$anon$3-591e58fa==org.apache.spark.ui.JettyUtils$$anon$3@23155c82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-591e58fa
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3444ms o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6e0ff644{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3444ms DeflaterPool@6e0ff644{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3444ms GzipHandler@58a55449{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@58dea0a5{STOPPED,min=32,inflate=-1} mime types IncludeExclude@2a2bb0eb{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@58dea0a5{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@58dea0a5{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@58dea0a5{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@58dea0a5{STARTING,min=32,inflate=-1} added {DeflaterPool@3c291aad{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@58dea0a5{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5d25e6bb{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e==org.apache.spark.ui.JettyUtils$$anon$3@ff588d09{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e=org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e==org.apache.spark.ui.JettyUtils$$anon$3@ff588d09{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5d25e6bb{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3450ms ServletHandler@5d25e6bb{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e==org.apache.spark.ui.JettyUtils$$anon$3@ff588d09{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3450ms org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e==org.apache.spark.ui.JettyUtils$$anon$3@ff588d09{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-ce5a68e
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3450ms o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3c291aad{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3451ms DeflaterPool@3c291aad{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3451ms GzipHandler@58dea0a5{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@733037{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7728643a{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@733037{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@733037{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@733037{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@733037{STARTING,min=32,inflate=-1} added {DeflaterPool@320e400{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@733037{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5df417a7{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-7c041b41[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-7c041b41==org.apache.spark.ui.JettyUtils$$anon$3@9c34dc8a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-7c041b41=org.apache.spark.ui.JettyUtils$$anon$3-7c041b41==org.apache.spark.ui.JettyUtils$$anon$3@9c34dc8a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5df417a7{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3455ms ServletHandler@5df417a7{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-7c041b41==org.apache.spark.ui.JettyUtils$$anon$3@9c34dc8a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3456ms org.apache.spark.ui.JettyUtils$$anon$3-7c041b41==org.apache.spark.ui.JettyUtils$$anon$3@9c34dc8a{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-7c041b41
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3456ms o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@320e400{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3457ms DeflaterPool@320e400{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3457ms GzipHandler@733037{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@5167268{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1cfd1875{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@5167268{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@664a9613{/stages,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@5167268{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@5167268{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@5167268{STARTING,min=32,inflate=-1} added {DeflaterPool@28c0b664{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@5167268{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@664a9613{/stages,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@664a9613{/stages,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5118388b{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-15a902e7[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-15a902e7==org.apache.spark.ui.JettyUtils$$anon$3@ff71f2fc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-15a902e7=org.apache.spark.ui.JettyUtils$$anon$3-15a902e7==org.apache.spark.ui.JettyUtils$$anon$3@ff71f2fc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5118388b{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3464ms ServletHandler@5118388b{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-15a902e7==org.apache.spark.ui.JettyUtils$$anon$3@ff71f2fc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3464ms org.apache.spark.ui.JettyUtils$$anon$3-15a902e7==org.apache.spark.ui.JettyUtils$$anon$3@ff71f2fc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-15a902e7
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3465ms o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@28c0b664{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3465ms DeflaterPool@28c0b664{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3465ms GzipHandler@5167268{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@2c444798{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1af7f54a{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@2c444798{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@2c444798{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@2c444798{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@2c444798{STARTING,min=32,inflate=-1} added {DeflaterPool@6ebd78d1{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@2c444798{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5af28b27{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-71104a4[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-71104a4==org.apache.spark.ui.JettyUtils$$anon$3@8ebbb6a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-71104a4=org.apache.spark.ui.JettyUtils$$anon$3-71104a4==org.apache.spark.ui.JettyUtils$$anon$3@8ebbb6a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5af28b27{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3469ms ServletHandler@5af28b27{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-71104a4==org.apache.spark.ui.JettyUtils$$anon$3@8ebbb6a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3470ms org.apache.spark.ui.JettyUtils$$anon$3-71104a4==org.apache.spark.ui.JettyUtils$$anon$3@8ebbb6a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-71104a4
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3470ms o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6ebd78d1{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3470ms DeflaterPool@6ebd78d1{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3470ms GzipHandler@2c444798{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@436390f4{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4d157787{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@436390f4{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@436390f4{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@436390f4{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@436390f4{STARTING,min=32,inflate=-1} added {DeflaterPool@68ed96ca{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@436390f4{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@332a7fce{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-549621f3[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-549621f3==org.apache.spark.ui.JettyUtils$$anon$3@25a530f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-549621f3=org.apache.spark.ui.JettyUtils$$anon$3-549621f3==org.apache.spark.ui.JettyUtils$$anon$3@25a530f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@332a7fce{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3476ms ServletHandler@332a7fce{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-549621f3==org.apache.spark.ui.JettyUtils$$anon$3@25a530f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3476ms org.apache.spark.ui.JettyUtils$$anon$3-549621f3==org.apache.spark.ui.JettyUtils$$anon$3@25a530f4{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-549621f3
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3476ms o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@68ed96ca{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3477ms DeflaterPool@68ed96ca{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3477ms GzipHandler@436390f4{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@54e7391d{STOPPED,min=32,inflate=-1} mime types IncludeExclude@50b8ae8d{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@54e7391d{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@54e7391d{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@54e7391d{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@54e7391d{STARTING,min=32,inflate=-1} added {DeflaterPool@255990cc{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@54e7391d{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5217f3d0{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8==org.apache.spark.ui.JettyUtils$$anon$3@422d3277{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8=org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8==org.apache.spark.ui.JettyUtils$$anon$3@422d3277{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5217f3d0{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3483ms ServletHandler@5217f3d0{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8==org.apache.spark.ui.JettyUtils$$anon$3@422d3277{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3483ms org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8==org.apache.spark.ui.JettyUtils$$anon$3@422d3277{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-37ebc9d8
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3483ms o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@255990cc{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3484ms DeflaterPool@255990cc{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3484ms GzipHandler@54e7391d{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@51c929ae{STOPPED,min=32,inflate=-1} mime types IncludeExclude@3c8bdd5b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@51c929ae{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@51c929ae{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@51c929ae{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@51c929ae{STARTING,min=32,inflate=-1} added {DeflaterPool@29d2d081{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@51c929ae{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@6e9319f{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-72e34f77[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-72e34f77==org.apache.spark.ui.JettyUtils$$anon$3@d687b307{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-72e34f77=org.apache.spark.ui.JettyUtils$$anon$3-72e34f77==org.apache.spark.ui.JettyUtils$$anon$3@d687b307{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@6e9319f{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3488ms ServletHandler@6e9319f{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-72e34f77==org.apache.spark.ui.JettyUtils$$anon$3@d687b307{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3488ms org.apache.spark.ui.JettyUtils$$anon$3-72e34f77==org.apache.spark.ui.JettyUtils$$anon$3@d687b307{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-72e34f77
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3488ms o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@29d2d081{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3489ms DeflaterPool@29d2d081{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3489ms GzipHandler@51c929ae{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@40e4ea87{STOPPED,min=32,inflate=-1} mime types IncludeExclude@58783f6c{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@40e4ea87{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@40e4ea87{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@40e4ea87{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@40e4ea87{STARTING,min=32,inflate=-1} added {DeflaterPool@3a7b503d{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@40e4ea87{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@77307458{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e==org.apache.spark.ui.JettyUtils$$anon$3@226e2d85{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e=org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e==org.apache.spark.ui.JettyUtils$$anon$3@226e2d85{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@77307458{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3494ms ServletHandler@77307458{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e==org.apache.spark.ui.JettyUtils$$anon$3@226e2d85{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3494ms org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e==org.apache.spark.ui.JettyUtils$$anon$3@226e2d85{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-1fc0053e
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3495ms o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3a7b503d{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3495ms DeflaterPool@3a7b503d{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3495ms GzipHandler@40e4ea87{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@512d92b{STOPPED,min=32,inflate=-1} mime types IncludeExclude@62c5bbdc{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@512d92b{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@18e7143f{/storage,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@512d92b{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@512d92b{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@512d92b{STARTING,min=32,inflate=-1} added {DeflaterPool@7bdf6bb7{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@512d92b{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@18e7143f{/storage,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@18e7143f{/storage,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@f9b7332{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-74cec793[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-74cec793==org.apache.spark.ui.JettyUtils$$anon$3@3fbfbcb9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-74cec793=org.apache.spark.ui.JettyUtils$$anon$3-74cec793==org.apache.spark.ui.JettyUtils$$anon$3@3fbfbcb9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@f9b7332{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3499ms ServletHandler@f9b7332{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-74cec793==org.apache.spark.ui.JettyUtils$$anon$3@3fbfbcb9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3499ms org.apache.spark.ui.JettyUtils$$anon$3-74cec793==org.apache.spark.ui.JettyUtils$$anon$3@3fbfbcb9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-74cec793
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3500ms o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@7bdf6bb7{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3500ms DeflaterPool@7bdf6bb7{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3500ms GzipHandler@512d92b{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@1bc53649{STOPPED,min=32,inflate=-1} mime types IncludeExclude@88d6f9b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@1bc53649{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@1bc53649{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@1bc53649{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@1bc53649{STARTING,min=32,inflate=-1} added {DeflaterPool@47d93e0d{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@1bc53649{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@1bdf8190{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-192f2f27[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-192f2f27==org.apache.spark.ui.JettyUtils$$anon$3@8552e241{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-192f2f27=org.apache.spark.ui.JettyUtils$$anon$3-192f2f27==org.apache.spark.ui.JettyUtils$$anon$3@8552e241{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@1bdf8190{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3504ms ServletHandler@1bdf8190{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-192f2f27==org.apache.spark.ui.JettyUtils$$anon$3@8552e241{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3504ms org.apache.spark.ui.JettyUtils$$anon$3-192f2f27==org.apache.spark.ui.JettyUtils$$anon$3@8552e241{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-192f2f27
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3505ms o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@47d93e0d{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3505ms DeflaterPool@47d93e0d{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3505ms GzipHandler@1bc53649{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@475b7792{STOPPED,min=32,inflate=-1} mime types IncludeExclude@751e664e{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@475b7792{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@475b7792{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@475b7792{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@475b7792{STARTING,min=32,inflate=-1} added {DeflaterPool@160c3ec1{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@475b7792{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@b672aa8{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff==org.apache.spark.ui.JettyUtils$$anon$3@89a8bd2e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff=org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff==org.apache.spark.ui.JettyUtils$$anon$3@89a8bd2e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@b672aa8{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3511ms ServletHandler@b672aa8{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff==org.apache.spark.ui.JettyUtils$$anon$3@89a8bd2e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3511ms org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff==org.apache.spark.ui.JettyUtils$$anon$3@89a8bd2e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-2fab4aff
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3511ms o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@160c3ec1{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3512ms DeflaterPool@160c3ec1{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3512ms GzipHandler@475b7792{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@182b435b{STOPPED,min=32,inflate=-1} mime types IncludeExclude@4d0402b{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@182b435b{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@182b435b{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@182b435b{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@182b435b{STARTING,min=32,inflate=-1} added {DeflaterPool@2fa7ae9{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@182b435b{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5cc69cfe{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b==org.apache.spark.ui.JettyUtils$$anon$3@40e7975b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b=org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b==org.apache.spark.ui.JettyUtils$$anon$3@40e7975b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5cc69cfe{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3517ms ServletHandler@5cc69cfe{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b==org.apache.spark.ui.JettyUtils$$anon$3@40e7975b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3518ms org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b==org.apache.spark.ui.JettyUtils$$anon$3@40e7975b{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-29cfd92b
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3518ms o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@2fa7ae9{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3518ms DeflaterPool@2fa7ae9{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3518ms GzipHandler@182b435b{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@7577b641{STOPPED,min=32,inflate=-1} mime types IncludeExclude@3704122f{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@7577b641{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@55f3c410{/environment,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@7577b641{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@7577b641{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@7577b641{STARTING,min=32,inflate=-1} added {DeflaterPool@3153ddfc{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@7577b641{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@55f3c410{/environment,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@55f3c410{/environment,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@11acdc30{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-770d4269[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-770d4269==org.apache.spark.ui.JettyUtils$$anon$3@8747bec1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-770d4269=org.apache.spark.ui.JettyUtils$$anon$3-770d4269==org.apache.spark.ui.JettyUtils$$anon$3@8747bec1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@11acdc30{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3523ms ServletHandler@11acdc30{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-770d4269==org.apache.spark.ui.JettyUtils$$anon$3@8747bec1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3523ms org.apache.spark.ui.JettyUtils$$anon$3-770d4269==org.apache.spark.ui.JettyUtils$$anon$3@8747bec1{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-770d4269
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3524ms o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3153ddfc{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3525ms DeflaterPool@3153ddfc{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3525ms GzipHandler@7577b641{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@60afd40d{STOPPED,min=32,inflate=-1} mime types IncludeExclude@28a2a3e7{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@60afd40d{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@60afd40d{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@60afd40d{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@60afd40d{STARTING,min=32,inflate=-1} added {DeflaterPool@3f2049b6{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@60afd40d{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@76a82f33{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-6bab2585[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-6bab2585==org.apache.spark.ui.JettyUtils$$anon$3@5592eff9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-6bab2585=org.apache.spark.ui.JettyUtils$$anon$3-6bab2585==org.apache.spark.ui.JettyUtils$$anon$3@5592eff9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@76a82f33{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3529ms ServletHandler@76a82f33{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-6bab2585==org.apache.spark.ui.JettyUtils$$anon$3@5592eff9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3530ms org.apache.spark.ui.JettyUtils$$anon$3-6bab2585==org.apache.spark.ui.JettyUtils$$anon$3@5592eff9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-6bab2585
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3530ms o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3f2049b6{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3530ms DeflaterPool@3f2049b6{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3530ms GzipHandler@60afd40d{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@10b3df93{STOPPED,min=32,inflate=-1} mime types IncludeExclude@ea27e34{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@10b3df93{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7f811d00{/executors,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@10b3df93{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@10b3df93{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@10b3df93{STARTING,min=32,inflate=-1} added {DeflaterPool@33a2499c{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@10b3df93{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7f811d00{/executors,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7f811d00{/executors,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@62923ee6{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4089713[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-4089713==org.apache.spark.ui.JettyUtils$$anon$3@eebaed90{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4089713=org.apache.spark.ui.JettyUtils$$anon$3-4089713==org.apache.spark.ui.JettyUtils$$anon$3@eebaed90{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@62923ee6{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3537ms ServletHandler@62923ee6{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-4089713==org.apache.spark.ui.JettyUtils$$anon$3@eebaed90{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3537ms org.apache.spark.ui.JettyUtils$$anon$3-4089713==org.apache.spark.ui.JettyUtils$$anon$3@eebaed90{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-4089713
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3538ms o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@33a2499c{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3538ms DeflaterPool@33a2499c{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3539ms GzipHandler@10b3df93{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@e72dba7{STOPPED,min=32,inflate=-1} mime types IncludeExclude@33c2bd{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@e72dba7{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@e72dba7{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@e72dba7{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@e72dba7{STARTING,min=32,inflate=-1} added {DeflaterPool@1dfd5f51{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@e72dba7{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@b91d8c4{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa==org.apache.spark.ui.JettyUtils$$anon$3@39bf8e35{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa=org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa==org.apache.spark.ui.JettyUtils$$anon$3@39bf8e35{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@b91d8c4{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3545ms ServletHandler@b91d8c4{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa==org.apache.spark.ui.JettyUtils$$anon$3@39bf8e35{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3546ms org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa==org.apache.spark.ui.JettyUtils$$anon$3@39bf8e35{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-4b6166aa
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3546ms o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@1dfd5f51{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3546ms DeflaterPool@1dfd5f51{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3547ms GzipHandler@e72dba7{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@3c321bdb{STOPPED,min=32,inflate=-1} mime types IncludeExclude@24855019{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@3c321bdb{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@3c321bdb{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3c321bdb{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@3c321bdb{STARTING,min=32,inflate=-1} added {DeflaterPool@3abd581e{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@3c321bdb{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@a1217f9{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff==org.apache.spark.ui.JettyUtils$$anon$3@233a05b8{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff=org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff==org.apache.spark.ui.JettyUtils$$anon$3@233a05b8{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@a1217f9{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3552ms ServletHandler@a1217f9{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff==org.apache.spark.ui.JettyUtils$$anon$3@233a05b8{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3552ms org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff==org.apache.spark.ui.JettyUtils$$anon$3@233a05b8{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-3bde62ff
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3552ms o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3abd581e{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3553ms DeflaterPool@3abd581e{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3553ms GzipHandler@3c321bdb{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@4d4d8fcf{STOPPED,min=32,inflate=-1} mime types IncludeExclude@610db97e{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@4d4d8fcf{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@4d4d8fcf{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4d4d8fcf{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@4d4d8fcf{STARTING,min=32,inflate=-1} added {DeflaterPool@6f0628de{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@4d4d8fcf{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@319dead1{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-791cbf87[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-791cbf87==org.apache.spark.ui.JettyUtils$$anon$3@f2d0a2e3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-791cbf87=org.apache.spark.ui.JettyUtils$$anon$3-791cbf87==org.apache.spark.ui.JettyUtils$$anon$3@f2d0a2e3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@319dead1{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3558ms ServletHandler@319dead1{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-791cbf87==org.apache.spark.ui.JettyUtils$$anon$3@f2d0a2e3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3559ms org.apache.spark.ui.JettyUtils$$anon$3-791cbf87==org.apache.spark.ui.JettyUtils$$anon$3@f2d0a2e3{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-791cbf87
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3559ms o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@6f0628de{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3559ms DeflaterPool@6f0628de{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3559ms GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@3fabf088{STOPPED,min=32,inflate=-1} mime types IncludeExclude@1e392345{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@3fabf088{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@3fabf088{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@3fabf088{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@3fabf088{STARTING,min=32,inflate=-1} added {DeflaterPool@12f3afb5{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@3fabf088{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@372ea2bc{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-f415a95[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.spark_project.jetty.servlet.DefaultServlet-f415a95==org.spark_project.jetty.servlet.DefaultServlet@25daa4dc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-f415a95=org.spark_project.jetty.servlet.DefaultServlet-f415a95==org.spark_project.jetty.servlet.DefaultServlet@25daa4dc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@372ea2bc{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3564ms ServletHandler@372ea2bc{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.spark_project.jetty.servlet.DefaultServlet-f415a95==org.spark_project.jetty.servlet.DefaultServlet@25daa4dc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3565ms org.spark_project.jetty.servlet.DefaultServlet-f415a95==org.spark_project.jetty.servlet.DefaultServlet@25daa4dc{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.spark_project.jetty.servlet.DefaultServlet-f415a95
2022-02-09 13:09:11 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Anukul%20Thalkar/.m2/repository/org/apache/spark/spark-core_2.11/2.4.8/spark-core_2.11-2.4.8.jar!/org/apache/spark/ui/static
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3577ms o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@12f3afb5{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3577ms DeflaterPool@12f3afb5{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3577ms GzipHandler@3fabf088{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@619bd14c{STOPPED,min=32,inflate=-1} mime types IncludeExclude@323e8306{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@619bd14c{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@32fe9d0a{/,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@619bd14c{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@619bd14c{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@619bd14c{STARTING,min=32,inflate=-1} added {DeflaterPool@a23a01d{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@619bd14c{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@32fe9d0a{/,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@32fe9d0a{/,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@c9413d8{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-64da2a7[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$4-64da2a7==org.apache.spark.ui.JettyUtils$$anon$4@f61d61a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-64da2a7=org.apache.spark.ui.JettyUtils$$anon$4-64da2a7==org.apache.spark.ui.JettyUtils$$anon$4@f61d61a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@c9413d8{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3584ms ServletHandler@c9413d8{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$4-64da2a7==org.apache.spark.ui.JettyUtils$$anon$4@f61d61a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3584ms org.apache.spark.ui.JettyUtils$$anon$4-64da2a7==org.apache.spark.ui.JettyUtils$$anon$4@f61d61a2{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$4-64da2a7
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3584ms o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@a23a01d{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3585ms DeflaterPool@a23a01d{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3585ms GzipHandler@619bd14c{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@4acf72b6{STOPPED,min=32,inflate=-1} mime types IncludeExclude@7561db12{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@4acf72b6{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@47428937{/api,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@4acf72b6{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@4acf72b6{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@4acf72b6{STARTING,min=32,inflate=-1} added {DeflaterPool@3301500b{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@4acf72b6{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@47428937{/api,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@47428937{/api,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3b9d6699{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-53499d85[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-53499d85=org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG ServletHandler:169 - Adding Default404Servlet to ServletHandler@3b9d6699{STARTING}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@3b9d6699{STARTING} added {org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@3b9d6699{STARTING} added {[/]=>org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e,POJO}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-53499d85[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-53499d85=org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-53499d85[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@5fa{/*},resource=org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=2]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=2]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-53499d85=org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}, org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e=org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@3b9d6699{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3603ms ServletHandler@3b9d6699{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3604ms org.glassfish.jersey.servlet.ServletContainer-53499d85==org.glassfish.jersey.servlet.ServletContainer@40714839{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3604ms org.spark_project.jetty.servlet.ServletHandler$Default404Servlet-6e9c413e==org.spark_project.jetty.servlet.ServletHandler$Default404Servlet@c2a16e4c{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3605ms o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3301500b{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3605ms DeflaterPool@3301500b{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3605ms GzipHandler@4acf72b6{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@57a4d5ee{STOPPED,min=32,inflate=-1} mime types IncludeExclude@5af5def9{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@57a4d5ee{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@57a4d5ee{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@57a4d5ee{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@57a4d5ee{STARTING,min=32,inflate=-1} added {DeflaterPool@3a45c42a{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@57a4d5ee{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5ae76500{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-6063d80a[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$4-6063d80a==org.apache.spark.ui.JettyUtils$$anon$4@a904e007{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-6063d80a=org.apache.spark.ui.JettyUtils$$anon$4-6063d80a==org.apache.spark.ui.JettyUtils$$anon$4@a904e007{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5ae76500{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3614ms ServletHandler@5ae76500{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$4-6063d80a==org.apache.spark.ui.JettyUtils$$anon$4@a904e007{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3615ms org.apache.spark.ui.JettyUtils$$anon$4-6063d80a==org.apache.spark.ui.JettyUtils$$anon$4@a904e007{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$4-6063d80a
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3615ms o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@3a45c42a{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3616ms DeflaterPool@3a45c42a{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3616ms GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4a69d1f9{*.svgz},resource=true] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG GzipHandler:208 - GzipHandler@36dce7ed{STOPPED,min=32,inflate=-1} mime types IncludeExclude@47a64f7d{i=[],ip=CONTAINS,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=CONTAINS}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@36dce7ed{STOPPED,min=32,inflate=-1} added {o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,STOPPED,@Spark},MANAGED}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STOPPED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {GzipHandler@36dce7ed{STOPPED,min=32,inflate=-1},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting GzipHandler@36dce7ed{STOPPED,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - GzipHandler@36dce7ed{STARTING,min=32,inflate=-1} added {DeflaterPool@33d05366{STOPPED,size=0,capacity=UNLIMITED},AUTO}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting GzipHandler@36dce7ed{STARTING,min=32,inflate=-1}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@24f360b2{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7==org.apache.spark.ui.JettyUtils$$anon$4@f8898a92{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7=org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7==org.apache.spark.ui.JettyUtils$$anon$4@f8898a92{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@24f360b2{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3625ms ServletHandler@24f360b2{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7==org.apache.spark.ui.JettyUtils$$anon$4@f8898a92{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3625ms org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7==org.apache.spark.ui.JettyUtils$$anon$4@f8898a92{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$4-60cf80e7
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3626ms o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting DeflaterPool@33d05366{STOPPED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3626ms DeflaterPool@33d05366{STARTED,size=0,capacity=UNLIMITED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @3626ms GzipHandler@36dce7ed{STARTED,min=32,inflate=-1}
2022-02-09 13:09:11 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://Clairvoyant-324.mshome.net:4040
2022-02-09 13:09:11 INFO  Executor:54 - Starting executor ID driver on host localhost
2022-02-09 13:09:11 DEBUG TransportServer:141 - Shuffle server started on port: 52097
2022-02-09 13:09:11 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52097.
2022-02-09 13:09:11 INFO  NettyBlockTransferService:54 - Server created on Clairvoyant-324.mshome.net:52097
2022-02-09 13:09:11 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2022-02-09 13:09:11 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, Clairvoyant-324.mshome.net, 52097, None)
2022-02-09 13:09:11 DEBUG DefaultTopologyMapper:58 - Got a request for Clairvoyant-324.mshome.net
2022-02-09 13:09:11 INFO  BlockManagerMasterEndpoint:54 - Registering block manager Clairvoyant-324.mshome.net:52097 with 1970.4 MB RAM, BlockManagerId(driver, Clairvoyant-324.mshome.net, 52097, None)
2022-02-09 13:09:11 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, Clairvoyant-324.mshome.net, 52097, None)
2022-02-09 13:09:11 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, Clairvoyant-324.mshome.net, 52097, None)
2022-02-09 13:09:11 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@51751e5f
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@2b0b4d53{/,null,STOPPED} added {ServletHandler@7068f7ca{STOPPED},MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@7068f7ca{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-38548b19==org.apache.spark.ui.JettyUtils$$anon$3@228f9e82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@7068f7ca{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-38548b19,POJO}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - metrics/json->[{o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,STOPPED,@Spark},[o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,STOPPED,@Spark},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@7068f7ca{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-38548b19[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-38548b19==org.apache.spark.ui.JettyUtils$$anon$3@228f9e82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-38548b19=org.apache.spark.ui.JettyUtils$$anon$3-38548b19==org.apache.spark.ui.JettyUtils$$anon$3@228f9e82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@7068f7ca{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4002ms ServletHandler@7068f7ca{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-38548b19==org.apache.spark.ui.JettyUtils$$anon$3@228f9e82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4002ms org.apache.spark.ui.JettyUtils$$anon$3-38548b19==org.apache.spark.ui.JettyUtils$$anon$3@228f9e82{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-38548b19
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4003ms o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG SparkContext:58 - Adding shutdown hook
2022-02-09 13:09:11 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/spark-warehouse').
2022-02-09 13:09:11 INFO  SharedState:54 - Warehouse path is 'file:/C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/spark-warehouse'.
2022-02-09 13:09:11 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@d8948cd
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1436a7ab{/,null,STOPPED} added {ServletHandler@3b7b05a8{STOPPED},MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@3b7b05a8{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4==org.apache.spark.ui.JettyUtils$$anon$3@36e86130{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@3b7b05a8{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4,POJO}
2022-02-09 13:09:11 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@7abe27bf
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@5b94ccbc{/,null,STOPPED} added {ServletHandler@38a1c423{STOPPED},MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@38a1c423{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-336365bc==org.apache.spark.ui.JettyUtils$$anon$3@1bb5abc9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@38a1c423{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-336365bc,POJO}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL->[{o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,STOPPED,@Spark},[o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - metrics/json->[{o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,STOPPED,@Spark},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@3b7b05a8{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4==org.apache.spark.ui.JettyUtils$$anon$3@36e86130{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4=org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4==org.apache.spark.ui.JettyUtils$$anon$3@36e86130{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@3b7b05a8{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4176ms ServletHandler@3b7b05a8{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4==org.apache.spark.ui.JettyUtils$$anon$3@36e86130{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4176ms org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4==org.apache.spark.ui.JettyUtils$$anon$3@36e86130{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-3d36dff4
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4177ms o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL->[{o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/json->[{o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,STOPPED,@Spark},[o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - metrics/json->[{o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,STOPPED,@Spark},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@38a1c423{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-336365bc[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-336365bc==org.apache.spark.ui.JettyUtils$$anon$3@1bb5abc9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-336365bc=org.apache.spark.ui.JettyUtils$$anon$3-336365bc==org.apache.spark.ui.JettyUtils$$anon$3@1bb5abc9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@38a1c423{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4183ms ServletHandler@38a1c423{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-336365bc==org.apache.spark.ui.JettyUtils$$anon$3@1bb5abc9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4183ms org.apache.spark.ui.JettyUtils$$anon$3-336365bc==org.apache.spark.ui.JettyUtils$$anon$3@1bb5abc9{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-336365bc
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4184ms o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4567e53d
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@7351a16e{/,null,STOPPED} added {ServletHandler@5bb7643d{STOPPED},MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@5bb7643d{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-3ac04654==org.apache.spark.ui.JettyUtils$$anon$3@e9b33448{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@5bb7643d{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-3ac04654,POJO}
2022-02-09 13:09:11 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@4074023c
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@3ed0918d{/,null,STOPPED} added {ServletHandler@5e268ce6{STOPPED},MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@5e268ce6{STOPPED} added {org.apache.spark.ui.JettyUtils$$anon$3-66ec9390==org.apache.spark.ui.JettyUtils$$anon$3@44e561fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@5e268ce6{STOPPED} added {[/]=>org.apache.spark.ui.JettyUtils$$anon$3-66ec9390,POJO}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL->[{o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/json->[{o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - metrics/json->[{o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/execution->[{o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,STOPPED,@Spark},[o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,STOPPED,@Spark},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5bb7643d{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-3ac04654[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-3ac04654==org.apache.spark.ui.JettyUtils$$anon$3@e9b33448{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-3ac04654=org.apache.spark.ui.JettyUtils$$anon$3-3ac04654==org.apache.spark.ui.JettyUtils$$anon$3@e9b33448{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5bb7643d{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4194ms ServletHandler@5bb7643d{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-3ac04654==org.apache.spark.ui.JettyUtils$$anon$3@e9b33448{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4194ms org.apache.spark.ui.JettyUtils$$anon$3-3ac04654==org.apache.spark.ui.JettyUtils$$anon$3@e9b33448{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-3ac04654
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4195ms o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,STOPPED,@Spark},[o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL->[{o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/json->[{o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - metrics/json->[{o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/execution->[{o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,STOPPED,@Spark},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5e268ce6{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$3-66ec9390[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.apache.spark.ui.JettyUtils$$anon$3-66ec9390==org.apache.spark.ui.JettyUtils$$anon$3@44e561fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$3-66ec9390=org.apache.spark.ui.JettyUtils$$anon$3-66ec9390==org.apache.spark.ui.JettyUtils$$anon$3@44e561fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5e268ce6{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4203ms ServletHandler@5e268ce6{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.apache.spark.ui.JettyUtils$$anon$3-66ec9390==org.apache.spark.ui.JettyUtils$$anon$3@44e561fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4203ms org.apache.spark.ui.JettyUtils$$anon$3-66ec9390==org.apache.spark.ui.JettyUtils$$anon$3@44e561fb{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.apache.spark.ui.JettyUtils$$anon$3-66ec9390
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4204ms o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG DecoratedObjectFactory:53 - Adding Decorator: org.spark_project.jetty.util.DeprecationWarning@54562ea6
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - o.s.j.s.ServletContextHandler@1a35993f{/,null,STOPPED} added {ServletHandler@5b12012e{STOPPED},MANAGED}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@5b12012e{STOPPED} added {org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2==org.spark_project.jetty.servlet.DefaultServlet@dd89647e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null},AUTO}
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ServletHandler@5b12012e{STOPPED} added {[/]=>org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2,POJO}
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - ->[{GzipHandler@619bd14c{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32fe9d0a{/,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd->[{GzipHandler@475b7792{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6b5176f2{/storage/rdd,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage->[{GzipHandler@512d92b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@18e7143f{/storage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/rdd/json->[{GzipHandler@182b435b{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6e46d9f4{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/execution/json->[{o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@3ed0918d{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - api->[{GzipHandler@4acf72b6{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@47428937{/api,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool/json->[{GzipHandler@40e4ea87{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@389adf1d{/stages/pool/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/pool->[{GzipHandler@51c929ae{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fa590ba{/stages/pool,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/json->[{GzipHandler@58a55449{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@6fff253c{/jobs/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static->[{GzipHandler@3fabf088{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b52c0d6{/static,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/json->[{GzipHandler@e72dba7{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7807ac2c{/executors/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/json->[{GzipHandler@54e7391d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@32232e55{/stages/stage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump/json->[{GzipHandler@4d4d8fcf{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2baa8d82{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment/json->[{GzipHandler@60afd40d{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@1922e6d{/environment/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/json->[{GzipHandler@733037{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2f162cc0{/jobs/job/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs->[{GzipHandler@781e7326{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2b62442c{/jobs,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/json->[{GzipHandler@2c444798{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a3e3e8b{/stages/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage->[{GzipHandler@436390f4{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@3c9168dc{/stages/stage,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - storage/json->[{GzipHandler@1bc53649{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4f8969b0{/storage/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL->[{o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@1436a7ab{/SQL,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - static/sql->[{o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,STOPPED,@Spark},[o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,STOPPED,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages/stage/kill->[{GzipHandler@36dce7ed{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2a2da905{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job->[{GzipHandler@58dea0a5{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@493dfb8e{/jobs/job,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - environment->[{GzipHandler@7577b641{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@55f3c410{/environment,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - stages->[{GzipHandler@5167268{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@664a9613{/stages,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors->[{GzipHandler@10b3df93{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@7f811d00{/executors,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/json->[{o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@5b94ccbc{/SQL/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - jobs/job/kill->[{GzipHandler@57a4d5ee{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@2fd1731c{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - metrics/json->[{o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@2b0b4d53{/metrics/json,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - SQL/execution->[{o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,AVAILABLE,@Spark},[o.s.j.s.ServletContextHandler@7351a16e{/SQL/execution,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContextHandlerCollection:157 - executors/threadDump->[{GzipHandler@3c321bdb{STARTED,min=32,inflate=-1},[o.s.j.s.ServletContextHandler@4a067c25{/executors/threadDump,null,AVAILABLE,@Spark}]}]
2022-02-09 13:09:11 DEBUG ContainerLifeCycle:412 - ContextHandlerCollection@740abb5{STARTED} added {o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,STOPPED,@Spark},UNMANAGED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,STOPPED,@Spark}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,STARTING,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting ServletHandler@5b12012e{STOPPED}
2022-02-09 13:09:11 DEBUG ServletHandler:1418 - Path=/[EMBEDDED:null] mapped to servlet=org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2[EMBEDDED:null]
2022-02-09 13:09:11 DEBUG PathMappings:257 - Added MappedResource[pathSpec=ServletPathSpec@4e{/},resource=org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2==org.spark_project.jetty.servlet.DefaultServlet@dd89647e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}] to PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1439 - filterNameMap={}
2022-02-09 13:09:11 DEBUG ServletHandler:1440 - pathFilters=null
2022-02-09 13:09:11 DEBUG ServletHandler:1441 - servletFilterMap=null
2022-02-09 13:09:11 DEBUG ServletHandler:1442 - servletPathMap=PathMappings[size=1]
2022-02-09 13:09:11 DEBUG ServletHandler:1443 - servletNameMap={org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2=org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2==org.spark_project.jetty.servlet.DefaultServlet@dd89647e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}}
2022-02-09 13:09:11 DEBUG AbstractHandler:94 - starting ServletHandler@5b12012e{STARTING}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4216ms ServletHandler@5b12012e{STARTED}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:201 - starting org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2==org.spark_project.jetty.servlet.DefaultServlet@dd89647e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4216ms org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2==org.spark_project.jetty.servlet.DefaultServlet@dd89647e{jsp=null,order=-1,inst=false,async=true,src=EMBEDDED:null}
2022-02-09 13:09:11 DEBUG ServletHolder:621 - Servlet.init null for org.spark_project.jetty.servlet.DefaultServlet-2f7dcef2
2022-02-09 13:09:11 DEBUG DefaultServlet:308 - resource base = jar:file:/C:/Users/Anukul%20Thalkar/.m2/repository/org/apache/spark/spark-sql_2.11/2.4.8/spark-sql_2.11-2.4.8.jar!/org/apache/spark/sql/execution/ui/static
2022-02-09 13:09:11 INFO  ContextHandler:916 - Started o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,AVAILABLE,@Spark}
2022-02-09 13:09:11 DEBUG AbstractLifeCycle:191 - STARTED @4239ms o.s.j.s.ServletContextHandler@1a35993f{/static/sql,null,AVAILABLE,@Spark}
2022-02-09 13:09:12 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint
2022-02-09 13:09:12 INFO  InMemoryFileIndex:54 - It took 30 ms to list leaf files for 1 paths.
2022-02-09 13:09:12 INFO  InMemoryFileIndex:54 - It took 5 ms to list leaf files for 2 paths.
2022-02-09 13:09:13 DEBUG Analyzer$ResolveReferences:58 - Resolving 'value to value#0
2022-02-09 13:09:13 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'Project [unresolvedalias('value, None)]   Project [value#0]
 +- Relation[value#0] text                  +- Relation[value#0] text
          
2022-02-09 13:09:14 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#4: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#4: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          
2022-02-09 13:09:14 DEBUG Analyzer$ResolveReferences:58 - Resolving 'value to value#0
2022-02-09 13:09:14 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'Filter (length(trim('value, None)) > 0)   Filter (length(trim(value#0, None)) > 0)
 +- Project [value#0]                       +- Project [value#0]
    +- Relation[value#0] text                  +- Relation[value#0] text
          
2022-02-09 13:09:14 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#5: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#5: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          
2022-02-09 13:09:14 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#6: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#6: java.lang.String
 +- LocalRelation <empty>, [value#0]                                                                                                                                      +- LocalRelation <empty>, [value#0]
          
2022-02-09 13:09:14 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 1                                    GlobalLimit 1
 +- LocalLimit 1                                  +- LocalLimit 1
    +- Filter (length(trim(value#0, None)) > 0)      +- Filter (length(trim(value#0, None)) > 0)
!      +- Project [value#0]                             +- Relation[value#0] text
!         +- Relation[value#0] text               
          
2022-02-09 13:09:14 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:14 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#0, None)) > 0)
2022-02-09 13:09:14 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2022-02-09 13:09:14 INFO  FileSourceScanExec:54 - Pushed Filters: 
2022-02-09 13:09:14 DEBUG GenerateSafeProjection:58 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:14 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:14 INFO  CodeGenerator:54 - Code generated in 290.8706 ms
2022-02-09 13:09:15 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-09 13:09:15 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-09 13:09:15 INFO  CodeGenerator:54 - Code generated in 24.0471 ms
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 221.9 KB, free 1970.2 MB)
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_0 locally took  48 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_0 without replication took  48 ms
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1970.2 MB)
2022-02-09 13:09:15 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.4 MB)
2022-02-09 13:09:15 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_0_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Told master about block broadcast_0_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_0_piece0 locally took  15 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_0_piece0 without replication took  15 ms
2022-02-09 13:09:15 INFO  SparkContext:54 - Created broadcast 0 from load at UseCase5Test.java:16
2022-02-09 13:09:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8388788 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$5) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.SparkPlan$$anonfun$5.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final byte[] org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(scala.Tuple2)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$5) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$6) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.SparkPlan$$anonfun$6.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.SparkPlan$$anonfun$6.apply(java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final byte[] org.apache.spark.sql.execution.SparkPlan$$anonfun$6.apply(scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$6) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:15 INFO  SparkContext:54 - Starting job: load at UseCase5Test.java:16
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Got job 0 (load at UseCase5Test.java:16) with 1 output partitions
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (load at UseCase5Test.java:16)
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - submitStage(ResultStage 0 (name=load at UseCase5Test.java:16;jobs=0))
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at load at UseCase5Test.java:16), which has no missing parents
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 0)
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 8.9 KB, free 1970.2 MB)
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_1 locally took  0 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_1 without replication took  0 ms
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1970.1 MB)
2022-02-09 13:09:15 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 4.6 KB, free: 1970.4 MB)
2022-02-09 13:09:15 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_1_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Told master about block broadcast_1_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_1_piece0 locally took  0 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_1_piece0 without replication took  0 ms
2022-02-09 13:09:15 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at load at UseCase5Test.java:16) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:15 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - Epoch for TaskSet 0.0: 0
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-02-09 13:09:15 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2022-02-09 13:09:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8355 bytes)
2022-02-09 13:09:15 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2022-02-09 13:09:15 DEBUG BlockManager:58 - Getting local block broadcast_1
2022-02-09 13:09:15 DEBUG BlockManager:58 - Level for block broadcast_1 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:15 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-09 13:09:15 DEBUG GenerateUnsafeProjection:58 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:15 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:15 INFO  CodeGenerator:54 - Code generated in 12.5351 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Getting local block broadcast_0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:15 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1283 bytes result sent to driver
2022-02-09 13:09:15 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_0.0, runningTasks: 0
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 174 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-02-09 13:09:15 INFO  DAGScheduler:54 - ResultStage 0 (load at UseCase5Test.java:16) finished in 0.268 s
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - After removal of stage 0, remaining stages = 0
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Job 0 finished: load at UseCase5Test.java:16, took 0.320631 s
2022-02-09 13:09:15 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#8: java.lang.String   DeserializeToObject cast(value#0 as string).toString, obj#8: java.lang.String
 +- Project [value#0]                                                                                                                                                     +- Project [value#0]
    +- Relation[value#0] text                                                                                                                                                +- Relation[value#0] text
          
2022-02-09 13:09:15 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
!DeserializeToObject cast(value#0 as string).toString, obj#8: java.lang.String   DeserializeToObject value#0.toString, obj#8: java.lang.String
!+- Project [value#0]                                                            +- Relation[value#0] text
!   +- Relation[value#0] text                                                    
          
2022-02-09 13:09:15 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2022-02-09 13:09:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2022-02-09 13:09:15 INFO  FileSourceScanExec:54 - Pushed Filters: 
2022-02-09 13:09:15 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }

2022-02-09 13:09:15 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }

2022-02-09 13:09:15 INFO  CodeGenerator:54 - Code generated in 14.8451 ms
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 221.9 KB, free 1969.9 MB)
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_2 locally took  16 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_2 without replication took  16 ms
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1969.9 MB)
2022-02-09 13:09:15 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.4 MB)
2022-02-09 13:09:15 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_2_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Told master about block broadcast_2_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_2_piece0 locally took  16 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_2_piece0 without replication took  16 ms
2022-02-09 13:09:15 INFO  SparkContext:54 - Created broadcast 2 from load at UseCase5Test.java:16
2022-02-09 13:09:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8388788 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$rdd$1) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.Dataset$$anonfun$rdd$1.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$rdd$1.objectType$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$rdd$1.apply(java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$rdd$1.apply(scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.Dataset$$anonfun$rdd$1$$anonfun$apply$16
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$rdd$1) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 3
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final scala.Option org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.maybeFirstLine$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.execution.datasources.csv.CSVOptions org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.parsedOptions$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.apply(java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.apply(scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9$$anonfun$apply$3
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.execution.datasources.csv.CSVOptions org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.options$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType[] org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.apply(org.apache.spark.sql.types.DataType[],java.lang.String[])
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType[] org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.apply(org.apache.spark.sql.types.DataType[],org.apache.spark.sql.types.DataType[])
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3) is now cleaned +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$36) +++
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$36.serialVersionUID
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$36.processPartition$1
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$36.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$36.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:15 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$36) is now cleaned +++
2022-02-09 13:09:15 INFO  SparkContext:54 - Starting job: load at UseCase5Test.java:16
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Got job 1 (load at UseCase5Test.java:16) with 1 output partitions
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (load at UseCase5Test.java:16)
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - submitStage(ResultStage 1 (name=load at UseCase5Test.java:16;jobs=1))
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[9] at load at UseCase5Test.java:16), which has no missing parents
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 1)
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 13.9 KB, free 1969.9 MB)
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_3 locally took  0 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_3 without replication took  0 ms
2022-02-09 13:09:15 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KB, free 1969.9 MB)
2022-02-09 13:09:15 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 7.5 KB, free: 1970.3 MB)
2022-02-09 13:09:15 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_3_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Told master about block broadcast_3_piece0
2022-02-09 13:09:15 DEBUG BlockManager:58 - Put block broadcast_3_piece0 locally took  0 ms
2022-02-09 13:09:15 DEBUG BlockManager:58 - Putting block broadcast_3_piece0 without replication took  0 ms
2022-02-09 13:09:15 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at load at UseCase5Test.java:16) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:15 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - Epoch for TaskSet 1.0: 0
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
2022-02-09 13:09:15 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-02-09 13:09:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8355 bytes)
2022-02-09 13:09:15 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)
2022-02-09 13:09:15 DEBUG BlockManager:58 - Getting local block broadcast_3
2022-02-09 13:09:15 DEBUG BlockManager:58 - Level for block broadcast_3 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:15 DEBUG GenerateSafeProjection:58 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:15 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-09 13:09:15 DEBUG GenerateUnsafeProjection:58 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:15 DEBUG BlockManager:58 - Getting local block broadcast_2
2022-02-09 13:09:15 DEBUG BlockManager:58 - Level for block broadcast_2 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:15 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-09 13:09:15 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1438 bytes result sent to driver
2022-02-09 13:09:15 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_1.0, runningTasks: 0
2022-02-09 13:09:15 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 32 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-02-09 13:09:15 INFO  DAGScheduler:54 - ResultStage 1 (load at UseCase5Test.java:16) finished in 0.048 s
2022-02-09 13:09:15 DEBUG DAGScheduler:58 - After removal of stage 1, remaining stages = 0
2022-02-09 13:09:15 INFO  DAGScheduler:54 - Job 1 finished: load at UseCase5Test.java:16, took 0.056313 s
2022-02-09 13:09:16 INFO  InMemoryFileIndex:54 - It took 1 ms to list leaf files for 1 paths.
2022-02-09 13:09:16 INFO  InMemoryFileIndex:54 - It took 2 ms to list leaf files for 2 paths.
2022-02-09 13:09:16 DEBUG Analyzer$ResolveReferences:58 - Resolving 'value to value#14
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'Project [unresolvedalias('value, None)]   Project [value#14]
 +- Relation[value#14] text                 +- Relation[value#14] text
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#18: java.lang.String   DeserializeToObject cast(value#14 as string).toString, obj#18: java.lang.String
 +- LocalRelation <empty>, [value#14]                                                                                                                                      +- LocalRelation <empty>, [value#14]
          
2022-02-09 13:09:16 DEBUG Analyzer$ResolveReferences:58 - Resolving 'value to value#14
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'Filter (length(trim('value, None)) > 0)   Filter (length(trim(value#14, None)) > 0)
 +- Project [value#14]                      +- Project [value#14]
    +- Relation[value#14] text                 +- Relation[value#14] text
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#19: java.lang.String   DeserializeToObject cast(value#14 as string).toString, obj#19: java.lang.String
 +- LocalRelation <empty>, [value#14]                                                                                                                                      +- LocalRelation <empty>, [value#14]
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#20: java.lang.String   DeserializeToObject cast(value#14 as string).toString, obj#20: java.lang.String
 +- LocalRelation <empty>, [value#14]                                                                                                                                      +- LocalRelation <empty>, [value#14]
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 1                                     GlobalLimit 1
 +- LocalLimit 1                                   +- LocalLimit 1
    +- Filter (length(trim(value#14, None)) > 0)      +- Filter (length(trim(value#14, None)) > 0)
!      +- Project [value#14]                             +- Relation[value#14] text
!         +- Relation[value#14] text               
          
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#14, None)) > 0)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: 
2022-02-09 13:09:16 DEBUG GenerateSafeProjection:58 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:16 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 221.9 KB, free 1969.7 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_4 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_4 without replication took  0 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1969.7 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_4_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_4_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_4_piece0 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_4_piece0 without replication took  0 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 4 from load at UseCase5Test.java:17
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8390764 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$5) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.SparkPlan$$anonfun$5.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final byte[] org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(scala.Tuple2)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$5) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$6) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.SparkPlan$$anonfun$6.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.SparkPlan$$anonfun$6.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final byte[] org.apache.spark.sql.execution.SparkPlan$$anonfun$6.apply(scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$6) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:16 INFO  SparkContext:54 - Starting job: load at UseCase5Test.java:17
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Got job 2 (load at UseCase5Test.java:17) with 1 output partitions
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Final stage: ResultStage 2 (load at UseCase5Test.java:17)
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitStage(ResultStage 2 (name=load at UseCase5Test.java:17;jobs=2))
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting ResultStage 2 (MapPartitionsRDD[13] at load at UseCase5Test.java:17), which has no missing parents
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 2)
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_5 stored as values in memory (estimated size 8.9 KB, free 1969.6 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_5 locally took  16 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_5 without replication took  16 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1969.6 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_5_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 4.6 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_5_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_5_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_5_piece0 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_5_piece0 without replication took  0 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 5 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at load at UseCase5Test.java:17) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 1 tasks
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Epoch for TaskSet 2.0: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 2.0: NO_PREF, ANY
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2022-02-09 13:09:16 INFO  Executor:54 - Running task 0.0 in stage 2.0 (TID 2)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_5
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_5 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-09 13:09:16 DEBUG GenerateUnsafeProjection:58 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_4
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_4 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 INFO  Executor:54 - Finished task 0.0 in stage 2.0 (TID 2). 1205 bytes result sent to driver
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_2.0, runningTasks: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 2) in 15 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-02-09 13:09:16 INFO  DAGScheduler:54 - ResultStage 2 (load at UseCase5Test.java:17) finished in 0.031 s
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - After removal of stage 2, remaining stages = 0
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Job 2 finished: load at UseCase5Test.java:17, took 0.026116 s
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#22: java.lang.String   DeserializeToObject cast(value#14 as string).toString, obj#22: java.lang.String
 +- Project [value#14]                                                                                                                                                     +- Project [value#14]
    +- Relation[value#14] text                                                                                                                                                +- Relation[value#14] text
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
!DeserializeToObject cast(value#14 as string).toString, obj#22: java.lang.String   DeserializeToObject value#14.toString, obj#22: java.lang.String
!+- Project [value#14]                                                             +- Relation[value#14] text
!   +- Relation[value#14] text                                                     
          
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: 
2022-02-09 13:09:16 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }

2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_6 stored as values in memory (estimated size 221.9 KB, free 1969.4 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_6 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_6 without replication took  0 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_6_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1969.4 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_6_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_6_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_6_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_6_piece0 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_6_piece0 without replication took  0 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 6 from load at UseCase5Test.java:17
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8390764 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$rdd$1) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.Dataset$$anonfun$rdd$1.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$rdd$1.objectType$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$rdd$1.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$rdd$1.apply(scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.Dataset$$anonfun$rdd$1$$anonfun$apply$16
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$rdd$1) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final scala.Option org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.maybeFirstLine$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.execution.datasources.csv.CSVOptions org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.parsedOptions$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.apply(scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9$$anonfun$apply$3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.execution.datasources.csv.CSVOptions org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.options$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType[] org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.apply(org.apache.spark.sql.types.DataType[],java.lang.String[])
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType[] org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.apply(org.apache.spark.sql.types.DataType[],org.apache.spark.sql.types.DataType[])
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$36) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$36.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$36.processPartition$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$36.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$36.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$36) is now cleaned +++
2022-02-09 13:09:16 INFO  SparkContext:54 - Starting job: load at UseCase5Test.java:17
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Got job 3 (load at UseCase5Test.java:17) with 1 output partitions
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (load at UseCase5Test.java:17)
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitStage(ResultStage 3 (name=load at UseCase5Test.java:17;jobs=3))
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting ResultStage 3 (MapPartitionsRDD[19] at load at UseCase5Test.java:17), which has no missing parents
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 3)
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_7 stored as values in memory (estimated size 13.9 KB, free 1969.4 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_7 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_7 without replication took  0 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.5 KB, free 1969.4 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_7_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 7.5 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_7_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_7_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_7_piece0 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_7_piece0 without replication took  0 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 7 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[19] at load at UseCase5Test.java:17) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 1 tasks
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Epoch for TaskSet 3.0: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 3.0: NO_PREF, ANY
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 8354 bytes)
2022-02-09 13:09:16 INFO  Executor:54 - Running task 0.0 in stage 3.0 (TID 3)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_7
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_7 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 DEBUG GenerateSafeProjection:58 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:16 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-09 13:09:16 DEBUG GenerateUnsafeProjection:58 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_6
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_6 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-09 13:09:16 INFO  Executor:54 - Finished task 0.0 in stage 3.0 (TID 3). 1443 bytes result sent to driver
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_3.0, runningTasks: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 3) in 31 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2022-02-09 13:09:16 INFO  DAGScheduler:54 - ResultStage 3 (load at UseCase5Test.java:17) finished in 0.047 s
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - After removal of stage 3, remaining stages = 0
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Job 3 finished: load at UseCase5Test.java:17, took 0.046969 s
2022-02-09 13:09:16 INFO  InMemoryFileIndex:54 - It took 1 ms to list leaf files for 1 paths.
2022-02-09 13:09:16 INFO  InMemoryFileIndex:54 - It took 1 ms to list leaf files for 2 paths.
2022-02-09 13:09:16 DEBUG Analyzer$ResolveReferences:58 - Resolving 'value to value#30
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'Project [unresolvedalias('value, None)]   Project [value#30]
 +- Relation[value#30] text                 +- Relation[value#30] text
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#34: java.lang.String   DeserializeToObject cast(value#30 as string).toString, obj#34: java.lang.String
 +- LocalRelation <empty>, [value#30]                                                                                                                                      +- LocalRelation <empty>, [value#30]
          
2022-02-09 13:09:16 DEBUG Analyzer$ResolveReferences:58 - Resolving 'value to value#30
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'Filter (length(trim('value, None)) > 0)   Filter (length(trim(value#30, None)) > 0)
 +- Project [value#30]                      +- Project [value#30]
    +- Relation[value#30] text                 +- Relation[value#30] text
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#35: java.lang.String   DeserializeToObject cast(value#30 as string).toString, obj#35: java.lang.String
 +- LocalRelation <empty>, [value#30]                                                                                                                                      +- LocalRelation <empty>, [value#30]
          
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(96)
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#36: java.lang.String   DeserializeToObject cast(value#30 as string).toString, obj#36: java.lang.String
 +- LocalRelation <empty>, [value#30]                                                                                                                                      +- LocalRelation <empty>, [value#30]
          
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 96
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 96
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(121)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 121
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 121
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(22)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 22
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 22
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(81)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 81
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 81
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(92)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 92
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 92
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(29)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 29
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 29
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(17)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 17
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 17
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(77)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 77
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 77
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(27)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 27
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 27
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(89)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 89
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 89
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(55)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 55
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 55
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(79)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 79
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 79
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(5)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning broadcast 5
2022-02-09 13:09:16 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 5
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
 GlobalLimit 1                                     GlobalLimit 1
 +- LocalLimit 1                                   +- LocalLimit 1
    +- Filter (length(trim(value#30, None)) > 0)      +- Filter (length(trim(value#30, None)) > 0)
!      +- Project [value#30]                             +- Relation[value#30] text
!         +- Relation[value#30] text               
          
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 5
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing broadcast 5
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_5
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_5 of size 9144 dropped from memory (free 2065057979)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_5_piece0
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_5_piece0 of size 4742 dropped from memory (free 2065062721)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: (length(trim(value#30, None)) > 0)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: 
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Removed broadcast_5_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 4.6 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_5_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_5_piece0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 5, response is 0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaned broadcast 5
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(1)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning broadcast 1
2022-02-09 13:09:16 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 1
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 1
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing broadcast 1
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_1
2022-02-09 13:09:16 DEBUG GenerateSafeProjection:58 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_1 of size 9144 dropped from memory (free 2065071865)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_1_piece0
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_1_piece0 of size 4741 dropped from memory (free 2065076606)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Removed broadcast_1_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 4.6 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_1_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_1_piece0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 1, response is 0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaned broadcast 1
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(6)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning broadcast 6
2022-02-09 13:09:16 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 6
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 6
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing broadcast 6
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_6_piece0
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_6_piece0 of size 21172 dropped from memory (free 2065097778)
2022-02-09 13:09:16 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 026 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       do {
/* 029 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 030 */         UTF8String scan_value_0 = scan_isNull_0 ?
/* 031 */         null : (scan_row_0.getUTF8String(0));
/* 032 */
/* 033 */         boolean filter_isNull_0 = true;
/* 034 */         boolean filter_value_0 = false;
/* 035 */         boolean filter_isNull_2 = false;
/* 036 */         UTF8String filter_value_2 = null;
/* 037 */         if (scan_isNull_0) {
/* 038 */           filter_isNull_2 = true;
/* 039 */         } else {
/* 040 */           filter_value_2 = scan_value_0.trim();
/* 041 */         }
/* 042 */         boolean filter_isNull_1 = filter_isNull_2;
/* 043 */         int filter_value_1 = -1;
/* 044 */
/* 045 */         if (!filter_isNull_2) {
/* 046 */           filter_value_1 = (filter_value_2).numChars();
/* 047 */         }
/* 048 */         if (!filter_isNull_1) {
/* 049 */           filter_isNull_0 = false; // resultCode could change nullability.
/* 050 */           filter_value_0 = filter_value_1 > 0;
/* 051 */
/* 052 */         }
/* 053 */         if (filter_isNull_0 || !filter_value_0) continue;
/* 054 */
/* 055 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 056 */
/* 057 */         filter_mutableStateArray_0[0].reset();
/* 058 */
/* 059 */         filter_mutableStateArray_0[0].zeroOutNullBytes();
/* 060 */
/* 061 */         if (scan_isNull_0) {
/* 062 */           filter_mutableStateArray_0[0].setNullAt(0);
/* 063 */         } else {
/* 064 */           filter_mutableStateArray_0[0].write(0, scan_value_0);
/* 065 */         }
/* 066 */         append((filter_mutableStateArray_0[0].getRow()));
/* 067 */
/* 068 */       } while(false);
/* 069 */       if (shouldStop()) return;
/* 070 */     }
/* 071 */   }
/* 072 */
/* 073 */ }

2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Removed broadcast_6_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_6_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_6_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_6
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_6 of size 227232 dropped from memory (free 2065325010)
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 6, response is 0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaned broadcast 6
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(6)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 6
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 6
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(62)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 62
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 62
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(40)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 40
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 40
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(11)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 11
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 11
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(86)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 86
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 86
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(112)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 112
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 112
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_8 stored as values in memory (estimated size 221.9 KB, free 1969.4 MB)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(65)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 65
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 65
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(87)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 87
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 87
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(69)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 69
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 69
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(63)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 63
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 63
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(117)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 117
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 117
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(18)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 18
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 18
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(82)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 82
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 82
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(97)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 97
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 97
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(38)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 38
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 38
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(57)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 57
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 57
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(14)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_8 locally took  5 ms
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 14
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_8 without replication took  5 ms
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 14
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(37)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 37
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 37
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(44)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 44
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 44
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(8)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 8
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 8
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(85)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 85
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 85
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(119)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 119
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 119
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(90)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 90
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 90
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(20)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 20
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 20
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(53)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 53
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 53
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(76)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 76
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 76
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(83)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 83
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 83
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(39)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 39
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 39
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(21)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 21
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 21
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(111)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 111
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 111
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(58)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 58
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 58
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(109)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 109
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 109
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(103)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 103
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 103
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(24)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 24
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 24
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(59)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 59
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 59
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(52)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 52
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 52
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(99)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 99
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 99
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(46)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 46
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 46
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(71)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 71
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 71
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(66)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 66
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 66
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(94)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 94
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 94
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(41)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 41
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 41
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(10)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 10
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 10
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(12)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 12
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 12
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(54)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 54
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 54
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(104)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 104
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 104
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(7)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning broadcast 7
2022-02-09 13:09:16 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 7
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 7
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing broadcast 7
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_7
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_7 of size 14256 dropped from memory (free 2065112034)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_7_piece0
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_7_piece0 of size 7725 dropped from memory (free 2065119759)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Removed broadcast_7_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 7.5 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_7_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_7_piece0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 7, response is 0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaned broadcast 7
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_8_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1969.4 MB)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(48)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 48
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 48
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(93)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 93
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 93
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(7)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 7
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 7
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(73)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 73
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 73
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(95)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 95
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 95
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(26)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 26
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 26
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(100)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 100
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 100
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(9)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 9
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 9
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(50)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 50
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 50
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(105)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 105
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 105
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(72)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 72
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_8_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 72
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(91)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 91
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_8_piece0
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 91
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_8_piece0
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(13)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_8_piece0 locally took  3 ms
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 13
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_8_piece0 without replication took  3 ms
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 13
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(102)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 102
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 102
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(84)
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 8 from load at UseCase5Test.java:18
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 84
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 84
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8737102 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(42)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 42
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 42
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(30)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 30
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 30
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(60)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 60
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 60
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(75)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 75
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 75
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(110)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 110
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 110
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(78)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 78
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 78
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(43)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 43
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 43
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(28)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 28
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 28
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(67)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 67
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 67
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(116)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 116
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 116
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(25)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 25
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 25
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(108)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 108
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 108
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(47)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 47
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 47
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(36)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 36
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 36
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(64)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 64
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 64
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(23)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 23
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 23
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(106)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 106
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 106
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(70)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 70
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 70
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(3)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning broadcast 3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 3
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing broadcast 3
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_3_piece0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_3_piece0 of size 7715 dropped from memory (free 2065106302)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Removed broadcast_3_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 7.5 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_3_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_3_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_3 of size 14232 dropped from memory (free 2065120534)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 3, response is 0
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaned broadcast 3
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(101)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 101
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 101
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(74)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 74
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$5) +++
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 74
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(115)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 115
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 115
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(4)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning broadcast 4
2022-02-09 13:09:16 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.SparkPlan$$anonfun$5.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing broadcast 4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final byte[] org.apache.spark.sql.execution.SparkPlan$$anonfun$5.apply(scala.Tuple2)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_4_piece0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_4_piece0 of size 21172 dropped from memory (free 2065141706)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Removed broadcast_4_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_4_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_4_piece0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG BlockManager:58 - Removing block broadcast_4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG MemoryStore:58 - Block broadcast_4 of size 227232 dropped from memory (free 2065368938)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$5) is now cleaned +++
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 4, response is 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$6) +++
2022-02-09 13:09:16 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaned broadcast 4
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(16)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 16
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.SparkPlan$$anonfun$6.serialVersionUID
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 16
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(68)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.SparkPlan$$anonfun$6.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 68
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final byte[] org.apache.spark.sql.execution.SparkPlan$$anonfun$6.apply(scala.collection.Iterator)
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 68
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(114)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 114
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 114
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(49)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 49
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 49
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(107)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 107
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 107
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(80)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 80
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 80
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(19)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 19
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 19
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(56)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 56
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 56
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(51)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 51
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 51
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(45)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 45
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 45
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.SparkPlan$$anonfun$6) is now cleaned +++
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(118)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 118
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 118
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(15)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 15
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 15
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(61)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 61
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 61
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(120)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 120
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 120
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(88)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 88
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 88
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(98)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 98
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 98
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(113)
2022-02-09 13:09:16 DEBUG ContextCleaner:58 - Cleaning accumulator 113
2022-02-09 13:09:16 INFO  ContextCleaner:54 - Cleaned accumulator 113
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:16 INFO  SparkContext:54 - Starting job: load at UseCase5Test.java:18
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Got job 4 (load at UseCase5Test.java:18) with 1 output partitions
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Final stage: ResultStage 4 (load at UseCase5Test.java:18)
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitStage(ResultStage 4 (name=load at UseCase5Test.java:18;jobs=4))
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting ResultStage 4 (MapPartitionsRDD[23] at load at UseCase5Test.java:18), which has no missing parents
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 4)
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_9 stored as values in memory (estimated size 8.9 KB, free 1969.7 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_9 locally took  16 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_9 without replication took  16 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.6 KB, free 1969.7 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_9_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 4.6 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_9_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_9_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_9_piece0 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_9_piece0 without replication took  0 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 9 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at load at UseCase5Test.java:18) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Adding task set 4.0 with 1 tasks
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Epoch for TaskSet 4.0: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 4.0: NO_PREF, ANY
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 8352 bytes)
2022-02-09 13:09:16 INFO  Executor:54 - Running task 0.0 in stage 4.0 (TID 4)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_9
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_9 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-09 13:09:16 DEBUG GenerateUnsafeProjection:58 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_8
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_8 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 INFO  Executor:54 - Finished task 0.0 in stage 4.0 (TID 4). 1234 bytes result sent to driver
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_4.0, runningTasks: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 4.0 (TID 4) in 17 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2022-02-09 13:09:16 INFO  DAGScheduler:54 - ResultStage 4 (load at UseCase5Test.java:18) finished in 0.033 s
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - After removal of stage 4, remaining stages = 0
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Job 4 finished: load at UseCase5Test.java:18, took 0.029540 s
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Resolution ===
!'DeserializeToObject unresolveddeserializer(upcast(getcolumnbyordinal(0, StringType), StringType, - root class: "java.lang.String").toString), obj#38: java.lang.String   DeserializeToObject cast(value#30 as string).toString, obj#38: java.lang.String
 +- Project [value#30]                                                                                                                                                     +- Project [value#30]
    +- Relation[value#30] text                                                                                                                                                +- Relation[value#30] text
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
!DeserializeToObject cast(value#30 as string).toString, obj#38: java.lang.String   DeserializeToObject value#30.toString, obj#38: java.lang.String
!+- Project [value#30]                                                             +- Relation[value#30] text
!   +- Relation[value#30] text                                                     
          
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: 
2022-02-09 13:09:16 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 010 */
/* 011 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 012 */     this.references = references;
/* 013 */   }
/* 014 */
/* 015 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 016 */     partitionIndex = index;
/* 017 */     this.inputs = inputs;
/* 018 */     scan_mutableStateArray_0[0] = inputs[0];
/* 019 */
/* 020 */   }
/* 021 */
/* 022 */   protected void processNext() throws java.io.IOException {
/* 023 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 024 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 025 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 026 */       append(scan_row_0);
/* 027 */       if (shouldStop()) return;
/* 028 */     }
/* 029 */   }
/* 030 */
/* 031 */ }

2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_10 stored as values in memory (estimated size 221.9 KB, free 1969.5 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_10 locally took  16 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_10 without replication took  16 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_10_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1969.4 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_10_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_10_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_10_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_10_piece0 locally took  15 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_10_piece0 without replication took  15 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 10 from load at UseCase5Test.java:18
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 8737102 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.Dataset$$anonfun$rdd$1) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.Dataset$$anonfun$rdd$1.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType org.apache.spark.sql.Dataset$$anonfun$rdd$1.objectType$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.Dataset$$anonfun$rdd$1.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.Dataset$$anonfun$rdd$1.apply(scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.Dataset$$anonfun$rdd$1$$anonfun$apply$16
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.Dataset$$anonfun$rdd$1) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final scala.Option org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.maybeFirstLine$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.execution.datasources.csv.CSVOptions org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.parsedOptions$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.apply(java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9.apply(scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9$$anonfun$apply$3
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.sql.execution.datasources.csv.TextInputCSVDataSource$$anonfun$9) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.execution.datasources.csv.CSVOptions org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.options$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType[] org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2.apply(org.apache.spark.sql.types.DataType[],java.lang.String[])
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$2) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.types.DataType[] org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3.apply(org.apache.spark.sql.types.DataType[],org.apache.spark.sql.types.DataType[])
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.datasources.csv.CSVInferSchema$$anonfun$3) is now cleaned +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$36) +++
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$36.serialVersionUID
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$36.processPartition$1
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$36.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$36.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:16 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$36) is now cleaned +++
2022-02-09 13:09:16 INFO  SparkContext:54 - Starting job: load at UseCase5Test.java:18
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Got job 5 (load at UseCase5Test.java:18) with 1 output partitions
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Final stage: ResultStage 5 (load at UseCase5Test.java:18)
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitStage(ResultStage 5 (name=load at UseCase5Test.java:18;jobs=5))
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting ResultStage 5 (MapPartitionsRDD[29] at load at UseCase5Test.java:18), which has no missing parents
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 5)
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_11 stored as values in memory (estimated size 14.0 KB, free 1969.4 MB)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_11 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_11 without replication took  0 ms
2022-02-09 13:09:16 INFO  MemoryStore:54 - Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.6 KB, free 1969.4 MB)
2022-02-09 13:09:16 INFO  BlockManagerInfo:54 - Added broadcast_11_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 7.6 KB, free: 1970.3 MB)
2022-02-09 13:09:16 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_11_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Told master about block broadcast_11_piece0
2022-02-09 13:09:16 DEBUG BlockManager:58 - Put block broadcast_11_piece0 locally took  0 ms
2022-02-09 13:09:16 DEBUG BlockManager:58 - Putting block broadcast_11_piece0 without replication took  0 ms
2022-02-09 13:09:16 INFO  SparkContext:54 - Created broadcast 11 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at load at UseCase5Test.java:18) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Adding task set 5.0 with 1 tasks
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Epoch for TaskSet 5.0: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 5.0: NO_PREF, ANY
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 8352 bytes)
2022-02-09 13:09:16 INFO  Executor:54 - Running task 0.0 in stage 5.0 (TID 5)
2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_11
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_11 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 DEBUG GenerateSafeProjection:58 - code for input[0, string, true].toString:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificSafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificSafeProjection extends org.apache.spark.sql.catalyst.expressions.codegen.BaseProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private InternalRow mutableRow;
/* 009 */
/* 010 */
/* 011 */   public SpecificSafeProjection(Object[] references) {
/* 012 */     this.references = references;
/* 013 */     mutableRow = (InternalRow) references[references.length - 1];
/* 014 */
/* 015 */   }
/* 016 */
/* 017 */   public void initialize(int partitionIndex) {
/* 018 */
/* 019 */   }
/* 020 */
/* 021 */   public java.lang.Object apply(java.lang.Object _i) {
/* 022 */     InternalRow i = (InternalRow) _i;
/* 023 */     boolean isNull_1 = i.isNullAt(0);
/* 024 */     UTF8String value_1 = isNull_1 ?
/* 025 */     null : (i.getUTF8String(0));
/* 026 */     boolean isNull_0 = true;
/* 027 */     java.lang.String value_0 = null;
/* 028 */     if (!isNull_1) {
/* 029 */
/* 030 */       isNull_0 = false;
/* 031 */       if (!isNull_0) {
/* 032 */
/* 033 */         Object funcResult_0 = null;
/* 034 */         funcResult_0 = value_1.toString();
/* 035 */         value_0 = (java.lang.String) funcResult_0;
/* 036 */
/* 037 */       }
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableRow.setNullAt(0);
/* 041 */     } else {
/* 042 */
/* 043 */       mutableRow.update(0, value_0);
/* 044 */     }
/* 045 */
/* 046 */     return mutableRow;
/* 047 */   }
/* 048 */
/* 049 */
/* 050 */ }

2022-02-09 13:09:16 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-09 13:09:16 DEBUG GenerateUnsafeProjection:58 - code for input[0, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     UTF8String value_0 = isNull_0 ?
/* 033 */     null : (i.getUTF8String(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:16 DEBUG BlockManager:58 - Getting local block broadcast_10
2022-02-09 13:09:16 DEBUG BlockManager:58 - Level for block broadcast_10 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:16 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-09 13:09:16 INFO  Executor:54 - Finished task 0.0 in stage 5.0 (TID 5). 1645 bytes result sent to driver
2022-02-09 13:09:16 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_5.0, runningTasks: 0
2022-02-09 13:09:16 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 5.0 (TID 5) in 121 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2022-02-09 13:09:16 INFO  DAGScheduler:54 - ResultStage 5 (load at UseCase5Test.java:18) finished in 0.121 s
2022-02-09 13:09:16 DEBUG DAGScheduler:58 - After removal of stage 5, remaining stages = 0
2022-02-09 13:09:16 INFO  DAGScheduler:54 - Job 5 finished: load at UseCase5Test.java:18, took 0.129022 s
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Cleanup ===
 Aggregate [department_id#10, department_name#11], [department_id#10, department_name#11, count(product_category_id#41) AS count(product_category_id)#112L]   Aggregate [department_id#10, department_name#11], [department_id#10, department_name#11, count(product_category_id#41) AS count(product_category_id)#112L]
 +- Join Inner, (category_id#24 = product_category_id#41)                                                                                                     +- Join Inner, (category_id#24 = product_category_id#41)
    :- Join Inner, (department_id#10 = category_department_id#25)                                                                                                :- Join Inner, (department_id#10 = category_department_id#25)
    :  :- Relation[department_id#10,department_name#11] csv                                                                                                      :  :- Relation[department_id#10,department_name#11] csv
    :  +- Relation[category_id#24,category_department_id#25,category_name#26] csv                                                                                :  +- Relation[category_id#24,category_department_id#25,category_name#26] csv
    +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv                               +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$1:58 - 
=== Result of Batch Cleanup ===
 Aggregate [count(1) AS count#120L]                                                                                                                                 Aggregate [count(1) AS count#120L]
 +- Sort [department_id#10 ASC NULLS FIRST], true                                                                                                                   +- Sort [department_id#10 ASC NULLS FIRST], true
    +- Aggregate [department_id#10, department_name#11], [department_id#10, department_name#11, count(product_category_id#41) AS count(product_category_id)#112L]      +- Aggregate [department_id#10, department_name#11], [department_id#10, department_name#11, count(product_category_id#41) AS count(product_category_id)#112L]
       +- Join Inner, (category_id#24 = product_category_id#41)                                                                                                           +- Join Inner, (category_id#24 = product_category_id#41)
          :- Join Inner, (department_id#10 = category_department_id#25)                                                                                                      :- Join Inner, (department_id#10 = category_department_id#25)
          :  :- Relation[department_id#10,department_name#11] csv                                                                                                            :  :- Relation[department_id#10,department_name#11] csv
          :  +- Relation[category_id#24,category_department_id#25,category_name#26] csv                                                                                      :  +- Relation[category_id#24,category_department_id#25,category_name#26] csv
          +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv                                     +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization before Inferring Filters ===
 Aggregate [count(1) AS count#120L]                                                                                                                                 Aggregate [count(1) AS count#120L]
!+- Sort [department_id#10 ASC NULLS FIRST], true                                                                                                                   +- Project
!   +- Aggregate [department_id#10, department_name#11], [department_id#10, department_name#11, count(product_category_id#41) AS count(product_category_id)#112L]      +- Sort [department_id#10 ASC NULLS FIRST], true
!      +- Join Inner, (category_id#24 = product_category_id#41)                                                                                                           +- Aggregate [department_id#10, department_name#11], [department_id#10]
!         :- Join Inner, (department_id#10 = category_department_id#25)                                                                                                      +- Project [department_id#10, department_name#11]
!         :  :- Relation[department_id#10,department_name#11] csv                                                                                                               +- Join Inner, (category_id#24 = product_category_id#41)
!         :  +- Relation[category_id#24,category_department_id#25,category_name#26] csv                                                                                            :- Project [department_id#10, department_name#11, category_id#24]
!         +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv                                           :  +- Join Inner, (department_id#10 = category_department_id#25)
!                                                                                                                                                                                  :     :- Relation[department_id#10,department_name#11] csv
!                                                                                                                                                                                  :     +- Project [category_id#24, category_department_id#25]
!                                                                                                                                                                                  :        +- Relation[category_id#24,category_department_id#25,category_name#26] csv
!                                                                                                                                                                                  +- Project [product_category_id#41]
!                                                                                                                                                                                     +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Infer Filters ===
 Aggregate [count(1) AS count#120L]                                                                                                                 Aggregate [count(1) AS count#120L]
 +- Project                                                                                                                                         +- Project
    +- Sort [department_id#10 ASC NULLS FIRST], true                                                                                                   +- Sort [department_id#10 ASC NULLS FIRST], true
       +- Aggregate [department_id#10, department_name#11], [department_id#10]                                                                            +- Aggregate [department_id#10, department_name#11], [department_id#10]
          +- Project [department_id#10, department_name#11]                                                                                                  +- Project [department_id#10, department_name#11]
             +- Join Inner, (category_id#24 = product_category_id#41)                                                                                           +- Join Inner, (category_id#24 = product_category_id#41)
!               :- Project [department_id#10, department_name#11, category_id#24]                                                                                  :- Filter isnotnull(category_id#24)
!               :  +- Join Inner, (department_id#10 = category_department_id#25)                                                                                   :  +- Project [department_id#10, department_name#11, category_id#24]
!               :     :- Relation[department_id#10,department_name#11] csv                                                                                         :     +- Join Inner, (department_id#10 = category_department_id#25)
!               :     +- Project [category_id#24, category_department_id#25]                                                                                       :        :- Filter isnotnull(department_id#10)
!               :        +- Relation[category_id#24,category_department_id#25,category_name#26] csv                                                                :        :  +- Relation[department_id#10,department_name#11] csv
!               +- Project [product_category_id#41]                                                                                                                :        +- Filter isnotnull(category_department_id#25)
!                  +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv                  :           +- Project [category_id#24, category_department_id#25]
!                                                                                                                                                                  :              +- Relation[category_id#24,category_department_id#25,category_name#26] csv
!                                                                                                                                                                  +- Filter isnotnull(product_category_id#41)
!                                                                                                                                                                     +- Project [product_category_id#41]
!                                                                                                                                                                        +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv
          
2022-02-09 13:09:16 DEBUG BaseSessionStateBuilder$$anon$2:58 - 
=== Result of Batch Operator Optimization after Inferring Filters ===
 Aggregate [count(1) AS count#120L]                                                                                                                    Aggregate [count(1) AS count#120L]
 +- Project                                                                                                                                            +- Project
    +- Sort [department_id#10 ASC NULLS FIRST], true                                                                                                      +- Sort [department_id#10 ASC NULLS FIRST], true
       +- Aggregate [department_id#10, department_name#11], [department_id#10]                                                                               +- Aggregate [department_id#10, department_name#11], [department_id#10]
          +- Project [department_id#10, department_name#11]                                                                                                     +- Project [department_id#10, department_name#11]
             +- Join Inner, (category_id#24 = product_category_id#41)                                                                                              +- Join Inner, (category_id#24 = product_category_id#41)
!               :- Filter isnotnull(category_id#24)                                                                                                                   :- Project [department_id#10, department_name#11, category_id#24]
!               :  +- Project [department_id#10, department_name#11, category_id#24]                                                                                  :  +- Join Inner, (department_id#10 = category_department_id#25)
!               :     +- Join Inner, (department_id#10 = category_department_id#25)                                                                                   :     :- Filter isnotnull(department_id#10)
!               :        :- Filter isnotnull(department_id#10)                                                                                                        :     :  +- Relation[department_id#10,department_name#11] csv
!               :        :  +- Relation[department_id#10,department_name#11] csv                                                                                      :     +- Project [category_id#24, category_department_id#25]
!               :        +- Filter isnotnull(category_department_id#25)                                                                                               :        +- Filter (isnotnull(category_department_id#25) && isnotnull(category_id#24))
!               :           +- Project [category_id#24, category_department_id#25]                                                                                    :           +- Relation[category_id#24,category_department_id#25,category_name#26] csv
!               :              +- Relation[category_id#24,category_department_id#25,category_name#26] csv                                                             +- Project [product_category_id#41]
!               +- Filter isnotnull(product_category_id#41)                                                                                                              +- Filter isnotnull(product_category_id#41)
!                  +- Project [product_category_id#41]                                                                                                                      +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv
!                     +- Relation[product_id#40,product_category_id#41,product_name#42,product_description#43,product_price#44,product_image#45] csv   
          
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - Considering join on: Some((category_id#24 = product_category_id#41))
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - leftKeys:List(category_id#24) | rightKeys:List(product_category_id#41)
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - Considering join on: Some((category_id#24 = product_category_id#41))
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - leftKeys:List(category_id#24) | rightKeys:List(product_category_id#41)
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - Considering join on: Some((department_id#10 = category_department_id#25))
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - leftKeys:List(department_id#10) | rightKeys:List(category_department_id#25)
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - Considering join on: Some((department_id#10 = category_department_id#25))
2022-02-09 13:09:16 DEBUG ExtractEquiJoinKeys:58 - leftKeys:List(department_id#10) | rightKeys:List(category_department_id#25)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(department_id#10)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<department_id: int, department_name: string>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(department_id)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(category_department_id#25),isnotnull(category_id#24)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<category_id: int, category_department_id: int>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(category_department_id),IsNotNull(category_id)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Pruning directories with: 
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: isnotnull(product_category_id#41)
2022-02-09 13:09:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<product_category_id: int>
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(product_category_id)
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(none)
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(none),IsNotNull(none)
2022-02-09 13:09:16 INFO  FileSourceScanExec:54 - Pushed Filters: IsNotNull(none)
2022-02-09 13:09:17 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         int scan_value_0 = scan_isNull_0 ?
/* 032 */         -1 : (scan_row_0.getInt(0));
/* 033 */
/* 034 */         if (!(!scan_isNull_0)) continue;
/* 035 */
/* 036 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 037 */
/* 038 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 039 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 040 */         null : (scan_row_0.getUTF8String(1));
/* 041 */         filter_mutableStateArray_0[1].reset();
/* 042 */
/* 043 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 044 */
/* 045 */         if (false) {
/* 046 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 047 */         } else {
/* 048 */           filter_mutableStateArray_0[1].write(0, scan_value_0);
/* 049 */         }
/* 050 */
/* 051 */         if (scan_isNull_1) {
/* 052 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 053 */         } else {
/* 054 */           filter_mutableStateArray_0[1].write(1, scan_value_1);
/* 055 */         }
/* 056 */         append((filter_mutableStateArray_0[1].getRow()));
/* 057 */
/* 058 */       } while(false);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */
/* 063 */ }

2022-02-09 13:09:17 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         int scan_value_0 = scan_isNull_0 ?
/* 032 */         -1 : (scan_row_0.getInt(0));
/* 033 */
/* 034 */         if (!(!scan_isNull_0)) continue;
/* 035 */
/* 036 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 037 */
/* 038 */         filter_mutableStateArray_0[1].reset();
/* 039 */
/* 040 */         if (false) {
/* 041 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 042 */         } else {
/* 043 */           filter_mutableStateArray_0[1].write(0, scan_value_0);
/* 044 */         }
/* 045 */         append((filter_mutableStateArray_0[1].getRow()));
/* 046 */
/* 047 */       } while(false);
/* 048 */       if (shouldStop()) return;
/* 049 */     }
/* 050 */   }
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         int scan_value_0 = scan_isNull_0 ?
/* 032 */         -1 : (scan_row_0.getInt(0));
/* 033 */
/* 034 */         if (!(!scan_isNull_0)) continue;
/* 035 */
/* 036 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 037 */
/* 038 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 039 */         UTF8String scan_value_1 = scan_isNull_1 ?
/* 040 */         null : (scan_row_0.getUTF8String(1));
/* 041 */         filter_mutableStateArray_0[1].reset();
/* 042 */
/* 043 */         filter_mutableStateArray_0[1].zeroOutNullBytes();
/* 044 */
/* 045 */         if (false) {
/* 046 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 047 */         } else {
/* 048 */           filter_mutableStateArray_0[1].write(0, scan_value_0);
/* 049 */         }
/* 050 */
/* 051 */         if (scan_isNull_1) {
/* 052 */           filter_mutableStateArray_0[1].setNullAt(1);
/* 053 */         } else {
/* 054 */           filter_mutableStateArray_0[1].write(1, scan_value_1);
/* 055 */         }
/* 056 */         append((filter_mutableStateArray_0[1].getRow()));
/* 057 */
/* 058 */       } while(false);
/* 059 */       if (shouldStop()) return;
/* 060 */     }
/* 061 */   }
/* 062 */
/* 063 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage2(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=2
/* 006 */ final class GeneratedIteratorForCodegenStage2 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 010 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage2(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     scan_mutableStateArray_0[0] = inputs[0];
/* 020 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 022 */
/* 023 */   }
/* 024 */
/* 025 */   protected void processNext() throws java.io.IOException {
/* 026 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 027 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 028 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 029 */       do {
/* 030 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 031 */         int scan_value_0 = scan_isNull_0 ?
/* 032 */         -1 : (scan_row_0.getInt(0));
/* 033 */
/* 034 */         if (!(!scan_isNull_0)) continue;
/* 035 */
/* 036 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* numOutputRows */).add(1);
/* 037 */
/* 038 */         filter_mutableStateArray_0[1].reset();
/* 039 */
/* 040 */         if (false) {
/* 041 */           filter_mutableStateArray_0[1].setNullAt(0);
/* 042 */         } else {
/* 043 */           filter_mutableStateArray_0[1].write(0, scan_value_0);
/* 044 */         }
/* 045 */         append((filter_mutableStateArray_0[1].getRow()));
/* 046 */
/* 047 */       } while(false);
/* 048 */       if (shouldStop()) return;
/* 049 */     }
/* 050 */   }
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 16.1386 ms
2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 19.4871 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_12 stored as values in memory (estimated size 221.8 KB, free 1969.2 MB)
2022-02-09 13:09:17 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage6(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=6
/* 006 */ final class GeneratedIteratorForCodegenStage6 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage6(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while (inputadapter_input_0.hasNext() && !stopEarly()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 036 */
/* 037 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 038 */       if (shouldStop()) return;
/* 039 */     }
/* 040 */
/* 041 */   }
/* 042 */
/* 043 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 044 */     // do aggregate
/* 045 */     // common sub-expressions
/* 046 */
/* 047 */     // evaluate aggregate function
/* 048 */     long agg_value_3 = -1L;
/* 049 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 050 */     // update aggregation buffer
/* 051 */     agg_bufIsNull_0 = false;
/* 052 */     agg_bufValue_0 = agg_value_3;
/* 053 */
/* 054 */   }
/* 055 */
/* 056 */   protected void processNext() throws java.io.IOException {
/* 057 */     while (!agg_initAgg_0) {
/* 058 */       agg_initAgg_0 = true;
/* 059 */       long agg_beforeAgg_0 = System.nanoTime();
/* 060 */       agg_doAggregateWithoutKey_0();
/* 061 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 062 */
/* 063 */       // output the result
/* 064 */
/* 065 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 066 */       agg_mutableStateArray_0[0].reset();
/* 067 */
/* 068 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 069 */
/* 070 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 071 */       append((agg_mutableStateArray_0[0].getRow()));
/* 072 */     }
/* 073 */   }
/* 074 */
/* 075 */ }

2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_13 stored as values in memory (estimated size 221.8 KB, free 1969.0 MB)
2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage6(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=6
/* 006 */ final class GeneratedIteratorForCodegenStage6 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private scala.collection.Iterator inputadapter_input_0;
/* 013 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 014 */
/* 015 */   public GeneratedIteratorForCodegenStage6(Object[] references) {
/* 016 */     this.references = references;
/* 017 */   }
/* 018 */
/* 019 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 020 */     partitionIndex = index;
/* 021 */     this.inputs = inputs;
/* 022 */
/* 023 */     inputadapter_input_0 = inputs[0];
/* 024 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 025 */
/* 026 */   }
/* 027 */
/* 028 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 029 */     // initialize aggregation buffer
/* 030 */     agg_bufIsNull_0 = false;
/* 031 */     agg_bufValue_0 = 0L;
/* 032 */
/* 033 */     while (inputadapter_input_0.hasNext() && !stopEarly()) {
/* 034 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 035 */       long inputadapter_value_0 = inputadapter_row_0.getLong(0);
/* 036 */
/* 037 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0);
/* 038 */       if (shouldStop()) return;
/* 039 */     }
/* 040 */
/* 041 */   }
/* 042 */
/* 043 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, long agg_expr_0_0) throws java.io.IOException {
/* 044 */     // do aggregate
/* 045 */     // common sub-expressions
/* 046 */
/* 047 */     // evaluate aggregate function
/* 048 */     long agg_value_3 = -1L;
/* 049 */     agg_value_3 = agg_bufValue_0 + agg_expr_0_0;
/* 050 */     // update aggregation buffer
/* 051 */     agg_bufIsNull_0 = false;
/* 052 */     agg_bufValue_0 = agg_value_3;
/* 053 */
/* 054 */   }
/* 055 */
/* 056 */   protected void processNext() throws java.io.IOException {
/* 057 */     while (!agg_initAgg_0) {
/* 058 */       agg_initAgg_0 = true;
/* 059 */       long agg_beforeAgg_0 = System.nanoTime();
/* 060 */       agg_doAggregateWithoutKey_0();
/* 061 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 062 */
/* 063 */       // output the result
/* 064 */
/* 065 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 066 */       agg_mutableStateArray_0[0].reset();
/* 067 */
/* 068 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 069 */
/* 070 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 071 */       append((agg_mutableStateArray_0[0].getRow()));
/* 072 */     }
/* 073 */   }
/* 074 */
/* 075 */ }

2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_12 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_12 without replication took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_13 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_13 without replication took  0 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_12_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1969.0 MB)
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_13_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1968.9 MB)
2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 16.3025 ms
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_12_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_12_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_12_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_12_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_12_piece0 without replication took  0 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 12 from run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_13_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_13_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_13_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_13_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_13_piece0 without replication took  0 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 13 from run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4368551 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194394 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:17 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage5(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=5
/* 006 */ final class GeneratedIteratorForCodegenStage5 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private boolean sort_needToSort_0;
/* 013 */   private org.apache.spark.sql.execution.UnsafeExternalRowSorter sort_sorter_0;
/* 014 */   private org.apache.spark.executor.TaskMetrics sort_metrics_0;
/* 015 */   private scala.collection.Iterator<UnsafeRow> sort_sortedIter_0;
/* 016 */   private scala.collection.Iterator inputadapter_input_0;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage5(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */
/* 027 */     sort_needToSort_0 = true;
/* 028 */     sort_sorter_0 = ((org.apache.spark.sql.execution.SortExec) references[0] /* plan */).createSorter();
/* 029 */     sort_metrics_0 = org.apache.spark.TaskContext.get().taskMetrics();
/* 030 */     inputadapter_input_0 = inputs[0];
/* 031 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 032 */
/* 033 */   }
/* 034 */
/* 035 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 036 */     // initialize aggregation buffer
/* 037 */     agg_bufIsNull_0 = false;
/* 038 */     agg_bufValue_0 = 0L;
/* 039 */
/* 040 */     if (sort_needToSort_0) {
/* 041 */       long sort_spillSizeBefore_0 = sort_metrics_0.memoryBytesSpilled();
/* 042 */       sort_addToSorter_0();
/* 043 */       sort_sortedIter_0 = sort_sorter_0.sort();
/* 044 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* sortTime */).add(sort_sorter_0.getSortTimeNanos() / 1000000);
/* 045 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */).add(sort_sorter_0.getPeakMemoryUsage());
/* 046 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */).add(sort_metrics_0.memoryBytesSpilled() - sort_spillSizeBefore_0);
/* 047 */       sort_metrics_0.incPeakExecutionMemory(sort_sorter_0.getPeakMemoryUsage());
/* 048 */       sort_needToSort_0 = false;
/* 049 */     }
/* 050 */
/* 051 */     while (sort_sortedIter_0.hasNext()) {
/* 052 */       UnsafeRow sort_outputRow_0 = (UnsafeRow)sort_sortedIter_0.next();
/* 053 */
/* 054 */       agg_doConsume_0();
/* 055 */
/* 056 */       if (shouldStop()) return;
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void sort_addToSorter_0() throws java.io.IOException {
/* 062 */     while (inputadapter_input_0.hasNext() && !stopEarly()) {
/* 063 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 064 */       sort_sorter_0.insertRow((UnsafeRow)inputadapter_row_0);
/* 065 */       if (shouldStop()) return;
/* 066 */     }
/* 067 */
/* 068 */   }
/* 069 */
/* 070 */   private void agg_doConsume_0() throws java.io.IOException {
/* 071 */     // do aggregate
/* 072 */     // common sub-expressions
/* 073 */
/* 074 */     // evaluate aggregate function
/* 075 */     long agg_value_1 = -1L;
/* 076 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 077 */     // update aggregation buffer
/* 078 */     agg_bufIsNull_0 = false;
/* 079 */     agg_bufValue_0 = agg_value_1;
/* 080 */
/* 081 */   }
/* 082 */
/* 083 */   protected void processNext() throws java.io.IOException {
/* 084 */     while (!agg_initAgg_0) {
/* 085 */       agg_initAgg_0 = true;
/* 086 */       long agg_beforeAgg_0 = System.nanoTime();
/* 087 */       agg_doAggregateWithoutKey_0();
/* 088 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 089 */
/* 090 */       // output the result
/* 091 */
/* 092 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 093 */       agg_mutableStateArray_0[0].reset();
/* 094 */
/* 095 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 096 */
/* 097 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 098 */       append((agg_mutableStateArray_0[0].getRow()));
/* 099 */     }
/* 100 */   }
/* 101 */
/* 102 */ }

2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.serialVersionUID
2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage5(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=5
/* 006 */ final class GeneratedIteratorForCodegenStage5 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private boolean agg_bufIsNull_0;
/* 011 */   private long agg_bufValue_0;
/* 012 */   private boolean sort_needToSort_0;
/* 013 */   private org.apache.spark.sql.execution.UnsafeExternalRowSorter sort_sorter_0;
/* 014 */   private org.apache.spark.executor.TaskMetrics sort_metrics_0;
/* 015 */   private scala.collection.Iterator<UnsafeRow> sort_sortedIter_0;
/* 016 */   private scala.collection.Iterator inputadapter_input_0;
/* 017 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 018 */
/* 019 */   public GeneratedIteratorForCodegenStage5(Object[] references) {
/* 020 */     this.references = references;
/* 021 */   }
/* 022 */
/* 023 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 024 */     partitionIndex = index;
/* 025 */     this.inputs = inputs;
/* 026 */
/* 027 */     sort_needToSort_0 = true;
/* 028 */     sort_sorter_0 = ((org.apache.spark.sql.execution.SortExec) references[0] /* plan */).createSorter();
/* 029 */     sort_metrics_0 = org.apache.spark.TaskContext.get().taskMetrics();
/* 030 */     inputadapter_input_0 = inputs[0];
/* 031 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 032 */
/* 033 */   }
/* 034 */
/* 035 */   private void agg_doAggregateWithoutKey_0() throws java.io.IOException {
/* 036 */     // initialize aggregation buffer
/* 037 */     agg_bufIsNull_0 = false;
/* 038 */     agg_bufValue_0 = 0L;
/* 039 */
/* 040 */     if (sort_needToSort_0) {
/* 041 */       long sort_spillSizeBefore_0 = sort_metrics_0.memoryBytesSpilled();
/* 042 */       sort_addToSorter_0();
/* 043 */       sort_sortedIter_0 = sort_sorter_0.sort();
/* 044 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* sortTime */).add(sort_sorter_0.getSortTimeNanos() / 1000000);
/* 045 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */).add(sort_sorter_0.getPeakMemoryUsage());
/* 046 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */).add(sort_metrics_0.memoryBytesSpilled() - sort_spillSizeBefore_0);
/* 047 */       sort_metrics_0.incPeakExecutionMemory(sort_sorter_0.getPeakMemoryUsage());
/* 048 */       sort_needToSort_0 = false;
/* 049 */     }
/* 050 */
/* 051 */     while (sort_sortedIter_0.hasNext()) {
/* 052 */       UnsafeRow sort_outputRow_0 = (UnsafeRow)sort_sortedIter_0.next();
/* 053 */
/* 054 */       agg_doConsume_0();
/* 055 */
/* 056 */       if (shouldStop()) return;
/* 057 */     }
/* 058 */
/* 059 */   }
/* 060 */
/* 061 */   private void sort_addToSorter_0() throws java.io.IOException {
/* 062 */     while (inputadapter_input_0.hasNext() && !stopEarly()) {
/* 063 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 064 */       sort_sorter_0.insertRow((UnsafeRow)inputadapter_row_0);
/* 065 */       if (shouldStop()) return;
/* 066 */     }
/* 067 */
/* 068 */   }
/* 069 */
/* 070 */   private void agg_doConsume_0() throws java.io.IOException {
/* 071 */     // do aggregate
/* 072 */     // common sub-expressions
/* 073 */
/* 074 */     // evaluate aggregate function
/* 075 */     long agg_value_1 = -1L;
/* 076 */     agg_value_1 = agg_bufValue_0 + 1L;
/* 077 */     // update aggregation buffer
/* 078 */     agg_bufIsNull_0 = false;
/* 079 */     agg_bufValue_0 = agg_value_1;
/* 080 */
/* 081 */   }
/* 082 */
/* 083 */   protected void processNext() throws java.io.IOException {
/* 084 */     while (!agg_initAgg_0) {
/* 085 */       agg_initAgg_0 = true;
/* 086 */       long agg_beforeAgg_0 = System.nanoTime();
/* 087 */       agg_doAggregateWithoutKey_0();
/* 088 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - agg_beforeAgg_0) / 1000000);
/* 089 */
/* 090 */       // output the result
/* 091 */
/* 092 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 093 */       agg_mutableStateArray_0[0].reset();
/* 094 */
/* 095 */       agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 096 */
/* 097 */       agg_mutableStateArray_0[0].write(0, agg_bufValue_0);
/* 098 */       append((agg_mutableStateArray_0[0].getRow()));
/* 099 */     }
/* 100 */   }
/* 101 */
/* 102 */ }

2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.$outer
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.$outer
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      <function0>
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      <function0>
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[34] at run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[35] at run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[34] at run at ThreadPoolExecutor.java:1149)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[35] at run at ThreadPoolExecutor.java:1149)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[34] at run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[35] at run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[34] at run at ThreadPoolExecutor.java:1149)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[35] at run at ThreadPoolExecutor.java:1149)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 31.346 ms
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Got job 6 (run at ThreadPoolExecutor.java:1149) with 1 output partitions
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Final stage: ResultStage 6 (run at ThreadPoolExecutor.java:1149)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitStage(ResultStage 6 (name=run at ThreadPoolExecutor.java:1149;jobs=6))
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting ResultStage 6 (MapPartitionsRDD[34] at run at ThreadPoolExecutor.java:1149), which has no missing parents
2022-02-09 13:09:17 INFO  SparkContext:54 - Starting job: run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 6)
2022-02-09 13:09:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_14 stored as values in memory (estimated size 11.0 KB, free 1968.9 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_14 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_14 without replication took  0 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_14_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1968.9 MB)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_14_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 6.0 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_14_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_14_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_14_piece0 locally took  17 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_14_piece0 without replication took  17 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 14 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Adding task set 6.0 with 1 tasks
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Epoch for TaskSet 6.0: 0
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 6.0: NO_PREF, ANY
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Got job 7 (run at ThreadPoolExecutor.java:1149) with 1 output partitions
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Final stage: ResultStage 7 (run at ThreadPoolExecutor.java:1149)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Parents of final stage: List()
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 8320 bytes)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Missing parents: List()
2022-02-09 13:09:17 INFO  Executor:54 - Running task 0.0 in stage 6.0 (TID 6)
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitStage(ResultStage 7 (name=run at ThreadPoolExecutor.java:1149;jobs=7))
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting ResultStage 7 (MapPartitionsRDD[35] at run at ThreadPoolExecutor.java:1149), which has no missing parents
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 7)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_14
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_14 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_15 stored as values in memory (estimated size 11.2 KB, free 1968.9 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_15 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_15 without replication took  0 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_15_piece0 stored as bytes in memory (estimated size 6.0 KB, free 1968.9 MB)
2022-02-09 13:09:17 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/products/part-00000, range: 0-174247, partition values: [empty row]
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_15_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 6.0 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_15_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_15_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_15_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_15_piece0 without replication took  0 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 15 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:17 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage4(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=4
/* 006 */ final class GeneratedIteratorForCodegenStage4 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 015 */
/* 016 */   public GeneratedIteratorForCodegenStage4(Object[] references) {
/* 017 */     this.references = references;
/* 018 */   }
/* 019 */
/* 020 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 021 */     partitionIndex = index;
/* 022 */     this.inputs = inputs;
/* 023 */
/* 024 */     inputadapter_input_0 = inputs[0];
/* 025 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 026 */     agg_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 031 */   throws java.io.IOException {
/* 032 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 033 */
/* 034 */     boolean agg_isNull_7 = agg_keyTerm_0.isNullAt(0);
/* 035 */     int agg_value_7 = agg_isNull_7 ?
/* 036 */     -1 : (agg_keyTerm_0.getInt(0));
/* 037 */     agg_mutableStateArray_0[1].reset();
/* 038 */
/* 039 */     agg_mutableStateArray_0[1].zeroOutNullBytes();
/* 040 */
/* 041 */     if (agg_isNull_7) {
/* 042 */       agg_mutableStateArray_0[1].setNullAt(0);
/* 043 */     } else {
/* 044 */       agg_mutableStateArray_0[1].write(0, agg_value_7);
/* 045 */     }
/* 046 */     append((agg_mutableStateArray_0[1].getRow()));
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 051 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 052 */
/* 053 */     // generate grouping key
/* 054 */     agg_mutableStateArray_0[0].reset();
/* 055 */
/* 056 */     agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 057 */
/* 058 */     if (agg_exprIsNull_0_0) {
/* 059 */       agg_mutableStateArray_0[0].setNullAt(0);
/* 060 */     } else {
/* 061 */       agg_mutableStateArray_0[0].write(0, agg_expr_0_0);
/* 062 */     }
/* 063 */
/* 064 */     if (agg_exprIsNull_1_0) {
/* 065 */       agg_mutableStateArray_0[0].setNullAt(1);
/* 066 */     } else {
/* 067 */       agg_mutableStateArray_0[0].write(1, agg_expr_1_0);
/* 068 */     }
/* 069 */     int agg_value_4 = 48;
/* 070 */
/* 071 */     if (!agg_exprIsNull_0_0) {
/* 072 */       agg_value_4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(agg_expr_0_0, agg_value_4);
/* 073 */     }
/* 074 */
/* 075 */     if (!agg_exprIsNull_1_0) {
/* 076 */       agg_value_4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_expr_1_0.getBaseObject(), agg_expr_1_0.getBaseOffset(), agg_expr_1_0.numBytes(), agg_value_4);
/* 077 */     }
/* 078 */     if (true) {
/* 079 */       // try to get the buffer from hash map
/* 080 */       agg_unsafeRowAggBuffer_0 =
/* 081 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((agg_mutableStateArray_0[0].getRow()), agg_value_4);
/* 082 */     }
/* 083 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 084 */     // aggregation after processing all input rows.
/* 085 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 086 */       if (agg_sorter_0 == null) {
/* 087 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 088 */       } else {
/* 089 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 090 */       }
/* 091 */
/* 092 */       // the hash map had be spilled, it should have enough memory now,
/* 093 */       // try to allocate buffer again.
/* 094 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 095 */         (agg_mutableStateArray_0[0].getRow()), agg_value_4);
/* 096 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 097 */         // failed to allocate the first page
/* 098 */         throw new OutOfMemoryError("No enough memory for aggregation");
/* 099 */       }
/* 100 */     }
/* 101 */
/* 102 */     // common sub-expressions
/* 103 */
/* 104 */     // evaluate aggregate function
/* 105 */
/* 106 */     // update unsafe row buffer
/* 107 */
/* 108 */   }
/* 109 */
/* 110 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 111 */     while (inputadapter_input_0.hasNext() && !stopEarly()) {
/* 112 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 113 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 114 */       int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 115 */       -1 : (inputadapter_row_0.getInt(0));
/* 116 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 117 */       UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 118 */       null : (inputadapter_row_0.getUTF8String(1));
/* 119 */
/* 120 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0, inputadapter_isNull_0, inputadapter_value_1, inputadapter_isNull_1);
/* 121 */       if (shouldStop()) return;
/* 122 */     }
/* 123 */
/* 124 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 125 */   }
/* 126 */
/* 127 */   protected void processNext() throws java.io.IOException {
/* 128 */     if (!agg_initAgg_0) {
/* 129 */       agg_initAgg_0 = true;
/* 130 */
/* 131 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 132 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 133 */       agg_doAggregateWithKeys_0();
/* 134 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 135 */     }
/* 136 */
/* 137 */     // output the result
/* 138 */
/* 139 */     while (agg_mapIter_0.next()) {
/* 140 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 141 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 142 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 143 */
/* 144 */       if (shouldStop()) return;
/* 145 */     }
/* 146 */
/* 147 */     agg_mapIter_0.close();
/* 148 */     if (agg_sorter_0 == null) {
/* 149 */       agg_hashMap_0.free();
/* 150 */     }
/* 151 */   }
/* 152 */
/* 153 */ }

2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[35] at run at ThreadPoolExecutor.java:1149) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Adding task set 7.0 with 1 tasks
2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */     return (mutableStateArray_0[0].getRow());
/* 040 */   }
/* 041 */
/* 042 */
/* 043 */ }

2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Epoch for TaskSet 7.0: 0
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 7.0: NO_PREF, ANY
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_6.0, runningTasks: 1
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage4(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=4
/* 006 */ final class GeneratedIteratorForCodegenStage4 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private scala.collection.Iterator inputadapter_input_0;
/* 014 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] agg_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[2];
/* 015 */
/* 016 */   public GeneratedIteratorForCodegenStage4(Object[] references) {
/* 017 */     this.references = references;
/* 018 */   }
/* 019 */
/* 020 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 021 */     partitionIndex = index;
/* 022 */     this.inputs = inputs;
/* 023 */
/* 024 */     inputadapter_input_0 = inputs[0];
/* 025 */     agg_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 026 */     agg_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 031 */   throws java.io.IOException {
/* 032 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 033 */
/* 034 */     boolean agg_isNull_7 = agg_keyTerm_0.isNullAt(0);
/* 035 */     int agg_value_7 = agg_isNull_7 ?
/* 036 */     -1 : (agg_keyTerm_0.getInt(0));
/* 037 */     agg_mutableStateArray_0[1].reset();
/* 038 */
/* 039 */     agg_mutableStateArray_0[1].zeroOutNullBytes();
/* 040 */
/* 041 */     if (agg_isNull_7) {
/* 042 */       agg_mutableStateArray_0[1].setNullAt(0);
/* 043 */     } else {
/* 044 */       agg_mutableStateArray_0[1].write(0, agg_value_7);
/* 045 */     }
/* 046 */     append((agg_mutableStateArray_0[1].getRow()));
/* 047 */
/* 048 */   }
/* 049 */
/* 050 */   private void agg_doConsume_0(InternalRow inputadapter_row_0, int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 051 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 052 */
/* 053 */     // generate grouping key
/* 054 */     agg_mutableStateArray_0[0].reset();
/* 055 */
/* 056 */     agg_mutableStateArray_0[0].zeroOutNullBytes();
/* 057 */
/* 058 */     if (agg_exprIsNull_0_0) {
/* 059 */       agg_mutableStateArray_0[0].setNullAt(0);
/* 060 */     } else {
/* 061 */       agg_mutableStateArray_0[0].write(0, agg_expr_0_0);
/* 062 */     }
/* 063 */
/* 064 */     if (agg_exprIsNull_1_0) {
/* 065 */       agg_mutableStateArray_0[0].setNullAt(1);
/* 066 */     } else {
/* 067 */       agg_mutableStateArray_0[0].write(1, agg_expr_1_0);
/* 068 */     }
/* 069 */     int agg_value_4 = 48;
/* 070 */
/* 071 */     if (!agg_exprIsNull_0_0) {
/* 072 */       agg_value_4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(agg_expr_0_0, agg_value_4);
/* 073 */     }
/* 074 */
/* 075 */     if (!agg_exprIsNull_1_0) {
/* 076 */       agg_value_4 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_expr_1_0.getBaseObject(), agg_expr_1_0.getBaseOffset(), agg_expr_1_0.numBytes(), agg_value_4);
/* 077 */     }
/* 078 */     if (true) {
/* 079 */       // try to get the buffer from hash map
/* 080 */       agg_unsafeRowAggBuffer_0 =
/* 081 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((agg_mutableStateArray_0[0].getRow()), agg_value_4);
/* 082 */     }
/* 083 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 084 */     // aggregation after processing all input rows.
/* 085 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 086 */       if (agg_sorter_0 == null) {
/* 087 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 088 */       } else {
/* 089 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 090 */       }
/* 091 */
/* 092 */       // the hash map had be spilled, it should have enough memory now,
/* 093 */       // try to allocate buffer again.
/* 094 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 095 */         (agg_mutableStateArray_0[0].getRow()), agg_value_4);
/* 096 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 097 */         // failed to allocate the first page
/* 098 */         throw new OutOfMemoryError("No enough memory for aggregation");
/* 099 */       }
/* 100 */     }
/* 101 */
/* 102 */     // common sub-expressions
/* 103 */
/* 104 */     // evaluate aggregate function
/* 105 */
/* 106 */     // update unsafe row buffer
/* 107 */
/* 108 */   }
/* 109 */
/* 110 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 111 */     while (inputadapter_input_0.hasNext() && !stopEarly()) {
/* 112 */       InternalRow inputadapter_row_0 = (InternalRow) inputadapter_input_0.next();
/* 113 */       boolean inputadapter_isNull_0 = inputadapter_row_0.isNullAt(0);
/* 114 */       int inputadapter_value_0 = inputadapter_isNull_0 ?
/* 115 */       -1 : (inputadapter_row_0.getInt(0));
/* 116 */       boolean inputadapter_isNull_1 = inputadapter_row_0.isNullAt(1);
/* 117 */       UTF8String inputadapter_value_1 = inputadapter_isNull_1 ?
/* 118 */       null : (inputadapter_row_0.getUTF8String(1));
/* 119 */
/* 120 */       agg_doConsume_0(inputadapter_row_0, inputadapter_value_0, inputadapter_isNull_0, inputadapter_value_1, inputadapter_isNull_1);
/* 121 */       if (shouldStop()) return;
/* 122 */     }
/* 123 */
/* 124 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 125 */   }
/* 126 */
/* 127 */   protected void processNext() throws java.io.IOException {
/* 128 */     if (!agg_initAgg_0) {
/* 129 */       agg_initAgg_0 = true;
/* 130 */
/* 131 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 132 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 133 */       agg_doAggregateWithKeys_0();
/* 134 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 135 */     }
/* 136 */
/* 137 */     // output the result
/* 138 */
/* 139 */     while (agg_mapIter_0.next()) {
/* 140 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 141 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 142 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 143 */
/* 144 */       if (shouldStop()) return;
/* 145 */     }
/* 146 */
/* 147 */     agg_mapIter_0.close();
/* 148 */     if (agg_sorter_0 == null) {
/* 149 */       agg_hashMap_0.free();
/* 150 */     }
/* 151 */   }
/* 152 */
/* 153 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 11.9396 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_12
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_12 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 36.4141 ms
2022-02-09 13:09:17 INFO  HashAggregateExec:54 - spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 0.0 in stage 6.0 (TID 6). 2181 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_6.0, runningTasks: 0
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 8323 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 0.0 in stage 7.0 (TID 7)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 6.0 (TID 6) in 79 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2022-02-09 13:09:17 INFO  DAGScheduler:54 - ResultStage 6 (run at ThreadPoolExecutor.java:1149) finished in 0.096 s
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_15
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_15 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - After removal of stage 6, remaining stages = 1
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Job 6 finished: run at ThreadPoolExecutor.java:1149, took 0.096656 s
2022-02-09 13:09:17 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/departments/part-00000, range: 0-90, partition values: [empty row]
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 0 acquired 1056.0 KB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@628660a9
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 11.6077 ms
2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_13
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_13 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 0.0 in stage 7.0 (TID 7). 1469 bytes result sent to driver
2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 10.4823 ms
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_7.0, runningTasks: 0
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 7.0 (TID 7) in 33 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2022-02-09 13:09:17 INFO  DAGScheduler:54 - ResultStage 7 (run at ThreadPoolExecutor.java:1149) finished in 0.112 s
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - After removal of stage 7, remaining stages = 0
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Job 7 finished: run at ThreadPoolExecutor.java:1149, took 0.126048 s
2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 0 acquired 1024.1 KB for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4f690df7
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for cast(input[0, int, true] as bigint):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     boolean isNull_0 = isNull_1;
/* 035 */     long value_0 = -1L;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 0 acquired 256.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4f690df7
2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 0 release 128.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4f690df7
2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 0 acquired 48.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4f690df7
2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 0 release 256.0 B from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@4f690df7
2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 0 acquired 464.0 B for org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@628660a9
2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 0 release 32.0 KB from org.apache.spark.sql.execution.joins.LongToUnsafeRowMap@628660a9
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_16 stored as values in memory (estimated size 1024.1 KB, free 1967.9 MB)
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_17 stored as values in memory (estimated size 1024.5 KB, free 1966.9 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_16 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_17 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_16 without replication took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_17 without replication took  0 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_16_piece0 stored as bytes in memory (estimated size 357.0 B, free 1966.9 MB)
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_17_piece0 stored as bytes in memory (estimated size 9.1 KB, free 1966.9 MB)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_16_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 357.0 B, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_16_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_16_piece0
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_17_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 9.1 KB, free: 1970.2 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_16_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_17_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_16_piece0 without replication took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_17_piece0
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 16 from run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_17_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_17_piece0 without replication took  0 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 17 from run at ThreadPoolExecutor.java:1149
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_16
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_16 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_17
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_17 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 DEBUG WholeStageCodegenExec:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage3(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=3
/* 006 */ final class GeneratedIteratorForCodegenStage3 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 014 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_1;
/* 015 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[9];
/* 016 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 017 */
/* 018 */   public GeneratedIteratorForCodegenStage3(Object[] references) {
/* 019 */     this.references = references;
/* 020 */   }
/* 021 */
/* 022 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 023 */     partitionIndex = index;
/* 024 */     this.inputs = inputs;
/* 025 */     wholestagecodegen_init_0_0();
/* 026 */     wholestagecodegen_init_0_1();
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 031 */   throws java.io.IOException {
/* 032 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[10] /* numOutputRows */).add(1);
/* 033 */
/* 034 */     boolean agg_isNull_9 = agg_keyTerm_0.isNullAt(0);
/* 035 */     int agg_value_9 = agg_isNull_9 ?
/* 036 */     -1 : (agg_keyTerm_0.getInt(0));
/* 037 */     boolean agg_isNull_10 = agg_keyTerm_0.isNullAt(1);
/* 038 */     UTF8String agg_value_10 = agg_isNull_10 ?
/* 039 */     null : (agg_keyTerm_0.getUTF8String(1));
/* 040 */     filter_mutableStateArray_0[8].reset();
/* 041 */
/* 042 */     filter_mutableStateArray_0[8].zeroOutNullBytes();
/* 043 */
/* 044 */     if (agg_isNull_9) {
/* 045 */       filter_mutableStateArray_0[8].setNullAt(0);
/* 046 */     } else {
/* 047 */       filter_mutableStateArray_0[8].write(0, agg_value_9);
/* 048 */     }
/* 049 */
/* 050 */     if (agg_isNull_10) {
/* 051 */       filter_mutableStateArray_0[8].setNullAt(1);
/* 052 */     } else {
/* 053 */       filter_mutableStateArray_0[8].write(1, agg_value_10);
/* 054 */     }
/* 055 */     append((filter_mutableStateArray_0[8].getRow()));
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   private void wholestagecodegen_init_0_1() {
/* 060 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 061 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 062 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 063 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 064 */
/* 065 */   }
/* 066 */
/* 067 */   private void agg_doConsume_0(int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 068 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 069 */
/* 070 */     // generate grouping key
/* 071 */     filter_mutableStateArray_0[7].reset();
/* 072 */
/* 073 */     filter_mutableStateArray_0[7].zeroOutNullBytes();
/* 074 */
/* 075 */     if (agg_exprIsNull_0_0) {
/* 076 */       filter_mutableStateArray_0[7].setNullAt(0);
/* 077 */     } else {
/* 078 */       filter_mutableStateArray_0[7].write(0, agg_expr_0_0);
/* 079 */     }
/* 080 */
/* 081 */     if (agg_exprIsNull_1_0) {
/* 082 */       filter_mutableStateArray_0[7].setNullAt(1);
/* 083 */     } else {
/* 084 */       filter_mutableStateArray_0[7].write(1, agg_expr_1_0);
/* 085 */     }
/* 086 */     int agg_value_6 = 48;
/* 087 */
/* 088 */     if (!agg_exprIsNull_0_0) {
/* 089 */       agg_value_6 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(agg_expr_0_0, agg_value_6);
/* 090 */     }
/* 091 */
/* 092 */     if (!agg_exprIsNull_1_0) {
/* 093 */       agg_value_6 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_expr_1_0.getBaseObject(), agg_expr_1_0.getBaseOffset(), agg_expr_1_0.numBytes(), agg_value_6);
/* 094 */     }
/* 095 */     if (true) {
/* 096 */       // try to get the buffer from hash map
/* 097 */       agg_unsafeRowAggBuffer_0 =
/* 098 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((filter_mutableStateArray_0[7].getRow()), agg_value_6);
/* 099 */     }
/* 100 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 101 */     // aggregation after processing all input rows.
/* 102 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 103 */       if (agg_sorter_0 == null) {
/* 104 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 105 */       } else {
/* 106 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 107 */       }
/* 108 */
/* 109 */       // the hash map had be spilled, it should have enough memory now,
/* 110 */       // try to allocate buffer again.
/* 111 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 112 */         (filter_mutableStateArray_0[7].getRow()), agg_value_6);
/* 113 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 114 */         // failed to allocate the first page
/* 115 */         throw new OutOfMemoryError("No enough memory for aggregation");
/* 116 */       }
/* 117 */     }
/* 118 */
/* 119 */     // common sub-expressions
/* 120 */
/* 121 */     // evaluate aggregate function
/* 122 */
/* 123 */     // update unsafe row buffer
/* 124 */
/* 125 */   }
/* 126 */
/* 127 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 128 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 129 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 130 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 131 */       do {
/* 132 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 133 */         int scan_value_1 = scan_isNull_1 ?
/* 134 */         -1 : (scan_row_0.getInt(1));
/* 135 */
/* 136 */         if (!(!scan_isNull_1)) continue;
/* 137 */
/* 138 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 139 */         int scan_value_0 = scan_isNull_0 ?
/* 140 */         -1 : (scan_row_0.getInt(0));
/* 141 */
/* 142 */         if (!(!scan_isNull_0)) continue;
/* 143 */
/* 144 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* numOutputRows */).add(1);
/* 145 */
/* 146 */         // generate join key for stream side
/* 147 */         boolean bhj_isNull_0 = false;
/* 148 */         long bhj_value_0 = -1L;
/* 149 */         if (!false) {
/* 150 */           bhj_value_0 = (long) scan_value_1;
/* 151 */         }
/* 152 */         // find matches from HashedRelation
/* 153 */         UnsafeRow bhj_matched_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 154 */         if (bhj_matched_0 != null) {
/* 155 */           {
/* 156 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[7] /* numOutputRows */).add(1);
/* 157 */
/* 158 */             // generate join key for stream side
/* 159 */             boolean bhj_isNull_8 = false;
/* 160 */             long bhj_value_8 = -1L;
/* 161 */             if (!false) {
/* 162 */               bhj_value_8 = (long) scan_value_0;
/* 163 */             }
/* 164 */             // find matches from HashRelation
/* 165 */             scala.collection.Iterator bhj_matches_0 = bhj_isNull_8 ? null : (scala.collection.Iterator)bhj_relation_1.get(bhj_value_8);
/* 166 */             if (bhj_matches_0 != null) {
/* 167 */               while (bhj_matches_0.hasNext()) {
/* 168 */                 UnsafeRow bhj_matched_1 = (UnsafeRow) bhj_matches_0.next();
/* 169 */                 {
/* 170 */                   ((org.apache.spark.sql.execution.metric.SQLMetric) references[9] /* numOutputRows */).add(1);
/* 171 */
/* 172 */                   boolean bhj_isNull_2 = bhj_matched_0.isNullAt(0);
/* 173 */                   int bhj_value_2 = bhj_isNull_2 ?
/* 174 */                   -1 : (bhj_matched_0.getInt(0));
/* 175 */                   boolean bhj_isNull_3 = bhj_matched_0.isNullAt(1);
/* 176 */                   UTF8String bhj_value_3 = bhj_isNull_3 ?
/* 177 */                   null : (bhj_matched_0.getUTF8String(1));
/* 178 */
/* 179 */                   agg_doConsume_0(bhj_value_2, bhj_isNull_2, bhj_value_3, bhj_isNull_3);
/* 180 */
/* 181 */                 }
/* 182 */               }
/* 183 */             }
/* 184 */
/* 185 */           }
/* 186 */         }
/* 187 */
/* 188 */       } while(false);
/* 189 */       if (shouldStop()) return;
/* 190 */     }
/* 191 */
/* 192 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 193 */   }
/* 194 */
/* 195 */   protected void processNext() throws java.io.IOException {
/* 196 */     if (!agg_initAgg_0) {
/* 197 */       agg_initAgg_0 = true;
/* 198 */
/* 199 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 200 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 201 */       agg_doAggregateWithKeys_0();
/* 202 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[11] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 203 */     }
/* 204 */
/* 205 */     // output the result
/* 206 */
/* 207 */     while (agg_mapIter_0.next()) {
/* 208 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 209 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 210 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 211 */
/* 212 */       if (shouldStop()) return;
/* 213 */     }
/* 214 */
/* 215 */     agg_mapIter_0.close();
/* 216 */     if (agg_sorter_0 == null) {
/* 217 */       agg_hashMap_0.free();
/* 218 */     }
/* 219 */   }
/* 220 */
/* 221 */   private void wholestagecodegen_init_0_0() {
/* 222 */     scan_mutableStateArray_0[0] = inputs[0];
/* 223 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 224 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 225 */
/* 226 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[6] /* broadcast */).value()).asReadOnlyCopy();
/* 227 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 228 */
/* 229 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 230 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 231 */
/* 232 */     bhj_relation_1 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[8] /* broadcast */).value()).asReadOnlyCopy();
/* 233 */     incPeakExecutionMemory(bhj_relation_1.estimatedSize());
/* 234 */
/* 235 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 236 */
/* 237 */   }
/* 238 */
/* 239 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage3(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=3
/* 006 */ final class GeneratedIteratorForCodegenStage3 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private boolean agg_initAgg_0;
/* 010 */   private org.apache.spark.unsafe.KVIterator agg_mapIter_0;
/* 011 */   private org.apache.spark.sql.execution.UnsafeFixedWidthAggregationMap agg_hashMap_0;
/* 012 */   private org.apache.spark.sql.execution.UnsafeKVExternalSorter agg_sorter_0;
/* 013 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_0;
/* 014 */   private org.apache.spark.sql.execution.joins.LongHashedRelation bhj_relation_1;
/* 015 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] filter_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[9];
/* 016 */   private scala.collection.Iterator[] scan_mutableStateArray_0 = new scala.collection.Iterator[1];
/* 017 */
/* 018 */   public GeneratedIteratorForCodegenStage3(Object[] references) {
/* 019 */     this.references = references;
/* 020 */   }
/* 021 */
/* 022 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 023 */     partitionIndex = index;
/* 024 */     this.inputs = inputs;
/* 025 */     wholestagecodegen_init_0_0();
/* 026 */     wholestagecodegen_init_0_1();
/* 027 */
/* 028 */   }
/* 029 */
/* 030 */   private void agg_doAggregateWithKeysOutput_0(UnsafeRow agg_keyTerm_0, UnsafeRow agg_bufferTerm_0)
/* 031 */   throws java.io.IOException {
/* 032 */     ((org.apache.spark.sql.execution.metric.SQLMetric) references[10] /* numOutputRows */).add(1);
/* 033 */
/* 034 */     boolean agg_isNull_9 = agg_keyTerm_0.isNullAt(0);
/* 035 */     int agg_value_9 = agg_isNull_9 ?
/* 036 */     -1 : (agg_keyTerm_0.getInt(0));
/* 037 */     boolean agg_isNull_10 = agg_keyTerm_0.isNullAt(1);
/* 038 */     UTF8String agg_value_10 = agg_isNull_10 ?
/* 039 */     null : (agg_keyTerm_0.getUTF8String(1));
/* 040 */     filter_mutableStateArray_0[8].reset();
/* 041 */
/* 042 */     filter_mutableStateArray_0[8].zeroOutNullBytes();
/* 043 */
/* 044 */     if (agg_isNull_9) {
/* 045 */       filter_mutableStateArray_0[8].setNullAt(0);
/* 046 */     } else {
/* 047 */       filter_mutableStateArray_0[8].write(0, agg_value_9);
/* 048 */     }
/* 049 */
/* 050 */     if (agg_isNull_10) {
/* 051 */       filter_mutableStateArray_0[8].setNullAt(1);
/* 052 */     } else {
/* 053 */       filter_mutableStateArray_0[8].write(1, agg_value_10);
/* 054 */     }
/* 055 */     append((filter_mutableStateArray_0[8].getRow()));
/* 056 */
/* 057 */   }
/* 058 */
/* 059 */   private void wholestagecodegen_init_0_1() {
/* 060 */     filter_mutableStateArray_0[5] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 061 */     filter_mutableStateArray_0[6] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 062 */     filter_mutableStateArray_0[7] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 063 */     filter_mutableStateArray_0[8] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 064 */
/* 065 */   }
/* 066 */
/* 067 */   private void agg_doConsume_0(int agg_expr_0_0, boolean agg_exprIsNull_0_0, UTF8String agg_expr_1_0, boolean agg_exprIsNull_1_0) throws java.io.IOException {
/* 068 */     UnsafeRow agg_unsafeRowAggBuffer_0 = null;
/* 069 */
/* 070 */     // generate grouping key
/* 071 */     filter_mutableStateArray_0[7].reset();
/* 072 */
/* 073 */     filter_mutableStateArray_0[7].zeroOutNullBytes();
/* 074 */
/* 075 */     if (agg_exprIsNull_0_0) {
/* 076 */       filter_mutableStateArray_0[7].setNullAt(0);
/* 077 */     } else {
/* 078 */       filter_mutableStateArray_0[7].write(0, agg_expr_0_0);
/* 079 */     }
/* 080 */
/* 081 */     if (agg_exprIsNull_1_0) {
/* 082 */       filter_mutableStateArray_0[7].setNullAt(1);
/* 083 */     } else {
/* 084 */       filter_mutableStateArray_0[7].write(1, agg_expr_1_0);
/* 085 */     }
/* 086 */     int agg_value_6 = 48;
/* 087 */
/* 088 */     if (!agg_exprIsNull_0_0) {
/* 089 */       agg_value_6 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(agg_expr_0_0, agg_value_6);
/* 090 */     }
/* 091 */
/* 092 */     if (!agg_exprIsNull_1_0) {
/* 093 */       agg_value_6 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(agg_expr_1_0.getBaseObject(), agg_expr_1_0.getBaseOffset(), agg_expr_1_0.numBytes(), agg_value_6);
/* 094 */     }
/* 095 */     if (true) {
/* 096 */       // try to get the buffer from hash map
/* 097 */       agg_unsafeRowAggBuffer_0 =
/* 098 */       agg_hashMap_0.getAggregationBufferFromUnsafeRow((filter_mutableStateArray_0[7].getRow()), agg_value_6);
/* 099 */     }
/* 100 */     // Can't allocate buffer from the hash map. Spill the map and fallback to sort-based
/* 101 */     // aggregation after processing all input rows.
/* 102 */     if (agg_unsafeRowAggBuffer_0 == null) {
/* 103 */       if (agg_sorter_0 == null) {
/* 104 */         agg_sorter_0 = agg_hashMap_0.destructAndCreateExternalSorter();
/* 105 */       } else {
/* 106 */         agg_sorter_0.merge(agg_hashMap_0.destructAndCreateExternalSorter());
/* 107 */       }
/* 108 */
/* 109 */       // the hash map had be spilled, it should have enough memory now,
/* 110 */       // try to allocate buffer again.
/* 111 */       agg_unsafeRowAggBuffer_0 = agg_hashMap_0.getAggregationBufferFromUnsafeRow(
/* 112 */         (filter_mutableStateArray_0[7].getRow()), agg_value_6);
/* 113 */       if (agg_unsafeRowAggBuffer_0 == null) {
/* 114 */         // failed to allocate the first page
/* 115 */         throw new OutOfMemoryError("No enough memory for aggregation");
/* 116 */       }
/* 117 */     }
/* 118 */
/* 119 */     // common sub-expressions
/* 120 */
/* 121 */     // evaluate aggregate function
/* 122 */
/* 123 */     // update unsafe row buffer
/* 124 */
/* 125 */   }
/* 126 */
/* 127 */   private void agg_doAggregateWithKeys_0() throws java.io.IOException {
/* 128 */     while (scan_mutableStateArray_0[0].hasNext()) {
/* 129 */       InternalRow scan_row_0 = (InternalRow) scan_mutableStateArray_0[0].next();
/* 130 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[4] /* numOutputRows */).add(1);
/* 131 */       do {
/* 132 */         boolean scan_isNull_1 = scan_row_0.isNullAt(1);
/* 133 */         int scan_value_1 = scan_isNull_1 ?
/* 134 */         -1 : (scan_row_0.getInt(1));
/* 135 */
/* 136 */         if (!(!scan_isNull_1)) continue;
/* 137 */
/* 138 */         boolean scan_isNull_0 = scan_row_0.isNullAt(0);
/* 139 */         int scan_value_0 = scan_isNull_0 ?
/* 140 */         -1 : (scan_row_0.getInt(0));
/* 141 */
/* 142 */         if (!(!scan_isNull_0)) continue;
/* 143 */
/* 144 */         ((org.apache.spark.sql.execution.metric.SQLMetric) references[5] /* numOutputRows */).add(1);
/* 145 */
/* 146 */         // generate join key for stream side
/* 147 */         boolean bhj_isNull_0 = false;
/* 148 */         long bhj_value_0 = -1L;
/* 149 */         if (!false) {
/* 150 */           bhj_value_0 = (long) scan_value_1;
/* 151 */         }
/* 152 */         // find matches from HashedRelation
/* 153 */         UnsafeRow bhj_matched_0 = bhj_isNull_0 ? null: (UnsafeRow)bhj_relation_0.getValue(bhj_value_0);
/* 154 */         if (bhj_matched_0 != null) {
/* 155 */           {
/* 156 */             ((org.apache.spark.sql.execution.metric.SQLMetric) references[7] /* numOutputRows */).add(1);
/* 157 */
/* 158 */             // generate join key for stream side
/* 159 */             boolean bhj_isNull_8 = false;
/* 160 */             long bhj_value_8 = -1L;
/* 161 */             if (!false) {
/* 162 */               bhj_value_8 = (long) scan_value_0;
/* 163 */             }
/* 164 */             // find matches from HashRelation
/* 165 */             scala.collection.Iterator bhj_matches_0 = bhj_isNull_8 ? null : (scala.collection.Iterator)bhj_relation_1.get(bhj_value_8);
/* 166 */             if (bhj_matches_0 != null) {
/* 167 */               while (bhj_matches_0.hasNext()) {
/* 168 */                 UnsafeRow bhj_matched_1 = (UnsafeRow) bhj_matches_0.next();
/* 169 */                 {
/* 170 */                   ((org.apache.spark.sql.execution.metric.SQLMetric) references[9] /* numOutputRows */).add(1);
/* 171 */
/* 172 */                   boolean bhj_isNull_2 = bhj_matched_0.isNullAt(0);
/* 173 */                   int bhj_value_2 = bhj_isNull_2 ?
/* 174 */                   -1 : (bhj_matched_0.getInt(0));
/* 175 */                   boolean bhj_isNull_3 = bhj_matched_0.isNullAt(1);
/* 176 */                   UTF8String bhj_value_3 = bhj_isNull_3 ?
/* 177 */                   null : (bhj_matched_0.getUTF8String(1));
/* 178 */
/* 179 */                   agg_doConsume_0(bhj_value_2, bhj_isNull_2, bhj_value_3, bhj_isNull_3);
/* 180 */
/* 181 */                 }
/* 182 */               }
/* 183 */             }
/* 184 */
/* 185 */           }
/* 186 */         }
/* 187 */
/* 188 */       } while(false);
/* 189 */       if (shouldStop()) return;
/* 190 */     }
/* 191 */
/* 192 */     agg_mapIter_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).finishAggregate(agg_hashMap_0, agg_sorter_0, ((org.apache.spark.sql.execution.metric.SQLMetric) references[1] /* peakMemory */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[2] /* spillSize */), ((org.apache.spark.sql.execution.metric.SQLMetric) references[3] /* avgHashProbe */));
/* 193 */   }
/* 194 */
/* 195 */   protected void processNext() throws java.io.IOException {
/* 196 */     if (!agg_initAgg_0) {
/* 197 */       agg_initAgg_0 = true;
/* 198 */
/* 199 */       agg_hashMap_0 = ((org.apache.spark.sql.execution.aggregate.HashAggregateExec) references[0] /* plan */).createHashMap();
/* 200 */       long wholestagecodegen_beforeAgg_0 = System.nanoTime();
/* 201 */       agg_doAggregateWithKeys_0();
/* 202 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[11] /* aggTime */).add((System.nanoTime() - wholestagecodegen_beforeAgg_0) / 1000000);
/* 203 */     }
/* 204 */
/* 205 */     // output the result
/* 206 */
/* 207 */     while (agg_mapIter_0.next()) {
/* 208 */       UnsafeRow agg_aggKey_0 = (UnsafeRow) agg_mapIter_0.getKey();
/* 209 */       UnsafeRow agg_aggBuffer_0 = (UnsafeRow) agg_mapIter_0.getValue();
/* 210 */       agg_doAggregateWithKeysOutput_0(agg_aggKey_0, agg_aggBuffer_0);
/* 211 */
/* 212 */       if (shouldStop()) return;
/* 213 */     }
/* 214 */
/* 215 */     agg_mapIter_0.close();
/* 216 */     if (agg_sorter_0 == null) {
/* 217 */       agg_hashMap_0.free();
/* 218 */     }
/* 219 */   }
/* 220 */
/* 221 */   private void wholestagecodegen_init_0_0() {
/* 222 */     scan_mutableStateArray_0[0] = inputs[0];
/* 223 */     filter_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 224 */     filter_mutableStateArray_0[1] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 225 */
/* 226 */     bhj_relation_0 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[6] /* broadcast */).value()).asReadOnlyCopy();
/* 227 */     incPeakExecutionMemory(bhj_relation_0.estimatedSize());
/* 228 */
/* 229 */     filter_mutableStateArray_0[2] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 230 */     filter_mutableStateArray_0[3] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(3, 32);
/* 231 */
/* 232 */     bhj_relation_1 = ((org.apache.spark.sql.execution.joins.LongHashedRelation) ((org.apache.spark.broadcast.TorrentBroadcast) references[8] /* broadcast */).value()).asReadOnlyCopy();
/* 233 */     incPeakExecutionMemory(bhj_relation_1.estimatedSize());
/* 234 */
/* 235 */     filter_mutableStateArray_0[4] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(4, 32);
/* 236 */
/* 237 */   }
/* 238 */
/* 239 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 37.5744 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_18 stored as values in memory (estimated size 221.8 KB, free 1966.7 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_18 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_18 without replication took  0 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_18_piece0 stored as bytes in memory (estimated size 20.7 KB, free 1966.7 MB)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_18_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 20.7 KB, free: 1970.2 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_18_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_18_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_18_piece0 locally took  16 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_18_piece0 without replication took  17 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 18 from count at UseCase5Test.java:25
2022-02-09 13:09:17 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4195382 bytes, open cost is considered as scanning 4194304 bytes.
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:17 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 11.7882 ms
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(290)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 290
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 290
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(141)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 141
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 141
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(136)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 136
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 136
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(248)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 248
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 248
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(147)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 147
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 147
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(155)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 155
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 155
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(125)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 125
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 125
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(151)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 151
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 151
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(282)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 282
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 282
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(267)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 267
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 267
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(249)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 249
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 249
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(263)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.RangePartitioner$$anonfun$9) +++
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 263
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 263
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(185)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 185
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 185
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(261)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 261
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 261
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(271)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 271
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 271
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(250)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 250
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 250
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(157)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 157
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 157
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(134)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 134
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.RangePartitioner$$anonfun$9.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.RangePartitioner$$anonfun$9.apply(java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.RangePartitioner$$anonfun$9.apply(scala.Product2)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 134
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(172)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 172
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 172
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(246)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 246
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 246
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(293)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 293
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 293
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(127)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.RangePartitioner$$anonfun$9) is now cleaned +++
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 127
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 127
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(164)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 164
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 164
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(189)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 189
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 189
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(270)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 270
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 270
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(253)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 253
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 253
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(256)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 256
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 256
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(258)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 258
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 258
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(169)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 169
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 169
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(266)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 266
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 266
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(259)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 259
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 259
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(264)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 264
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 264
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(130)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 130
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 130
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(152)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 152
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 152
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(171)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 171
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.RangePartitioner$$anonfun$13) +++
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 171
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(170)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 170
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 170
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(165)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 165
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 165
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(179)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 179
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 179
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(291)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.RangePartitioner$$anonfun$13.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final int org.apache.spark.RangePartitioner$$anonfun$13.sampleSizePerPartition$2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final scala.reflect.ClassTag org.apache.spark.RangePartitioner$$anonfun$13.evidence$5$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final int org.apache.spark.RangePartitioner$$anonfun$13.shift$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 291
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.RangePartitioner$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 291
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.RangePartitioner$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(275)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 275
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 275
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(280)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 280
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 280
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(177)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 177
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 177
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(9)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning broadcast 9
2022-02-09 13:09:17 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 9
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.RangePartitioner$$anonfun$13) is now cleaned +++
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 9
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing broadcast 9
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_9_piece0
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_9_piece0 of size 4741 dropped from memory (free 2062202317)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Removed broadcast_9_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 4.6 KB, free: 1970.2 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_9_piece0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) +++
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_9_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_9
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_9 of size 9144 dropped from memory (free 2062211461)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.$outer
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      <function0>
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[43] at count at UseCase5Test.java:25
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 9, response is 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaned broadcast 9
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(260)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 260
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 260
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(272)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 272
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 272
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[43] at count at UseCase5Test.java:25)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(176)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 176
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 176
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(284)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 284
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 284
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(245)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 245
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 245
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(156)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 156
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 156
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(158)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 158
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 158
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(146)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 146
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 146
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(132)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 132
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 132
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(143)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 143
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 143
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(180)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 180
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 180
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(285)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 285
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 285
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(181)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 181
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 181
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(123)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 123
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 123
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(135)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 135
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 135
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(14)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning broadcast 14
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 1
2022-02-09 13:09:17 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 14
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[43] at count at UseCase5Test.java:25
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 14
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing broadcast 14
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_14
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_14 of size 11272 dropped from memory (free 2062222733)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_14_piece0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_14_piece0 of size 6104 dropped from memory (free 2062228837)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Removed broadcast_14_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 6.0 KB, free: 1970.2 MB)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_14_piece0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[43] at count at UseCase5Test.java:25)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_14_piece0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) is now cleaned +++
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 14, response is 0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaned broadcast 14
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(288)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 288
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 288
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(145)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 145
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 145
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(174)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 174
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 174
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(142)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 142
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 142
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(178)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 178
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 178
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(168)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 168
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 168
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(289)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 289
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 289
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(251)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 251
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 251
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(273)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 273
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 273
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(11)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning broadcast 11
2022-02-09 13:09:17 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 11
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 11
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing broadcast 11
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_11
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_11 of size 14312 dropped from memory (free 2062243149)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_11_piece0
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_11_piece0 of size 7756 dropped from memory (free 2062250905)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Removed broadcast_11_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 7.6 KB, free: 1970.2 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_11_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_11_piece0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 11, response is 0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaned broadcast 11
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(175)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 175
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 175
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(173)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 173
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 173
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(183)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 183
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 183
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(279)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 279
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 279
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(154)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 154
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 154
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(138)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 138
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 138
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(292)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 292
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 292
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(128)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 128
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 128
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(247)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 247
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 247
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(122)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 122
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 122
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(277)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 277
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 277
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(161)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 161
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 161
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(10)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning broadcast 10
2022-02-09 13:09:17 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 10
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 10
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing broadcast 10
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_10
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_10 of size 227232 dropped from memory (free 2062478137)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_10_piece0
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_10_piece0 of size 21172 dropped from memory (free 2062499309)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Removed broadcast_10_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_10_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_10_piece0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 10, response is 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaned broadcast 10
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(254)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 254
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 254
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(262)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 262
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 262
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(281)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 281
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 281
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(8)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning broadcast 8
2022-02-09 13:09:17 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 8
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:17 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 8
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing broadcast 8
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_8
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_8 of size 227232 dropped from memory (free 2062726541)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_8_piece0
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_8_piece0 of size 21172 dropped from memory (free 2062747713)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Removed broadcast_8_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 20.7 KB, free: 1970.3 MB)
2022-02-09 13:09:17 INFO  SparkContext:54 - Starting job: count at UseCase5Test.java:25
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_8_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_8_piece0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 8, response is 0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaned broadcast 8
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(148)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 148
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 148
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(252)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 252
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 252
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(278)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 278
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 278
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(153)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 153
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 153
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(294)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 294
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 294
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(126)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 126
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 126
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Registering RDD 38 (count at UseCase5Test.java:25) as input to shuffle 0
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(15)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning broadcast 15
2022-02-09 13:09:17 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 15
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 15
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing broadcast 15
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_15
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_15 of size 11432 dropped from memory (free 2062759145)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Removing block broadcast_15_piece0
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Got job 8 (count at UseCase5Test.java:25) with 200 output partitions
2022-02-09 13:09:17 DEBUG MemoryStore:58 - Block broadcast_15_piece0 of size 6144 dropped from memory (free 2062765289)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Final stage: ResultStage 9 (count at UseCase5Test.java:25)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 8)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Removed broadcast_15_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 6.0 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_15_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_15_piece0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 15, response is 0
2022-02-09 13:09:17 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 8)
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitStage(ResultStage 9 (name=count at UseCase5Test.java:25;jobs=8))
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaned broadcast 15
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - missing: List(ShuffleMapStage 8)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(265)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 265
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 265
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(133)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 133
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 133
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(287)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 287
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 287
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(166)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 166
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 166
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(137)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 137
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitStage(ShuffleMapStage 8 (name=count at UseCase5Test.java:25;jobs=8))
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 137
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(286)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 8 (MapPartitionsRDD[38] at count at UseCase5Test.java:25), which has no missing parents
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 286
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitMissingTasks(ShuffleMapStage 8)
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 286
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(140)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 140
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 140
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(255)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 255
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 255
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(162)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 162
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 162
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(283)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 283
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 283
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(163)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 163
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 163
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(144)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 144
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 144
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(149)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 149
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 149
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(160)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 160
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 160
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(268)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 268
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 268
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(276)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 276
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 276
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(159)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 159
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 159
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(131)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 131
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 131
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(150)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 150
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 150
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(257)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 257
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 257
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(124)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 124
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 124
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(182)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 182
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 182
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(129)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 129
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 129
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(184)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 184
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 184
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(167)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 167
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 167
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(269)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 269
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 269
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(274)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 274
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 274
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(139)
2022-02-09 13:09:17 DEBUG ContextCleaner:58 - Cleaning accumulator 139
2022-02-09 13:09:17 INFO  ContextCleaner:54 - Cleaned accumulator 139
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_19 stored as values in memory (estimated size 31.0 KB, free 1967.2 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_19 locally took  16 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_19 without replication took  16 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_19_piece0 stored as bytes in memory (estimated size 13.7 KB, free 1967.2 MB)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_19_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 13.7 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_19_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_19_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_19_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_19_piece0 without replication took  0 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 19 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[38] at count at UseCase5Test.java:25) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Adding task set 8.0 with 1 tasks
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Epoch for TaskSet 8.0: 0
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 8.0: NO_PREF, ANY
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 8311 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 0.0 in stage 8.0 (TID 8)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_19
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_19 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for pmod(hash(input[0, int, true], input[1, string, true], 42), 200):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = false;
/* 032 */     int value_0 = -1;
/* 033 */     if (200 == 0) {
/* 034 */       isNull_0 = true;
/* 035 */     } else {
/* 036 */       int value_1 = 42;
/* 037 */       boolean isNull_2 = i.isNullAt(0);
/* 038 */       int value_2 = isNull_2 ?
/* 039 */       -1 : (i.getInt(0));
/* 040 */       if (!isNull_2) {
/* 041 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_2, value_1);
/* 042 */       }
/* 043 */       boolean isNull_3 = i.isNullAt(1);
/* 044 */       UTF8String value_3 = isNull_3 ?
/* 045 */       null : (i.getUTF8String(1));
/* 046 */       if (!isNull_3) {
/* 047 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(value_3.getBaseObject(), value_3.getBaseOffset(), value_3.numBytes(), value_1);
/* 048 */       }
/* 049 */
/* 050 */       int remainder_0 = value_1 % 200;
/* 051 */       if (remainder_0 < 0) {
/* 052 */         value_0=(remainder_0 + 200) % 200;
/* 053 */       } else {
/* 054 */         value_0=remainder_0;
/* 055 */       }
/* 056 */
/* 057 */     }
/* 058 */     if (isNull_0) {
/* 059 */       mutableStateArray_0[0].setNullAt(0);
/* 060 */     } else {
/* 061 */       mutableStateArray_0[0].write(0, value_0);
/* 062 */     }
/* 063 */     return (mutableStateArray_0[0].getRow());
/* 064 */   }
/* 065 */
/* 066 */
/* 067 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = false;
/* 032 */     int value_0 = -1;
/* 033 */     if (200 == 0) {
/* 034 */       isNull_0 = true;
/* 035 */     } else {
/* 036 */       int value_1 = 42;
/* 037 */       boolean isNull_2 = i.isNullAt(0);
/* 038 */       int value_2 = isNull_2 ?
/* 039 */       -1 : (i.getInt(0));
/* 040 */       if (!isNull_2) {
/* 041 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashInt(value_2, value_1);
/* 042 */       }
/* 043 */       boolean isNull_3 = i.isNullAt(1);
/* 044 */       UTF8String value_3 = isNull_3 ?
/* 045 */       null : (i.getUTF8String(1));
/* 046 */       if (!isNull_3) {
/* 047 */         value_1 = org.apache.spark.unsafe.hash.Murmur3_x86_32.hashUnsafeBytes(value_3.getBaseObject(), value_3.getBaseOffset(), value_3.numBytes(), value_1);
/* 048 */       }
/* 049 */
/* 050 */       int remainder_0 = value_1 % 200;
/* 051 */       if (remainder_0 < 0) {
/* 052 */         value_0=(remainder_0 + 200) % 200;
/* 053 */       } else {
/* 054 */         value_0=remainder_0;
/* 055 */       }
/* 056 */
/* 057 */     }
/* 058 */     if (isNull_0) {
/* 059 */       mutableStateArray_0[0].setNullAt(0);
/* 060 */     } else {
/* 061 */       mutableStateArray_0[0].write(0, value_0);
/* 062 */     }
/* 063 */     return (mutableStateArray_0[0].getRow());
/* 064 */   }
/* 065 */
/* 066 */
/* 067 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 15.9489 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 9.1272 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 8 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@28fd79e8
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 INFO  FileScanRDD:54 - Reading File path: file:///C:/Users/Anukul%20Thalkar/IdeaProjects/UseCases/src/main/resources/retail_db/categories/part-00000, range: 0-1078, partition values: [empty row]
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, int, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     int value_1 = isNull_1 ?
/* 042 */     -1 : (i.getInt(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 INFO  CodeGenerator:54 - Code generated in 8.6151 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_18
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_18 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 8 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@28fd79e8
2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 8 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@28fd79e8
2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 8 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@28fd79e8
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 0.0 in stage 8.0 (TID 8). 3980 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_8.0, runningTasks: 0
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 8.0 (TID 8) in 212 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:17 INFO  DAGScheduler:54 - ShuffleMapStage 8 (count at UseCase5Test.java:25) finished in 0.228 s
2022-02-09 13:09:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2022-02-09 13:09:17 INFO  DAGScheduler:54 - running: Set()
2022-02-09 13:09:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 9)
2022-02-09 13:09:17 INFO  DAGScheduler:54 - failed: Set()
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Increasing epoch to 1
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitStage(ResultStage 9 (name=count at UseCase5Test.java:25;jobs=8))
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting ResultStage 9 (MapPartitionsRDD[43] at count at UseCase5Test.java:25), which has no missing parents
2022-02-09 13:09:17 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 9)
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_20 stored as values in memory (estimated size 30.6 KB, free 1967.1 MB)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_20 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_20 without replication took  0 ms
2022-02-09 13:09:17 INFO  MemoryStore:54 - Block broadcast_20_piece0 stored as bytes in memory (estimated size 14.2 KB, free 1967.1 MB)
2022-02-09 13:09:17 INFO  BlockManagerInfo:54 - Added broadcast_20_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 14.2 KB, free: 1970.3 MB)
2022-02-09 13:09:17 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_20_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Told master about block broadcast_20_piece0
2022-02-09 13:09:17 DEBUG BlockManager:58 - Put block broadcast_20_piece0 locally took  0 ms
2022-02-09 13:09:17 DEBUG BlockManager:58 - Putting block broadcast_20_piece0 without replication took  0 ms
2022-02-09 13:09:17 INFO  SparkContext:54 - Created broadcast 20 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:17 INFO  DAGScheduler:54 - Submitting 200 missing tasks from ResultStage 9 (MapPartitionsRDD[43] at count at UseCase5Test.java:25) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2022-02-09 13:09:17 INFO  TaskSchedulerImpl:54 - Adding task set 9.0 with 200 tasks
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Epoch for TaskSet 9.0: 1
2022-02-09 13:09:17 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 9.0: NO_PREF, ANY
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 0.0 in stage 9.0 (TID 9)
2022-02-09 13:09:17 DEBUG BlockManager:58 - Getting local block broadcast_20
2022-02-09 13:09:17 DEBUG BlockManager:58 - Level for block broadcast_20 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 0-1
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 9 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6e68829a
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 9 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6e68829a
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 0.0 in stage 9.0 (TID 9). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 9.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 1.0 in stage 9.0 (TID 10)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 9.0 (TID 9) in 47 ms on localhost (executor driver) (1/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 1-2
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 10 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@36508843
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 10 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@36508843
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 1.0 in stage 9.0 (TID 10). 4410 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 2.0 in stage 9.0 (TID 11, localhost, executor driver, partition 2, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 2.0 in stage 9.0 (TID 11)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 9.0 (TID 10) in 0 ms on localhost (executor driver) (2/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 2-3
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 11 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@367f72fe
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 11 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@367f72fe
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 2.0 in stage 9.0 (TID 11). 4539 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 3.0 in stage 9.0 (TID 12, localhost, executor driver, partition 3, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 3.0 in stage 9.0 (TID 12)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 2.0 in stage 9.0 (TID 11) in 17 ms on localhost (executor driver) (3/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 3-4
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 12 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3dfb68f8
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 12 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3dfb68f8
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 3.0 in stage 9.0 (TID 12). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 4.0 in stage 9.0 (TID 13, localhost, executor driver, partition 4, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 4.0 in stage 9.0 (TID 13)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 3.0 in stage 9.0 (TID 12) in 16 ms on localhost (executor driver) (4/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 4-5
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 13 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1e131436
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 13 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1e131436
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 4.0 in stage 9.0 (TID 13). 4410 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 5.0 in stage 9.0 (TID 14, localhost, executor driver, partition 5, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 5.0 in stage 9.0 (TID 14)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 4.0 in stage 9.0 (TID 13) in 15 ms on localhost (executor driver) (5/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 5-6
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 14 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@740ec826
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 14 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@740ec826
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 5.0 in stage 9.0 (TID 14). 4410 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 6.0 in stage 9.0 (TID 15, localhost, executor driver, partition 6, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 6.0 in stage 9.0 (TID 15)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 5.0 in stage 9.0 (TID 14) in 0 ms on localhost (executor driver) (6/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 6-7
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 15 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6b334175
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 15 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6b334175
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 6.0 in stage 9.0 (TID 15). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 7.0 in stage 9.0 (TID 16, localhost, executor driver, partition 7, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 7.0 in stage 9.0 (TID 16)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 6.0 in stage 9.0 (TID 15) in 16 ms on localhost (executor driver) (7/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 7-8
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 16 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@55feef97
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 16 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@55feef97
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 7.0 in stage 9.0 (TID 16). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 8.0 in stage 9.0 (TID 17, localhost, executor driver, partition 8, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 8.0 in stage 9.0 (TID 17)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 7.0 in stage 9.0 (TID 16) in 20 ms on localhost (executor driver) (8/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 8-9
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 17 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3cbadeac
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 17 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3cbadeac
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 8.0 in stage 9.0 (TID 17). 4453 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 9.0 in stage 9.0 (TID 18, localhost, executor driver, partition 9, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 9.0 in stage 9.0 (TID 18)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 8.0 in stage 9.0 (TID 17) in 5 ms on localhost (executor driver) (9/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 9-10
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 18 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6d960822
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 18 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6d960822
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 9.0 in stage 9.0 (TID 18). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 10.0 in stage 9.0 (TID 19, localhost, executor driver, partition 10, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 10.0 in stage 9.0 (TID 19)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 9.0 in stage 9.0 (TID 18) in 16 ms on localhost (executor driver) (10/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 10-11
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 19 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6b75d072
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 19 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6b75d072
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 10.0 in stage 9.0 (TID 19). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 11.0 in stage 9.0 (TID 20, localhost, executor driver, partition 11, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 11.0 in stage 9.0 (TID 20)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 10.0 in stage 9.0 (TID 19) in 16 ms on localhost (executor driver) (11/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 11-12
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 20 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@77b463d1
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 20 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@77b463d1
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 11.0 in stage 9.0 (TID 20). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 12.0 in stage 9.0 (TID 21, localhost, executor driver, partition 12, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 12.0 in stage 9.0 (TID 21)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 11.0 in stage 9.0 (TID 20) in 16 ms on localhost (executor driver) (12/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 12-13
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 21 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@998afda
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 21 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@998afda
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 12.0 in stage 9.0 (TID 21). 4410 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 13.0 in stage 9.0 (TID 22, localhost, executor driver, partition 13, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 13.0 in stage 9.0 (TID 22)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 12.0 in stage 9.0 (TID 21) in 16 ms on localhost (executor driver) (13/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 13-14
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 22 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@20fd28f8
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 22 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@20fd28f8
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 13.0 in stage 9.0 (TID 22). 4410 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 14.0 in stage 9.0 (TID 23, localhost, executor driver, partition 14, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 14.0 in stage 9.0 (TID 23)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 13.0 in stage 9.0 (TID 22) in 0 ms on localhost (executor driver) (14/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 14-15
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 23 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@452320ca
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 23 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@452320ca
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 14.0 in stage 9.0 (TID 23). 4496 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 15.0 in stage 9.0 (TID 24, localhost, executor driver, partition 15, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 15.0 in stage 9.0 (TID 24)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 14.0 in stage 9.0 (TID 23) in 15 ms on localhost (executor driver) (15/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 15-16
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 24 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5c55ba1f
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 24 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5c55ba1f
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 15.0 in stage 9.0 (TID 24). 4453 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 16.0 in stage 9.0 (TID 25, localhost, executor driver, partition 16, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 16.0 in stage 9.0 (TID 25)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 15.0 in stage 9.0 (TID 24) in 16 ms on localhost (executor driver) (16/200)
2022-02-09 13:09:17 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 16-17
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:17 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:17 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:224 - Task 25 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@85d290c
2022-02-09 13:09:17 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:17 DEBUG TaskMemoryManager:233 - Task 25 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@85d290c
2022-02-09 13:09:17 INFO  Executor:54 - Finished task 16.0 in stage 9.0 (TID 25). 4410 bytes result sent to driver
2022-02-09 13:09:17 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Starting task 17.0 in stage 9.0 (TID 26, localhost, executor driver, partition 17, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:17 INFO  Executor:54 - Running task 17.0 in stage 9.0 (TID 26)
2022-02-09 13:09:17 INFO  TaskSetManager:54 - Finished task 16.0 in stage 9.0 (TID 25) in 0 ms on localhost (executor driver) (17/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 17-18
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 26 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@31b4f689
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 26 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@31b4f689
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 17.0 in stage 9.0 (TID 26). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 18.0 in stage 9.0 (TID 27, localhost, executor driver, partition 18, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 18.0 in stage 9.0 (TID 27)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 17.0 in stage 9.0 (TID 26) in 16 ms on localhost (executor driver) (18/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 18-19
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 27 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5c2055a4
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 27 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5c2055a4
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 18.0 in stage 9.0 (TID 27). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 19.0 in stage 9.0 (TID 28, localhost, executor driver, partition 19, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 19.0 in stage 9.0 (TID 28)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 18.0 in stage 9.0 (TID 27) in 16 ms on localhost (executor driver) (19/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 19-20
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 28 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4175452f
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 28 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4175452f
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 19.0 in stage 9.0 (TID 28). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 20.0 in stage 9.0 (TID 29, localhost, executor driver, partition 20, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 20.0 in stage 9.0 (TID 29)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 19.0 in stage 9.0 (TID 28) in 16 ms on localhost (executor driver) (20/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 20-21
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 29 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@22eb942c
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 29 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@22eb942c
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 20.0 in stage 9.0 (TID 29). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 21.0 in stage 9.0 (TID 30, localhost, executor driver, partition 21, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 21.0 in stage 9.0 (TID 30)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 20.0 in stage 9.0 (TID 29) in 16 ms on localhost (executor driver) (21/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 21-22
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 30 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@fc8bea5
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 30 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@fc8bea5
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 21.0 in stage 9.0 (TID 30). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 22.0 in stage 9.0 (TID 31, localhost, executor driver, partition 22, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 22.0 in stage 9.0 (TID 31)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 21.0 in stage 9.0 (TID 30) in 16 ms on localhost (executor driver) (22/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 22-23
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 31 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@37ae2425
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 31 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@37ae2425
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 22.0 in stage 9.0 (TID 31). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 23.0 in stage 9.0 (TID 32, localhost, executor driver, partition 23, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 23.0 in stage 9.0 (TID 32)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 22.0 in stage 9.0 (TID 31) in 16 ms on localhost (executor driver) (23/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 23-24
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 32 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3e33c0fe
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 32 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3e33c0fe
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 23.0 in stage 9.0 (TID 32). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 24.0 in stage 9.0 (TID 33, localhost, executor driver, partition 24, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 24.0 in stage 9.0 (TID 33)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 23.0 in stage 9.0 (TID 32) in 0 ms on localhost (executor driver) (24/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 24-25
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 33 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@13b6368e
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 33 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@13b6368e
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 24.0 in stage 9.0 (TID 33). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 25.0 in stage 9.0 (TID 34, localhost, executor driver, partition 25, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 25.0 in stage 9.0 (TID 34)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 24.0 in stage 9.0 (TID 33) in 15 ms on localhost (executor driver) (25/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 25-26
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 34 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2f5833a6
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 34 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2f5833a6
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 25.0 in stage 9.0 (TID 34). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 26.0 in stage 9.0 (TID 35, localhost, executor driver, partition 26, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 26.0 in stage 9.0 (TID 35)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 25.0 in stage 9.0 (TID 34) in 18 ms on localhost (executor driver) (26/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 26-27
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 35 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4037a16d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 35 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4037a16d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 26.0 in stage 9.0 (TID 35). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 27.0 in stage 9.0 (TID 36, localhost, executor driver, partition 27, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 27.0 in stage 9.0 (TID 36)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 26.0 in stage 9.0 (TID 35) in 19 ms on localhost (executor driver) (27/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 27-28
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 36 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@125348a9
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 36 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@125348a9
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 27.0 in stage 9.0 (TID 36). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 28.0 in stage 9.0 (TID 37, localhost, executor driver, partition 28, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 28.0 in stage 9.0 (TID 37)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 27.0 in stage 9.0 (TID 36) in 3 ms on localhost (executor driver) (28/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 28-29
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 37 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@485874ef
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 37 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@485874ef
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 28.0 in stage 9.0 (TID 37). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 29.0 in stage 9.0 (TID 38, localhost, executor driver, partition 29, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 29.0 in stage 9.0 (TID 38)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 28.0 in stage 9.0 (TID 37) in 17 ms on localhost (executor driver) (29/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 29-30
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 38 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@70639ab
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 38 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@70639ab
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 29.0 in stage 9.0 (TID 38). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 30.0 in stage 9.0 (TID 39, localhost, executor driver, partition 30, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 30.0 in stage 9.0 (TID 39)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 29.0 in stage 9.0 (TID 38) in 14 ms on localhost (executor driver) (30/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 30-31
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 39 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@18505597
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 39 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@18505597
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 30.0 in stage 9.0 (TID 39). 4539 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 31.0 in stage 9.0 (TID 40, localhost, executor driver, partition 31, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 31.0 in stage 9.0 (TID 40)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 30.0 in stage 9.0 (TID 39) in 15 ms on localhost (executor driver) (31/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 31-32
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 40 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@29573475
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 40 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@29573475
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 31.0 in stage 9.0 (TID 40). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 32.0 in stage 9.0 (TID 41, localhost, executor driver, partition 32, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 32.0 in stage 9.0 (TID 41)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 31.0 in stage 9.0 (TID 40) in 15 ms on localhost (executor driver) (32/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 32-33
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 41 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@339dd292
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 41 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@339dd292
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 32.0 in stage 9.0 (TID 41). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 33.0 in stage 9.0 (TID 42, localhost, executor driver, partition 33, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 33.0 in stage 9.0 (TID 42)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 32.0 in stage 9.0 (TID 41) in 0 ms on localhost (executor driver) (33/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 33-34
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 42 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@65ea7b97
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 42 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@65ea7b97
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 33.0 in stage 9.0 (TID 42). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 34.0 in stage 9.0 (TID 43, localhost, executor driver, partition 34, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 34.0 in stage 9.0 (TID 43)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 33.0 in stage 9.0 (TID 42) in 16 ms on localhost (executor driver) (34/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 34-35
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 43 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6531d522
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 43 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6531d522
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 34.0 in stage 9.0 (TID 43). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 35.0 in stage 9.0 (TID 44, localhost, executor driver, partition 35, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 35.0 in stage 9.0 (TID 44)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 34.0 in stage 9.0 (TID 43) in 16 ms on localhost (executor driver) (35/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 35-36
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 44 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7b58eb6a
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 44 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7b58eb6a
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 35.0 in stage 9.0 (TID 44). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 36.0 in stage 9.0 (TID 45, localhost, executor driver, partition 36, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 36.0 in stage 9.0 (TID 45)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 35.0 in stage 9.0 (TID 44) in 0 ms on localhost (executor driver) (36/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 36-37
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 45 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@680bf63e
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 45 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@680bf63e
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 36.0 in stage 9.0 (TID 45). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 37.0 in stage 9.0 (TID 46, localhost, executor driver, partition 37, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 37.0 in stage 9.0 (TID 46)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 36.0 in stage 9.0 (TID 45) in 15 ms on localhost (executor driver) (37/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 37-38
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 46 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2f0f9517
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 46 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2f0f9517
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 37.0 in stage 9.0 (TID 46). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 38.0 in stage 9.0 (TID 47, localhost, executor driver, partition 38, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 38.0 in stage 9.0 (TID 47)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 37.0 in stage 9.0 (TID 46) in 16 ms on localhost (executor driver) (38/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 38-39
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 47 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@34b05ab
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 47 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@34b05ab
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 38.0 in stage 9.0 (TID 47). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 39.0 in stage 9.0 (TID 48, localhost, executor driver, partition 39, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 39.0 in stage 9.0 (TID 48)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 38.0 in stage 9.0 (TID 47) in 0 ms on localhost (executor driver) (39/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 39-40
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 48 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5471f668
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 48 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5471f668
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 39.0 in stage 9.0 (TID 48). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 40.0 in stage 9.0 (TID 49, localhost, executor driver, partition 40, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 40.0 in stage 9.0 (TID 49)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 39.0 in stage 9.0 (TID 48) in 17 ms on localhost (executor driver) (40/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 40-41
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 49 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@26a3297f
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 49 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@26a3297f
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 40.0 in stage 9.0 (TID 49). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 41.0 in stage 9.0 (TID 50, localhost, executor driver, partition 41, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 41.0 in stage 9.0 (TID 50)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 40.0 in stage 9.0 (TID 49) in 16 ms on localhost (executor driver) (41/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 41-42
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 50 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7112ec77
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 50 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7112ec77
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 41.0 in stage 9.0 (TID 50). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 42.0 in stage 9.0 (TID 51, localhost, executor driver, partition 42, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 42.0 in stage 9.0 (TID 51)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 41.0 in stage 9.0 (TID 50) in 0 ms on localhost (executor driver) (42/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 42-43
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 51 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@22cddf36
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 51 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@22cddf36
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 42.0 in stage 9.0 (TID 51). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 43.0 in stage 9.0 (TID 52, localhost, executor driver, partition 43, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 43.0 in stage 9.0 (TID 52)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 42.0 in stage 9.0 (TID 51) in 17 ms on localhost (executor driver) (43/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 43-44
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 52 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5eac23df
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 52 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5eac23df
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 43.0 in stage 9.0 (TID 52). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 44.0 in stage 9.0 (TID 53, localhost, executor driver, partition 44, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 44.0 in stage 9.0 (TID 53)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 43.0 in stage 9.0 (TID 52) in 16 ms on localhost (executor driver) (44/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 44-45
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 53 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@64eb95b5
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 53 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@64eb95b5
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 44.0 in stage 9.0 (TID 53). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 45.0 in stage 9.0 (TID 54, localhost, executor driver, partition 45, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 45.0 in stage 9.0 (TID 54)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 44.0 in stage 9.0 (TID 53) in 0 ms on localhost (executor driver) (45/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 45-46
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 54 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@577a84bd
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 54 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@577a84bd
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 45.0 in stage 9.0 (TID 54). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 46.0 in stage 9.0 (TID 55, localhost, executor driver, partition 46, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 46.0 in stage 9.0 (TID 55)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 45.0 in stage 9.0 (TID 54) in 16 ms on localhost (executor driver) (46/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 46-47
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 55 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5cdbbc25
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 55 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5cdbbc25
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 46.0 in stage 9.0 (TID 55). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 47.0 in stage 9.0 (TID 56, localhost, executor driver, partition 47, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 47.0 in stage 9.0 (TID 56)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 46.0 in stage 9.0 (TID 55) in 17 ms on localhost (executor driver) (47/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 47-48
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 56 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6d96b2ae
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 56 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6d96b2ae
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 47.0 in stage 9.0 (TID 56). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 48.0 in stage 9.0 (TID 57, localhost, executor driver, partition 48, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 48.0 in stage 9.0 (TID 57)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 47.0 in stage 9.0 (TID 56) in 15 ms on localhost (executor driver) (48/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 48-49
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 57 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@397d7044
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 57 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@397d7044
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 48.0 in stage 9.0 (TID 57). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 49.0 in stage 9.0 (TID 58, localhost, executor driver, partition 49, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 49.0 in stage 9.0 (TID 58)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 48.0 in stage 9.0 (TID 57) in 21 ms on localhost (executor driver) (49/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 49-50
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 58 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@93f5eab
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 58 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@93f5eab
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 49.0 in stage 9.0 (TID 58). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 50.0 in stage 9.0 (TID 59, localhost, executor driver, partition 50, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 50.0 in stage 9.0 (TID 59)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 49.0 in stage 9.0 (TID 58) in 18 ms on localhost (executor driver) (50/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 50-51
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 59 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5ded2b5c
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 59 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5ded2b5c
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 50.0 in stage 9.0 (TID 59). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 51.0 in stage 9.0 (TID 60, localhost, executor driver, partition 51, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 51.0 in stage 9.0 (TID 60)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 50.0 in stage 9.0 (TID 59) in 13 ms on localhost (executor driver) (51/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 51-52
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 60 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@70b68502
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 60 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@70b68502
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 51.0 in stage 9.0 (TID 60). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 52.0 in stage 9.0 (TID 61, localhost, executor driver, partition 52, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 52.0 in stage 9.0 (TID 61)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 51.0 in stage 9.0 (TID 60) in 7 ms on localhost (executor driver) (52/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 52-53
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 61 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@51f817e9
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 61 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@51f817e9
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 52.0 in stage 9.0 (TID 61). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 53.0 in stage 9.0 (TID 62, localhost, executor driver, partition 53, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 53.0 in stage 9.0 (TID 62)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 52.0 in stage 9.0 (TID 61) in 19 ms on localhost (executor driver) (53/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 53-54
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 62 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1ba868d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 62 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1ba868d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 53.0 in stage 9.0 (TID 62). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 54.0 in stage 9.0 (TID 63, localhost, executor driver, partition 54, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 54.0 in stage 9.0 (TID 63)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 53.0 in stage 9.0 (TID 62) in 0 ms on localhost (executor driver) (54/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 54-55
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 63 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6815c8db
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 63 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6815c8db
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 54.0 in stage 9.0 (TID 63). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 55.0 in stage 9.0 (TID 64, localhost, executor driver, partition 55, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 55.0 in stage 9.0 (TID 64)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 54.0 in stage 9.0 (TID 63) in 16 ms on localhost (executor driver) (55/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 55-56
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 64 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1f00d8de
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 64 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1f00d8de
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 55.0 in stage 9.0 (TID 64). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 56.0 in stage 9.0 (TID 65, localhost, executor driver, partition 56, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 56.0 in stage 9.0 (TID 65)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 55.0 in stage 9.0 (TID 64) in 0 ms on localhost (executor driver) (56/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 56-57
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 65 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@582cdb19
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 65 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@582cdb19
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 56.0 in stage 9.0 (TID 65). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 57.0 in stage 9.0 (TID 66, localhost, executor driver, partition 57, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 57.0 in stage 9.0 (TID 66)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 56.0 in stage 9.0 (TID 65) in 16 ms on localhost (executor driver) (57/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 57-58
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 66 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@232d4da4
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 66 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@232d4da4
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 57.0 in stage 9.0 (TID 66). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 58.0 in stage 9.0 (TID 67, localhost, executor driver, partition 58, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 58.0 in stage 9.0 (TID 67)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 57.0 in stage 9.0 (TID 66) in 16 ms on localhost (executor driver) (58/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 58-59
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 67 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@564ab51
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 67 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@564ab51
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 58.0 in stage 9.0 (TID 67). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 59.0 in stage 9.0 (TID 68, localhost, executor driver, partition 59, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 59.0 in stage 9.0 (TID 68)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 58.0 in stage 9.0 (TID 67) in 0 ms on localhost (executor driver) (59/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 59-60
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 68 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2ed16d54
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 68 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2ed16d54
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 59.0 in stage 9.0 (TID 68). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 60.0 in stage 9.0 (TID 69, localhost, executor driver, partition 60, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 59.0 in stage 9.0 (TID 68) in 15 ms on localhost (executor driver) (60/200)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 60.0 in stage 9.0 (TID 69)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 60-61
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 69 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@41e39dd6
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 69 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@41e39dd6
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 60.0 in stage 9.0 (TID 69). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 61.0 in stage 9.0 (TID 70, localhost, executor driver, partition 61, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 61.0 in stage 9.0 (TID 70)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 60.0 in stage 9.0 (TID 69) in 6 ms on localhost (executor driver) (61/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 61-62
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 70 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@42a1adc5
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 70 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@42a1adc5
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 61.0 in stage 9.0 (TID 70). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 62.0 in stage 9.0 (TID 71, localhost, executor driver, partition 62, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 62.0 in stage 9.0 (TID 71)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 61.0 in stage 9.0 (TID 70) in 17 ms on localhost (executor driver) (62/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 62-63
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 71 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@492eac84
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 71 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@492eac84
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 62.0 in stage 9.0 (TID 71). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 63.0 in stage 9.0 (TID 72, localhost, executor driver, partition 63, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 63.0 in stage 9.0 (TID 72)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 62.0 in stage 9.0 (TID 71) in 5 ms on localhost (executor driver) (63/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 63-64
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 72 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@49a3a19a
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 72 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@49a3a19a
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 63.0 in stage 9.0 (TID 72). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 64.0 in stage 9.0 (TID 73, localhost, executor driver, partition 64, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 64.0 in stage 9.0 (TID 73)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 63.0 in stage 9.0 (TID 72) in 16 ms on localhost (executor driver) (64/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 64-65
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 73 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@390a7e14
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 73 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@390a7e14
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 64.0 in stage 9.0 (TID 73). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 65.0 in stage 9.0 (TID 74, localhost, executor driver, partition 65, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 65.0 in stage 9.0 (TID 74)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 64.0 in stage 9.0 (TID 73) in 8 ms on localhost (executor driver) (65/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 65-66
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 74 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6a9de63d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 74 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6a9de63d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 65.0 in stage 9.0 (TID 74). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 66.0 in stage 9.0 (TID 75, localhost, executor driver, partition 66, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 66.0 in stage 9.0 (TID 75)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 65.0 in stage 9.0 (TID 74) in 18 ms on localhost (executor driver) (66/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 66-67
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 75 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@163e31b0
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 75 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@163e31b0
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 66.0 in stage 9.0 (TID 75). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 67.0 in stage 9.0 (TID 76, localhost, executor driver, partition 67, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 67.0 in stage 9.0 (TID 76)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 66.0 in stage 9.0 (TID 75) in 0 ms on localhost (executor driver) (67/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 67-68
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 76 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7786c8e2
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 76 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7786c8e2
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 67.0 in stage 9.0 (TID 76). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 68.0 in stage 9.0 (TID 77, localhost, executor driver, partition 68, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 68.0 in stage 9.0 (TID 77)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 67.0 in stage 9.0 (TID 76) in 17 ms on localhost (executor driver) (68/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 68-69
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  2 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 77 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2c9a38c9
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 77 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2c9a38c9
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 68.0 in stage 9.0 (TID 77). 4582 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 69.0 in stage 9.0 (TID 78, localhost, executor driver, partition 69, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 69.0 in stage 9.0 (TID 78)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 68.0 in stage 9.0 (TID 77) in 21 ms on localhost (executor driver) (69/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 69-70
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 78 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@35a57d86
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 78 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@35a57d86
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 69.0 in stage 9.0 (TID 78). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 70.0 in stage 9.0 (TID 79, localhost, executor driver, partition 70, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 70.0 in stage 9.0 (TID 79)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 69.0 in stage 9.0 (TID 78) in 16 ms on localhost (executor driver) (70/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 70-71
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 79 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2894313
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 79 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2894313
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 70.0 in stage 9.0 (TID 79). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 71.0 in stage 9.0 (TID 80, localhost, executor driver, partition 71, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 71.0 in stage 9.0 (TID 80)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 70.0 in stage 9.0 (TID 79) in 16 ms on localhost (executor driver) (71/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 71-72
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 80 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@282b5e8f
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 80 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@282b5e8f
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 71.0 in stage 9.0 (TID 80). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 72.0 in stage 9.0 (TID 81, localhost, executor driver, partition 72, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 71.0 in stage 9.0 (TID 80) in 17 ms on localhost (executor driver) (72/200)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 72.0 in stage 9.0 (TID 81)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 72-73
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 81 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@fbd4f13
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 81 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@fbd4f13
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 72.0 in stage 9.0 (TID 81). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 73.0 in stage 9.0 (TID 82, localhost, executor driver, partition 73, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 73.0 in stage 9.0 (TID 82)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 72.0 in stage 9.0 (TID 81) in 0 ms on localhost (executor driver) (73/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 73-74
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 82 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@433d0e69
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 82 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@433d0e69
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 73.0 in stage 9.0 (TID 82). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 74.0 in stage 9.0 (TID 83, localhost, executor driver, partition 74, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 74.0 in stage 9.0 (TID 83)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 73.0 in stage 9.0 (TID 82) in 16 ms on localhost (executor driver) (74/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 74-75
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 83 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@58985197
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 83 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@58985197
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 74.0 in stage 9.0 (TID 83). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 75.0 in stage 9.0 (TID 84, localhost, executor driver, partition 75, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 75.0 in stage 9.0 (TID 84)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 74.0 in stage 9.0 (TID 83) in 16 ms on localhost (executor driver) (75/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 75-76
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 84 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@48b96fb8
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 84 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@48b96fb8
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 75.0 in stage 9.0 (TID 84). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 76.0 in stage 9.0 (TID 85, localhost, executor driver, partition 76, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 76.0 in stage 9.0 (TID 85)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 75.0 in stage 9.0 (TID 84) in 0 ms on localhost (executor driver) (76/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 76-77
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 85 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@76b3bfc4
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 85 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@76b3bfc4
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 76.0 in stage 9.0 (TID 85). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 77.0 in stage 9.0 (TID 86, localhost, executor driver, partition 77, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 77.0 in stage 9.0 (TID 86)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 76.0 in stage 9.0 (TID 85) in 16 ms on localhost (executor driver) (77/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 77-78
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 86 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5fb2378a
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 86 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5fb2378a
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 77.0 in stage 9.0 (TID 86). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 78.0 in stage 9.0 (TID 87, localhost, executor driver, partition 78, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 78.0 in stage 9.0 (TID 87)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 77.0 in stage 9.0 (TID 86) in 9 ms on localhost (executor driver) (78/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 78-79
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 87 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@c5af866
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 87 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@c5af866
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 78.0 in stage 9.0 (TID 87). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 79.0 in stage 9.0 (TID 88, localhost, executor driver, partition 79, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 79.0 in stage 9.0 (TID 88)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 78.0 in stage 9.0 (TID 87) in 16 ms on localhost (executor driver) (79/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 79-80
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 88 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@23e261a2
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 88 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@23e261a2
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 79.0 in stage 9.0 (TID 88). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 80.0 in stage 9.0 (TID 89, localhost, executor driver, partition 80, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 80.0 in stage 9.0 (TID 89)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 79.0 in stage 9.0 (TID 88) in 0 ms on localhost (executor driver) (80/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 80-81
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 89 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1c6e8b6d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 89 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1c6e8b6d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 80.0 in stage 9.0 (TID 89). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 81.0 in stage 9.0 (TID 90, localhost, executor driver, partition 81, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 81.0 in stage 9.0 (TID 90)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 80.0 in stage 9.0 (TID 89) in 22 ms on localhost (executor driver) (81/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 81-82
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 90 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5bcf9658
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 90 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5bcf9658
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 81.0 in stage 9.0 (TID 90). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 82.0 in stage 9.0 (TID 91, localhost, executor driver, partition 82, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 82.0 in stage 9.0 (TID 91)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 81.0 in stage 9.0 (TID 90) in 16 ms on localhost (executor driver) (82/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 82-83
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 91 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@91dd48b
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 91 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@91dd48b
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 82.0 in stage 9.0 (TID 91). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 83.0 in stage 9.0 (TID 92, localhost, executor driver, partition 83, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 83.0 in stage 9.0 (TID 92)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 82.0 in stage 9.0 (TID 91) in 17 ms on localhost (executor driver) (83/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 83-84
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 92 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@ff11e7f
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 92 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@ff11e7f
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 83.0 in stage 9.0 (TID 92). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 84.0 in stage 9.0 (TID 93, localhost, executor driver, partition 84, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 84.0 in stage 9.0 (TID 93)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 83.0 in stage 9.0 (TID 92) in 15 ms on localhost (executor driver) (84/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 84-85
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 93 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@66c33584
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 93 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@66c33584
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 84.0 in stage 9.0 (TID 93). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 85.0 in stage 9.0 (TID 94, localhost, executor driver, partition 85, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 85.0 in stage 9.0 (TID 94)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 84.0 in stage 9.0 (TID 93) in 15 ms on localhost (executor driver) (85/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 85-86
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 94 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@20cb0270
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 94 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@20cb0270
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 85.0 in stage 9.0 (TID 94). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 86.0 in stage 9.0 (TID 95, localhost, executor driver, partition 86, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 86.0 in stage 9.0 (TID 95)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 85.0 in stage 9.0 (TID 94) in 16 ms on localhost (executor driver) (86/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 86-87
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 95 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@140e050d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 95 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@140e050d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 86.0 in stage 9.0 (TID 95). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 87.0 in stage 9.0 (TID 96, localhost, executor driver, partition 87, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 86.0 in stage 9.0 (TID 95) in 0 ms on localhost (executor driver) (87/200)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 87.0 in stage 9.0 (TID 96)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 87-88
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 96 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2d6d7cf7
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 96 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2d6d7cf7
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 87.0 in stage 9.0 (TID 96). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 88.0 in stage 9.0 (TID 97, localhost, executor driver, partition 88, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 88.0 in stage 9.0 (TID 97)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 87.0 in stage 9.0 (TID 96) in 16 ms on localhost (executor driver) (88/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 88-89
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 97 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3f896c35
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 97 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3f896c35
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 88.0 in stage 9.0 (TID 97). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 89.0 in stage 9.0 (TID 98, localhost, executor driver, partition 89, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 89.0 in stage 9.0 (TID 98)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 88.0 in stage 9.0 (TID 97) in 0 ms on localhost (executor driver) (89/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 89-90
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  1 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 98 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7d2f70d0
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 98 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7d2f70d0
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 89.0 in stage 9.0 (TID 98). 4539 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 90.0 in stage 9.0 (TID 99, localhost, executor driver, partition 90, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 90.0 in stage 9.0 (TID 99)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 89.0 in stage 9.0 (TID 98) in 19 ms on localhost (executor driver) (90/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 90-91
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 99 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@68b1d03d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 99 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@68b1d03d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 90.0 in stage 9.0 (TID 99). 4539 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 91.0 in stage 9.0 (TID 100, localhost, executor driver, partition 91, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 90.0 in stage 9.0 (TID 99) in 16 ms on localhost (executor driver) (91/200)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 91.0 in stage 9.0 (TID 100)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 91-92
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 100 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1247d3b9
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 100 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1247d3b9
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 91.0 in stage 9.0 (TID 100). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 92.0 in stage 9.0 (TID 101, localhost, executor driver, partition 92, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 92.0 in stage 9.0 (TID 101)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 91.0 in stage 9.0 (TID 100) in 11 ms on localhost (executor driver) (92/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 92-93
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 101 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@563d6666
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 101 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@563d6666
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 92.0 in stage 9.0 (TID 101). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 93.0 in stage 9.0 (TID 102, localhost, executor driver, partition 93, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 93.0 in stage 9.0 (TID 102)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 92.0 in stage 9.0 (TID 101) in 16 ms on localhost (executor driver) (93/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 93-94
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 102 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@55ca25f1
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 102 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@55ca25f1
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 93.0 in stage 9.0 (TID 102). 4539 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 94.0 in stage 9.0 (TID 103, localhost, executor driver, partition 94, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 94.0 in stage 9.0 (TID 103)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 93.0 in stage 9.0 (TID 102) in 3 ms on localhost (executor driver) (94/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 94-95
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 103 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@80c0893
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 103 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@80c0893
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 94.0 in stage 9.0 (TID 103). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 95.0 in stage 9.0 (TID 104, localhost, executor driver, partition 95, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 95.0 in stage 9.0 (TID 104)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 94.0 in stage 9.0 (TID 103) in 16 ms on localhost (executor driver) (95/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 95-96
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 104 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3aa2ac9c
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 104 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3aa2ac9c
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 95.0 in stage 9.0 (TID 104). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 96.0 in stage 9.0 (TID 105, localhost, executor driver, partition 96, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 96.0 in stage 9.0 (TID 105)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 95.0 in stage 9.0 (TID 104) in 0 ms on localhost (executor driver) (96/200)
2022-02-09 13:09:18 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(19)
2022-02-09 13:09:18 DEBUG ContextCleaner:58 - Cleaning broadcast 19
2022-02-09 13:09:18 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 19
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 96-97
2022-02-09 13:09:18 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 19
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 DEBUG BlockManager:58 - Removing broadcast 19
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 DEBUG BlockManager:58 - Removing block broadcast_19_piece0
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG MemoryStore:58 - Block broadcast_19_piece0 of size 14040 dropped from memory (free 2062687682)
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 INFO  BlockManagerInfo:54 - Removed broadcast_19_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 13.7 KB, free: 1970.3 MB)
2022-02-09 13:09:18 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_19_piece0
2022-02-09 13:09:18 DEBUG BlockManager:58 - Told master about block broadcast_19_piece0
2022-02-09 13:09:18 DEBUG BlockManager:58 - Removing block broadcast_19
2022-02-09 13:09:18 DEBUG MemoryStore:58 - Block broadcast_19 of size 31744 dropped from memory (free 2062719426)
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 105 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2ae46593
2022-02-09 13:09:18 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 19, response is 0
2022-02-09 13:09:18 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG ContextCleaner:58 - Cleaned broadcast 19
2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 105 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2ae46593
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 96.0 in stage 9.0 (TID 105). 4539 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 98.0 in stage 9.0 (TID 106, localhost, executor driver, partition 98, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 98.0 in stage 9.0 (TID 106)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 96.0 in stage 9.0 (TID 105) in 24 ms on localhost (executor driver) (97/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 98-99
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 106 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@133a025c
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 106 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@133a025c
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 98.0 in stage 9.0 (TID 106). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 99.0 in stage 9.0 (TID 107, localhost, executor driver, partition 99, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 99.0 in stage 9.0 (TID 107)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 98.0 in stage 9.0 (TID 106) in 0 ms on localhost (executor driver) (98/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 99-100
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 107 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6136baa4
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 107 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6136baa4
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 99.0 in stage 9.0 (TID 107). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 100.0 in stage 9.0 (TID 108, localhost, executor driver, partition 100, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 100.0 in stage 9.0 (TID 108)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 99.0 in stage 9.0 (TID 107) in 16 ms on localhost (executor driver) (99/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 100-101
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 108 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@91b2e6a
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 108 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@91b2e6a
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 100.0 in stage 9.0 (TID 108). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 101.0 in stage 9.0 (TID 109, localhost, executor driver, partition 101, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 101.0 in stage 9.0 (TID 109)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 100.0 in stage 9.0 (TID 108) in 0 ms on localhost (executor driver) (100/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 101-102
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 109 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7e637b00
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 109 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7e637b00
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 101.0 in stage 9.0 (TID 109). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 102.0 in stage 9.0 (TID 110, localhost, executor driver, partition 102, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 102.0 in stage 9.0 (TID 110)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 101.0 in stage 9.0 (TID 109) in 16 ms on localhost (executor driver) (101/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 102-103
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 110 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2c4e5450
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 110 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2c4e5450
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 102.0 in stage 9.0 (TID 110). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 103.0 in stage 9.0 (TID 111, localhost, executor driver, partition 103, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 103.0 in stage 9.0 (TID 111)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 102.0 in stage 9.0 (TID 110) in 16 ms on localhost (executor driver) (102/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 103-104
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 111 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2764e5e8
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 111 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2764e5e8
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 103.0 in stage 9.0 (TID 111). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 104.0 in stage 9.0 (TID 112, localhost, executor driver, partition 104, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 104.0 in stage 9.0 (TID 112)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 103.0 in stage 9.0 (TID 111) in 0 ms on localhost (executor driver) (103/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 104-105
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 112 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2697c1d
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 112 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2697c1d
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 104.0 in stage 9.0 (TID 112). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 105.0 in stage 9.0 (TID 113, localhost, executor driver, partition 105, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 105.0 in stage 9.0 (TID 113)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 104.0 in stage 9.0 (TID 112) in 16 ms on localhost (executor driver) (104/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 105-106
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  1 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 113 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@467fc450
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 113 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@467fc450
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 105.0 in stage 9.0 (TID 113). 4539 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 106.0 in stage 9.0 (TID 114, localhost, executor driver, partition 106, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 106.0 in stage 9.0 (TID 114)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 105.0 in stage 9.0 (TID 113) in 5 ms on localhost (executor driver) (105/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 106-107
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 114 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4b721515
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 114 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4b721515
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 106.0 in stage 9.0 (TID 114). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 107.0 in stage 9.0 (TID 115, localhost, executor driver, partition 107, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 107.0 in stage 9.0 (TID 115)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 106.0 in stage 9.0 (TID 114) in 8 ms on localhost (executor driver) (106/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 107-108
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 115 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@60653a58
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 115 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@60653a58
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 107.0 in stage 9.0 (TID 115). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 109.0 in stage 9.0 (TID 116, localhost, executor driver, partition 109, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 107.0 in stage 9.0 (TID 115) in 11 ms on localhost (executor driver) (107/200)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 109.0 in stage 9.0 (TID 116)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 109-110
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 116 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@e0be8e9
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 116 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@e0be8e9
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 109.0 in stage 9.0 (TID 116). 4453 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 110.0 in stage 9.0 (TID 117, localhost, executor driver, partition 110, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 110.0 in stage 9.0 (TID 117)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 109.0 in stage 9.0 (TID 116) in 8 ms on localhost (executor driver) (108/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 110-111
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 117 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@40fec123
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 117 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@40fec123
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 110.0 in stage 9.0 (TID 117). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 111.0 in stage 9.0 (TID 118, localhost, executor driver, partition 111, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 110.0 in stage 9.0 (TID 117) in 16 ms on localhost (executor driver) (109/200)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 111.0 in stage 9.0 (TID 118)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 111-112
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 118 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4eb47d83
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 118 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4eb47d83
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 111.0 in stage 9.0 (TID 118). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 112.0 in stage 9.0 (TID 119, localhost, executor driver, partition 112, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 112.0 in stage 9.0 (TID 119)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 111.0 in stage 9.0 (TID 118) in 0 ms on localhost (executor driver) (110/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 112-113
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 119 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@643008aa
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 119 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@643008aa
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 112.0 in stage 9.0 (TID 119). 4496 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 113.0 in stage 9.0 (TID 120, localhost, executor driver, partition 113, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 113.0 in stage 9.0 (TID 120)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 112.0 in stage 9.0 (TID 119) in 16 ms on localhost (executor driver) (111/200)
2022-02-09 13:09:18 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 113-114
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:18 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:18 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:224 - Task 120 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2e643a73
2022-02-09 13:09:18 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:18 DEBUG TaskMemoryManager:233 - Task 120 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2e643a73
2022-02-09 13:09:18 INFO  Executor:54 - Finished task 113.0 in stage 9.0 (TID 120). 4410 bytes result sent to driver
2022-02-09 13:09:18 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Starting task 114.0 in stage 9.0 (TID 121, localhost, executor driver, partition 114, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:18 INFO  Executor:54 - Running task 114.0 in stage 9.0 (TID 121)
2022-02-09 13:09:18 INFO  TaskSetManager:54 - Finished task 113.0 in stage 9.0 (TID 120) in 0 ms on localhost (executor driver) (112/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 114-115
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 121 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@35b2522a
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 121 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@35b2522a
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 114.0 in stage 9.0 (TID 121). 4539 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 115.0 in stage 9.0 (TID 122, localhost, executor driver, partition 115, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 115.0 in stage 9.0 (TID 122)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 114.0 in stage 9.0 (TID 121) in 15 ms on localhost (executor driver) (113/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 115-116
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 122 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4c691e9f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 122 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4c691e9f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 115.0 in stage 9.0 (TID 122). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 117.0 in stage 9.0 (TID 123, localhost, executor driver, partition 117, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 117.0 in stage 9.0 (TID 123)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 115.0 in stage 9.0 (TID 122) in 8 ms on localhost (executor driver) (114/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 117-118
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 123 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7c1cd383
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 123 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7c1cd383
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 117.0 in stage 9.0 (TID 123). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 118.0 in stage 9.0 (TID 124, localhost, executor driver, partition 118, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 118.0 in stage 9.0 (TID 124)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 117.0 in stage 9.0 (TID 123) in 22 ms on localhost (executor driver) (115/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 118-119
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 124 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@30b4f9a
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 124 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@30b4f9a
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 118.0 in stage 9.0 (TID 124). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 119.0 in stage 9.0 (TID 125, localhost, executor driver, partition 119, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 119.0 in stage 9.0 (TID 125)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 118.0 in stage 9.0 (TID 124) in 6 ms on localhost (executor driver) (116/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 119-120
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 125 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4b546845
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 125 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4b546845
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 119.0 in stage 9.0 (TID 125). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 120.0 in stage 9.0 (TID 126, localhost, executor driver, partition 120, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 120.0 in stage 9.0 (TID 126)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 119.0 in stage 9.0 (TID 125) in 16 ms on localhost (executor driver) (117/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 120-121
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 126 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4bef4595
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 126 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4bef4595
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 120.0 in stage 9.0 (TID 126). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 121.0 in stage 9.0 (TID 127, localhost, executor driver, partition 121, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 121.0 in stage 9.0 (TID 127)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 120.0 in stage 9.0 (TID 126) in 0 ms on localhost (executor driver) (118/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 121-122
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 127 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3698fd80
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 127 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3698fd80
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 121.0 in stage 9.0 (TID 127). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 122.0 in stage 9.0 (TID 128, localhost, executor driver, partition 122, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 122.0 in stage 9.0 (TID 128)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 121.0 in stage 9.0 (TID 127) in 16 ms on localhost (executor driver) (119/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 122-123
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 128 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1b2c49f9
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 128 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1b2c49f9
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 122.0 in stage 9.0 (TID 128). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 123.0 in stage 9.0 (TID 129, localhost, executor driver, partition 123, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 123.0 in stage 9.0 (TID 129)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 122.0 in stage 9.0 (TID 128) in 0 ms on localhost (executor driver) (120/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 123-124
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 129 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4f7b1334
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 129 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4f7b1334
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 123.0 in stage 9.0 (TID 129). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 124.0 in stage 9.0 (TID 130, localhost, executor driver, partition 124, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 124.0 in stage 9.0 (TID 130)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 123.0 in stage 9.0 (TID 129) in 16 ms on localhost (executor driver) (121/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 124-125
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 130 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1cc2714b
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 130 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1cc2714b
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 124.0 in stage 9.0 (TID 130). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 125.0 in stage 9.0 (TID 131, localhost, executor driver, partition 125, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 125.0 in stage 9.0 (TID 131)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 124.0 in stage 9.0 (TID 130) in 0 ms on localhost (executor driver) (122/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 125-126
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 131 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2d1523f6
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 131 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2d1523f6
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 125.0 in stage 9.0 (TID 131). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 126.0 in stage 9.0 (TID 132, localhost, executor driver, partition 126, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 126.0 in stage 9.0 (TID 132)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 125.0 in stage 9.0 (TID 131) in 16 ms on localhost (executor driver) (123/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 126-127
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 132 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@59fd5150
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 132 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@59fd5150
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 126.0 in stage 9.0 (TID 132). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 127.0 in stage 9.0 (TID 133, localhost, executor driver, partition 127, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 127.0 in stage 9.0 (TID 133)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 126.0 in stage 9.0 (TID 132) in 15 ms on localhost (executor driver) (124/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 127-128
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 133 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5f0c87a
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 133 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5f0c87a
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 127.0 in stage 9.0 (TID 133). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 128.0 in stage 9.0 (TID 134, localhost, executor driver, partition 128, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 128.0 in stage 9.0 (TID 134)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 127.0 in stage 9.0 (TID 133) in 16 ms on localhost (executor driver) (125/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 128-129
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 134 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@37c02ce7
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 134 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@37c02ce7
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 128.0 in stage 9.0 (TID 134). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 129.0 in stage 9.0 (TID 135, localhost, executor driver, partition 129, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 129.0 in stage 9.0 (TID 135)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 128.0 in stage 9.0 (TID 134) in 0 ms on localhost (executor driver) (126/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 129-130
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 135 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5dca2c3f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 135 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5dca2c3f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 129.0 in stage 9.0 (TID 135). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 130.0 in stage 9.0 (TID 136, localhost, executor driver, partition 130, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 130.0 in stage 9.0 (TID 136)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 129.0 in stage 9.0 (TID 135) in 17 ms on localhost (executor driver) (127/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 130-131
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 136 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@bde169
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 136 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@bde169
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 130.0 in stage 9.0 (TID 136). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 131.0 in stage 9.0 (TID 137, localhost, executor driver, partition 131, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 131.0 in stage 9.0 (TID 137)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 130.0 in stage 9.0 (TID 136) in 15 ms on localhost (executor driver) (128/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 131-132
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 137 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3fa77dd9
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 137 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3fa77dd9
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 131.0 in stage 9.0 (TID 137). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 132.0 in stage 9.0 (TID 138, localhost, executor driver, partition 132, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 132.0 in stage 9.0 (TID 138)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 131.0 in stage 9.0 (TID 137) in 15 ms on localhost (executor driver) (129/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 132-133
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 138 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@45b7f105
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 138 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@45b7f105
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 132.0 in stage 9.0 (TID 138). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 133.0 in stage 9.0 (TID 139, localhost, executor driver, partition 133, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 133.0 in stage 9.0 (TID 139)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 132.0 in stage 9.0 (TID 138) in 20 ms on localhost (executor driver) (130/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 133-134
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 139 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3b6f4cee
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 139 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3b6f4cee
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 133.0 in stage 9.0 (TID 139). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 135.0 in stage 9.0 (TID 140, localhost, executor driver, partition 135, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 135.0 in stage 9.0 (TID 140)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 133.0 in stage 9.0 (TID 139) in 0 ms on localhost (executor driver) (131/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 135-136
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 140 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@12c466f1
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 140 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@12c466f1
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 135.0 in stage 9.0 (TID 140). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 136.0 in stage 9.0 (TID 141, localhost, executor driver, partition 136, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 136.0 in stage 9.0 (TID 141)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 135.0 in stage 9.0 (TID 140) in 9 ms on localhost (executor driver) (132/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 136-137
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 141 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@f53f250
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 141 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@f53f250
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 136.0 in stage 9.0 (TID 141). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 137.0 in stage 9.0 (TID 142, localhost, executor driver, partition 137, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 137.0 in stage 9.0 (TID 142)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 136.0 in stage 9.0 (TID 141) in 6 ms on localhost (executor driver) (133/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 137-138
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 142 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1db85b87
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 142 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1db85b87
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 137.0 in stage 9.0 (TID 142). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 138.0 in stage 9.0 (TID 143, localhost, executor driver, partition 138, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 137.0 in stage 9.0 (TID 142) in 16 ms on localhost (executor driver) (134/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 138.0 in stage 9.0 (TID 143)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 138-139
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 143 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@38c341c0
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 143 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@38c341c0
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 138.0 in stage 9.0 (TID 143). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 139.0 in stage 9.0 (TID 144, localhost, executor driver, partition 139, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 139.0 in stage 9.0 (TID 144)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 138.0 in stage 9.0 (TID 143) in 0 ms on localhost (executor driver) (135/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 139-140
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 144 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@433a823f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 144 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@433a823f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 139.0 in stage 9.0 (TID 144). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 140.0 in stage 9.0 (TID 145, localhost, executor driver, partition 140, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 140.0 in stage 9.0 (TID 145)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 139.0 in stage 9.0 (TID 144) in 16 ms on localhost (executor driver) (136/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 140-141
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 145 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@8e4bf31
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 145 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@8e4bf31
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 140.0 in stage 9.0 (TID 145). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 141.0 in stage 9.0 (TID 146, localhost, executor driver, partition 141, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 141.0 in stage 9.0 (TID 146)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 140.0 in stage 9.0 (TID 145) in 16 ms on localhost (executor driver) (137/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 141-142
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 146 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@68ddf551
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 146 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@68ddf551
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 141.0 in stage 9.0 (TID 146). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 142.0 in stage 9.0 (TID 147, localhost, executor driver, partition 142, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 142.0 in stage 9.0 (TID 147)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 141.0 in stage 9.0 (TID 146) in 0 ms on localhost (executor driver) (138/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 142-143
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 147 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5d220af6
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 147 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5d220af6
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 142.0 in stage 9.0 (TID 147). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 143.0 in stage 9.0 (TID 148, localhost, executor driver, partition 143, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 143.0 in stage 9.0 (TID 148)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 142.0 in stage 9.0 (TID 147) in 16 ms on localhost (executor driver) (139/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 143-144
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 148 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@30e11528
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 148 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@30e11528
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 143.0 in stage 9.0 (TID 148). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 144.0 in stage 9.0 (TID 149, localhost, executor driver, partition 144, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 144.0 in stage 9.0 (TID 149)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 143.0 in stage 9.0 (TID 148) in 0 ms on localhost (executor driver) (140/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 144-145
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 149 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7cf29845
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 149 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7cf29845
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 144.0 in stage 9.0 (TID 149). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 145.0 in stage 9.0 (TID 150, localhost, executor driver, partition 145, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 145.0 in stage 9.0 (TID 150)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 144.0 in stage 9.0 (TID 149) in 15 ms on localhost (executor driver) (141/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 145-146
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 150 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@24ad6ef0
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 150 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@24ad6ef0
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 145.0 in stage 9.0 (TID 150). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 146.0 in stage 9.0 (TID 151, localhost, executor driver, partition 146, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 146.0 in stage 9.0 (TID 151)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 145.0 in stage 9.0 (TID 150) in 0 ms on localhost (executor driver) (142/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 146-147
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 151 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5996382f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 151 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5996382f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 146.0 in stage 9.0 (TID 151). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 147.0 in stage 9.0 (TID 152, localhost, executor driver, partition 147, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 147.0 in stage 9.0 (TID 152)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 146.0 in stage 9.0 (TID 151) in 17 ms on localhost (executor driver) (143/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 147-148
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 152 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@51eba70
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 152 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@51eba70
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 147.0 in stage 9.0 (TID 152). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 148.0 in stage 9.0 (TID 153, localhost, executor driver, partition 148, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 148.0 in stage 9.0 (TID 153)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 147.0 in stage 9.0 (TID 152) in 0 ms on localhost (executor driver) (144/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 148-149
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 153 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@45512ff6
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 153 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@45512ff6
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 148.0 in stage 9.0 (TID 153). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 149.0 in stage 9.0 (TID 154, localhost, executor driver, partition 149, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 149.0 in stage 9.0 (TID 154)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 148.0 in stage 9.0 (TID 153) in 16 ms on localhost (executor driver) (145/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 149-150
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 154 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@528a2bde
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 154 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@528a2bde
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 149.0 in stage 9.0 (TID 154). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 150.0 in stage 9.0 (TID 155, localhost, executor driver, partition 150, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 150.0 in stage 9.0 (TID 155)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 149.0 in stage 9.0 (TID 154) in 0 ms on localhost (executor driver) (146/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 150-151
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 155 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3a150fdf
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 155 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3a150fdf
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 150.0 in stage 9.0 (TID 155). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 151.0 in stage 9.0 (TID 156, localhost, executor driver, partition 151, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 151.0 in stage 9.0 (TID 156)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 150.0 in stage 9.0 (TID 155) in 0 ms on localhost (executor driver) (147/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 151-152
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 15 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  15 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 156 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@51e48f2c
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 156 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@51e48f2c
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 151.0 in stage 9.0 (TID 156). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 152.0 in stage 9.0 (TID 157, localhost, executor driver, partition 152, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 152.0 in stage 9.0 (TID 157)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 151.0 in stage 9.0 (TID 156) in 16 ms on localhost (executor driver) (148/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 152-153
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 157 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@676a8cf3
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 157 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@676a8cf3
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 152.0 in stage 9.0 (TID 157). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 153.0 in stage 9.0 (TID 158, localhost, executor driver, partition 153, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 153.0 in stage 9.0 (TID 158)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 152.0 in stage 9.0 (TID 157) in 0 ms on localhost (executor driver) (149/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 153-154
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  1 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 158 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@294e9c5c
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 158 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@294e9c5c
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 153.0 in stage 9.0 (TID 158). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 154.0 in stage 9.0 (TID 159, localhost, executor driver, partition 154, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 154.0 in stage 9.0 (TID 159)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 153.0 in stage 9.0 (TID 158) in 17 ms on localhost (executor driver) (150/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 154-155
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 159 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7251293
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 159 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7251293
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 154.0 in stage 9.0 (TID 159). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 155.0 in stage 9.0 (TID 160, localhost, executor driver, partition 155, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 154.0 in stage 9.0 (TID 159) in 5 ms on localhost (executor driver) (151/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 155.0 in stage 9.0 (TID 160)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 155-156
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 160 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2d16bba4
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 160 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2d16bba4
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 155.0 in stage 9.0 (TID 160). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 157.0 in stage 9.0 (TID 161, localhost, executor driver, partition 157, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 157.0 in stage 9.0 (TID 161)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 155.0 in stage 9.0 (TID 160) in 0 ms on localhost (executor driver) (152/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 157-158
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 161 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1fe9e406
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 161 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1fe9e406
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 157.0 in stage 9.0 (TID 161). 4539 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 158.0 in stage 9.0 (TID 162, localhost, executor driver, partition 158, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 157.0 in stage 9.0 (TID 161) in 25 ms on localhost (executor driver) (153/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 158.0 in stage 9.0 (TID 162)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 158-159
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 162 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@a8bc34b
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 162 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@a8bc34b
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 158.0 in stage 9.0 (TID 162). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 159.0 in stage 9.0 (TID 163, localhost, executor driver, partition 159, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 159.0 in stage 9.0 (TID 163)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 158.0 in stage 9.0 (TID 162) in 7 ms on localhost (executor driver) (154/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 159-160
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 163 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5c7ffeec
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 163 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5c7ffeec
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 159.0 in stage 9.0 (TID 163). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 160.0 in stage 9.0 (TID 164, localhost, executor driver, partition 160, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 160.0 in stage 9.0 (TID 164)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 159.0 in stage 9.0 (TID 163) in 16 ms on localhost (executor driver) (155/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 160-161
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 164 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@28b0c169
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 164 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@28b0c169
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 160.0 in stage 9.0 (TID 164). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 161.0 in stage 9.0 (TID 165, localhost, executor driver, partition 161, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 161.0 in stage 9.0 (TID 165)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 160.0 in stage 9.0 (TID 164) in 0 ms on localhost (executor driver) (156/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 161-162
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 165 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7b92e37c
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 165 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7b92e37c
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 161.0 in stage 9.0 (TID 165). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 162.0 in stage 9.0 (TID 166, localhost, executor driver, partition 162, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 162.0 in stage 9.0 (TID 166)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 161.0 in stage 9.0 (TID 165) in 16 ms on localhost (executor driver) (157/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 162-163
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 166 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@587ad642
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 166 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@587ad642
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 162.0 in stage 9.0 (TID 166). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 163.0 in stage 9.0 (TID 167, localhost, executor driver, partition 163, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 163.0 in stage 9.0 (TID 167)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 162.0 in stage 9.0 (TID 166) in 0 ms on localhost (executor driver) (158/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 163-164
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 167 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4753809e
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 167 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4753809e
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 163.0 in stage 9.0 (TID 167). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 164.0 in stage 9.0 (TID 168, localhost, executor driver, partition 164, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 164.0 in stage 9.0 (TID 168)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 163.0 in stage 9.0 (TID 167) in 17 ms on localhost (executor driver) (159/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 164-165
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 168 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@38f40c6c
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 168 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@38f40c6c
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 164.0 in stage 9.0 (TID 168). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 165.0 in stage 9.0 (TID 169, localhost, executor driver, partition 165, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 165.0 in stage 9.0 (TID 169)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 164.0 in stage 9.0 (TID 168) in 15 ms on localhost (executor driver) (160/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 165-166
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 169 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@44d0fff4
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 169 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@44d0fff4
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 165.0 in stage 9.0 (TID 169). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 166.0 in stage 9.0 (TID 170, localhost, executor driver, partition 166, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 166.0 in stage 9.0 (TID 170)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 165.0 in stage 9.0 (TID 169) in 15 ms on localhost (executor driver) (161/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 166-167
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 170 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@107389e8
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 170 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@107389e8
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 166.0 in stage 9.0 (TID 170). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 167.0 in stage 9.0 (TID 171, localhost, executor driver, partition 167, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 167.0 in stage 9.0 (TID 171)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 166.0 in stage 9.0 (TID 170) in 16 ms on localhost (executor driver) (162/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 167-168
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 171 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2ea4cdf3
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 171 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2ea4cdf3
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 167.0 in stage 9.0 (TID 171). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 168.0 in stage 9.0 (TID 172, localhost, executor driver, partition 168, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 168.0 in stage 9.0 (TID 172)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 167.0 in stage 9.0 (TID 171) in 25 ms on localhost (executor driver) (163/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 168-169
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 172 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@34328e38
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 172 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@34328e38
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 168.0 in stage 9.0 (TID 172). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 169.0 in stage 9.0 (TID 173, localhost, executor driver, partition 169, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 169.0 in stage 9.0 (TID 173)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 168.0 in stage 9.0 (TID 172) in 8 ms on localhost (executor driver) (164/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 169-170
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 173 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3bf5c891
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 173 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3bf5c891
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 169.0 in stage 9.0 (TID 173). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 170.0 in stage 9.0 (TID 174, localhost, executor driver, partition 170, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 170.0 in stage 9.0 (TID 174)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 169.0 in stage 9.0 (TID 173) in 9 ms on localhost (executor driver) (165/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 170-171
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 174 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@55587a4a
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 174 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@55587a4a
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 170.0 in stage 9.0 (TID 174). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 171.0 in stage 9.0 (TID 175, localhost, executor driver, partition 171, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 171.0 in stage 9.0 (TID 175)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 170.0 in stage 9.0 (TID 174) in 0 ms on localhost (executor driver) (166/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 171-172
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 175 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3ad6efdb
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 175 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3ad6efdb
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 171.0 in stage 9.0 (TID 175). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 172.0 in stage 9.0 (TID 176, localhost, executor driver, partition 172, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 172.0 in stage 9.0 (TID 176)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 171.0 in stage 9.0 (TID 175) in 15 ms on localhost (executor driver) (167/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 172-173
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 176 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@52a5210d
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 176 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@52a5210d
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 172.0 in stage 9.0 (TID 176). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 173.0 in stage 9.0 (TID 177, localhost, executor driver, partition 173, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 173.0 in stage 9.0 (TID 177)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 172.0 in stage 9.0 (TID 176) in 0 ms on localhost (executor driver) (168/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 173-174
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 177 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5d1b3cee
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 177 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5d1b3cee
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 173.0 in stage 9.0 (TID 177). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 174.0 in stage 9.0 (TID 178, localhost, executor driver, partition 174, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 174.0 in stage 9.0 (TID 178)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 173.0 in stage 9.0 (TID 177) in 21 ms on localhost (executor driver) (169/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 174-175
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 178 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@41854d56
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 178 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@41854d56
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 174.0 in stage 9.0 (TID 178). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 175.0 in stage 9.0 (TID 179, localhost, executor driver, partition 175, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 175.0 in stage 9.0 (TID 179)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 174.0 in stage 9.0 (TID 178) in 3 ms on localhost (executor driver) (170/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 175-176
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 179 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@66c221e9
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 179 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@66c221e9
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 175.0 in stage 9.0 (TID 179). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 176.0 in stage 9.0 (TID 180, localhost, executor driver, partition 176, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 176.0 in stage 9.0 (TID 180)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 175.0 in stage 9.0 (TID 179) in 8 ms on localhost (executor driver) (171/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 176-177
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 180 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3e4a5921
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 180 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3e4a5921
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 176.0 in stage 9.0 (TID 180). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 177.0 in stage 9.0 (TID 181, localhost, executor driver, partition 177, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 177.0 in stage 9.0 (TID 181)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 176.0 in stage 9.0 (TID 180) in 16 ms on localhost (executor driver) (172/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 177-178
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 181 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4e7435f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 181 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4e7435f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 177.0 in stage 9.0 (TID 181). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 178.0 in stage 9.0 (TID 182, localhost, executor driver, partition 178, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 178.0 in stage 9.0 (TID 182)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 177.0 in stage 9.0 (TID 181) in 0 ms on localhost (executor driver) (173/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 178-179
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 182 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@31eaafba
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 182 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@31eaafba
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 178.0 in stage 9.0 (TID 182). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 179.0 in stage 9.0 (TID 183, localhost, executor driver, partition 179, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 179.0 in stage 9.0 (TID 183)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 178.0 in stage 9.0 (TID 182) in 0 ms on localhost (executor driver) (174/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 179-180
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 183 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@436a94b1
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 183 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@436a94b1
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 179.0 in stage 9.0 (TID 183). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 180.0 in stage 9.0 (TID 184, localhost, executor driver, partition 180, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 179.0 in stage 9.0 (TID 183) in 24 ms on localhost (executor driver) (175/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 180.0 in stage 9.0 (TID 184)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 180-181
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 2 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  2 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 184 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@639169f6
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 184 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@639169f6
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 180.0 in stage 9.0 (TID 184). 4539 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 181.0 in stage 9.0 (TID 185, localhost, executor driver, partition 181, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 181.0 in stage 9.0 (TID 185)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 180.0 in stage 9.0 (TID 184) in 10 ms on localhost (executor driver) (176/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 181-182
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 185 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@413ad9d2
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 185 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@413ad9d2
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 181.0 in stage 9.0 (TID 185). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 182.0 in stage 9.0 (TID 186, localhost, executor driver, partition 182, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 182.0 in stage 9.0 (TID 186)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 181.0 in stage 9.0 (TID 185) in 2 ms on localhost (executor driver) (177/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 182-183
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 186 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1e707c3
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 186 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1e707c3
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 182.0 in stage 9.0 (TID 186). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 183.0 in stage 9.0 (TID 187, localhost, executor driver, partition 183, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 182.0 in stage 9.0 (TID 186) in 16 ms on localhost (executor driver) (178/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 183.0 in stage 9.0 (TID 187)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 183-184
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 187 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@49fb38fd
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 187 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@49fb38fd
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 183.0 in stage 9.0 (TID 187). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 184.0 in stage 9.0 (TID 188, localhost, executor driver, partition 184, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 184.0 in stage 9.0 (TID 188)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 183.0 in stage 9.0 (TID 187) in 17 ms on localhost (executor driver) (179/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 184-185
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 188 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@416f7e50
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 188 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@416f7e50
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 184.0 in stage 9.0 (TID 188). 4453 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 185.0 in stage 9.0 (TID 189, localhost, executor driver, partition 185, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 185.0 in stage 9.0 (TID 189)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 184.0 in stage 9.0 (TID 188) in 1 ms on localhost (executor driver) (180/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 185-186
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 189 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6cf0eb3e
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 189 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6cf0eb3e
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 185.0 in stage 9.0 (TID 189). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 186.0 in stage 9.0 (TID 190, localhost, executor driver, partition 186, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 185.0 in stage 9.0 (TID 189) in 0 ms on localhost (executor driver) (181/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 186.0 in stage 9.0 (TID 190)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 186-187
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 190 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@29fefc0c
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 190 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@29fefc0c
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 186.0 in stage 9.0 (TID 190). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 187.0 in stage 9.0 (TID 191, localhost, executor driver, partition 187, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 186.0 in stage 9.0 (TID 190) in 15 ms on localhost (executor driver) (182/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 187.0 in stage 9.0 (TID 191)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 187-188
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 191 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@e526e40
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 191 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@e526e40
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 187.0 in stage 9.0 (TID 191). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 188.0 in stage 9.0 (TID 192, localhost, executor driver, partition 188, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 188.0 in stage 9.0 (TID 192)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 187.0 in stage 9.0 (TID 191) in 0 ms on localhost (executor driver) (183/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 188-189
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 192 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1d7a1896
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 192 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1d7a1896
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 188.0 in stage 9.0 (TID 192). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 189.0 in stage 9.0 (TID 193, localhost, executor driver, partition 189, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 189.0 in stage 9.0 (TID 193)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 188.0 in stage 9.0 (TID 192) in 18 ms on localhost (executor driver) (184/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 189-190
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 193 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@230c3b18
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 193 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@230c3b18
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 189.0 in stage 9.0 (TID 193). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 190.0 in stage 9.0 (TID 194, localhost, executor driver, partition 190, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 190.0 in stage 9.0 (TID 194)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 189.0 in stage 9.0 (TID 193) in 0 ms on localhost (executor driver) (185/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 190-191
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 194 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@645190c4
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 194 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@645190c4
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 190.0 in stage 9.0 (TID 194). 4539 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 191.0 in stage 9.0 (TID 195, localhost, executor driver, partition 191, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 191.0 in stage 9.0 (TID 195)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 190.0 in stage 9.0 (TID 194) in 17 ms on localhost (executor driver) (186/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 191-192
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 195 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5e197b3f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 195 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5e197b3f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 191.0 in stage 9.0 (TID 195). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 192.0 in stage 9.0 (TID 196, localhost, executor driver, partition 192, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 192.0 in stage 9.0 (TID 196)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 191.0 in stage 9.0 (TID 195) in 0 ms on localhost (executor driver) (187/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 192-193
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 196 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7b4d47ff
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 196 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7b4d47ff
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 192.0 in stage 9.0 (TID 196). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 193.0 in stage 9.0 (TID 197, localhost, executor driver, partition 193, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 193.0 in stage 9.0 (TID 197)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 192.0 in stage 9.0 (TID 196) in 16 ms on localhost (executor driver) (188/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 193-194
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 197 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@251f0508
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 197 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@251f0508
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 193.0 in stage 9.0 (TID 197). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 194.0 in stage 9.0 (TID 198, localhost, executor driver, partition 194, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 194.0 in stage 9.0 (TID 198)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 193.0 in stage 9.0 (TID 197) in 0 ms on localhost (executor driver) (189/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 194-195
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  17 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 198 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2a351a53
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 198 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2a351a53
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 194.0 in stage 9.0 (TID 198). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 195.0 in stage 9.0 (TID 199, localhost, executor driver, partition 195, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 195.0 in stage 9.0 (TID 199)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 194.0 in stage 9.0 (TID 198) in 18 ms on localhost (executor driver) (190/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 195-196
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 199 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4544cde9
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 199 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4544cde9
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 195.0 in stage 9.0 (TID 199). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 196.0 in stage 9.0 (TID 200, localhost, executor driver, partition 196, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 196.0 in stage 9.0 (TID 200)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 195.0 in stage 9.0 (TID 199) in 0 ms on localhost (executor driver) (191/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 196-197
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 200 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1e7ab45e
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 200 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1e7ab45e
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 196.0 in stage 9.0 (TID 200). 4496 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 198.0 in stage 9.0 (TID 201, localhost, executor driver, partition 198, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 196.0 in stage 9.0 (TID 200) in 15 ms on localhost (executor driver) (192/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 198.0 in stage 9.0 (TID 201)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 198-199
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 201 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5b349a34
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 201 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5b349a34
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 198.0 in stage 9.0 (TID 201). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 199.0 in stage 9.0 (TID 202, localhost, executor driver, partition 199, PROCESS_LOCAL, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 199.0 in stage 9.0 (TID 202)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 198.0 in stage 9.0 (TID 201) in 0 ms on localhost (executor driver) (193/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 199-200
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 202 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4bb1d0be
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 202 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4bb1d0be
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 199.0 in stage 9.0 (TID 202). 4410 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 97.0 in stage 9.0 (TID 203, localhost, executor driver, partition 97, ANY, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 97.0 in stage 9.0 (TID 203)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 199.0 in stage 9.0 (TID 202) in 0 ms on localhost (executor driver) (194/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 97-98
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_97
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 203 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@148b388f
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 203 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@148b388f
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 203 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@148b388f
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 203 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@148b388f
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 97.0 in stage 9.0 (TID 203). 4647 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 108.0 in stage 9.0 (TID 204, localhost, executor driver, partition 108, ANY, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 108.0 in stage 9.0 (TID 204)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 97.0 in stage 9.0 (TID 203) in 32 ms on localhost (executor driver) (195/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 108-109
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_108
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 204 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2393f018
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 204 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@2393f018
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 204 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2393f018
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 204 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@2393f018
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 108.0 in stage 9.0 (TID 204). 4561 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 116.0 in stage 9.0 (TID 205, localhost, executor driver, partition 116, ANY, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 116.0 in stage 9.0 (TID 205)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 108.0 in stage 9.0 (TID 204) in 0 ms on localhost (executor driver) (196/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 116-117
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_116
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 205 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@66efbac5
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 205 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@66efbac5
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 205 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@66efbac5
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 205 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@66efbac5
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 116.0 in stage 9.0 (TID 205). 4561 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 134.0 in stage 9.0 (TID 206, localhost, executor driver, partition 134, ANY, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 134.0 in stage 9.0 (TID 206)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 116.0 in stage 9.0 (TID 205) in 15 ms on localhost (executor driver) (197/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 134-135
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_134
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 206 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2e68f4fb
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 206 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@2e68f4fb
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 206 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2e68f4fb
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 206 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@2e68f4fb
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 134.0 in stage 9.0 (TID 206). 4561 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 156.0 in stage 9.0 (TID 207, localhost, executor driver, partition 156, ANY, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 156.0 in stage 9.0 (TID 207)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 134.0 in stage 9.0 (TID 206) in 0 ms on localhost (executor driver) (198/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 156-157
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_156
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 207 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@341263e8
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 207 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@341263e8
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 207 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@341263e8
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 207 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@341263e8
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 156.0 in stage 9.0 (TID 207). 4561 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 197.0 in stage 9.0 (TID 208, localhost, executor driver, partition 197, ANY, 7767 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 197.0 in stage 9.0 (TID 208)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 156.0 in stage 9.0 (TID 207) in 0 ms on localhost (executor driver) (199/200)
2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 197-198
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_197
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 208 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@57395d72
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 208 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@57395d72
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 208 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@57395d72
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 208 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@57395d72
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 197.0 in stage 9.0 (TID 208). 4647 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_9.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 197.0 in stage 9.0 (TID 208) in 16 ms on localhost (executor driver) (200/200)
2022-02-09 13:09:19 INFO  TaskSchedulerImpl:54 - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2022-02-09 13:09:19 INFO  DAGScheduler:54 - ResultStage 9 (count at UseCase5Test.java:25) finished in 2.004 s
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - After removal of stage 8, remaining stages = 1
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - After removal of stage 9, remaining stages = 0
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Job 8 finished: count at UseCase5Test.java:25, took 2.258012 s
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared fields: 4
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.serialVersionUID
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final org.apache.spark.sql.catalyst.expressions.codegen.CodeAndComment org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.cleanedSource$2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final java.lang.Object[] org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.references$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final org.apache.spark.sql.execution.metric.SQLMetric org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.durationMs$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final scala.collection.Iterator org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13.apply(int,scala.collection.Iterator)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13) is now cleaned +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.serialVersionUID
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD$$anonfun$collect$1 org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.$outer
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(java.lang.Object)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15.apply(scala.collection.Iterator)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer classes: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer objects: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      <function0>
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[50] at count at UseCase5Test.java:25
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[50] at count at UseCase5Test.java:25)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + cloning the object <function0> of class org.apache.spark.rdd.RDD$$anonfun$collect$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.RDD$$anonfun$collect$1)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.rdd.RDD$$anonfun$collect$1.serialVersionUID
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.$outer
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$collect$1.apply()
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public org.apache.spark.rdd.RDD org.apache.spark.rdd.RDD$$anonfun$collect$1.org$apache$spark$rdd$RDD$$anonfun$$$outer()
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + inner classes: 1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer classes: 1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      org.apache.spark.rdd.RDD
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer objects: 1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      MapPartitionsRDD[50] at count at UseCase5Test.java:25
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 4 classes
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class java.lang.Object,Set())
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD,Set(org$apache$spark$rdd$RDD$$evidence$1))
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class org.apache.spark.rdd.RDD$$anonfun$collect$1,Set($outer))
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      (class scala.runtime.AbstractFunction0,Set())
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outermost object is not a closure or REPL line object,so do not clone it: (class org.apache.spark.rdd.RDD,MapPartitionsRDD[50] at count at UseCase5Test.java:25)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  +++ closure <function0> (org.apache.spark.rdd.RDD$$anonfun$collect$1) is now cleaned +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$15) is now cleaned +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 - +++ Cleaning closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) +++
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared fields: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public static final long org.apache.spark.SparkContext$$anonfun$runJob$5.serialVersionUID
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      private final scala.Function1 org.apache.spark.SparkContext$$anonfun$runJob$5.cleanedFunc$1
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + declared methods: 2
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(java.lang.Object,java.lang.Object)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$runJob$5.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + inner classes: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer classes: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + outer objects: 0
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + populating accessed fields because this is the starting closure
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + fields accessed by starting closure: 0 classes
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  + there are no enclosing objects!
2022-02-09 13:09:19 DEBUG ClosureCleaner:58 -  +++ closure <function2> (org.apache.spark.SparkContext$$anonfun$runJob$5) is now cleaned +++
2022-02-09 13:09:19 INFO  SparkContext:54 - Starting job: count at UseCase5Test.java:25
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Registering RDD 44 (count at UseCase5Test.java:25) as input to shuffle 1
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Registering RDD 47 (count at UseCase5Test.java:25) as input to shuffle 2
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Got job 9 (count at UseCase5Test.java:25) with 1 output partitions
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Final stage: ResultStage 13 (count at UseCase5Test.java:25)
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 12)
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 12)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - submitStage(ResultStage 13 (name=count at UseCase5Test.java:25;jobs=9))
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - missing: List(ShuffleMapStage 12)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - submitStage(ShuffleMapStage 12 (name=count at UseCase5Test.java:25;jobs=9))
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - missing: List(ShuffleMapStage 11)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - submitStage(ShuffleMapStage 11 (name=count at UseCase5Test.java:25;jobs=9))
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 11 (MapPartitionsRDD[44] at count at UseCase5Test.java:25), which has no missing parents
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - submitMissingTasks(ShuffleMapStage 11)
2022-02-09 13:09:19 INFO  MemoryStore:54 - Block broadcast_21 stored as values in memory (estimated size 31.7 KB, free 1967.1 MB)
2022-02-09 13:09:19 DEBUG BlockManager:58 - Put block broadcast_21 locally took  0 ms
2022-02-09 13:09:19 DEBUG BlockManager:58 - Putting block broadcast_21 without replication took  0 ms
2022-02-09 13:09:19 INFO  MemoryStore:54 - Block broadcast_21_piece0 stored as bytes in memory (estimated size 14.7 KB, free 1967.1 MB)
2022-02-09 13:09:19 INFO  BlockManagerInfo:54 - Added broadcast_21_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 14.7 KB, free: 1970.3 MB)
2022-02-09 13:09:19 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_21_piece0
2022-02-09 13:09:19 DEBUG BlockManager:58 - Told master about block broadcast_21_piece0
2022-02-09 13:09:19 DEBUG BlockManager:58 - Put block broadcast_21_piece0 locally took  18 ms
2022-02-09 13:09:19 DEBUG BlockManager:58 - Putting block broadcast_21_piece0 without replication took  18 ms
2022-02-09 13:09:19 INFO  SparkContext:54 - Created broadcast 21 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:19 INFO  DAGScheduler:54 - Submitting 200 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[44] at count at UseCase5Test.java:25) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
2022-02-09 13:09:19 INFO  TaskSchedulerImpl:54 - Adding task set 11.0 with 200 tasks
2022-02-09 13:09:19 DEBUG TaskSetManager:58 - Epoch for TaskSet 11.0: 1
2022-02-09 13:09:19 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 11.0: NO_PREF, ANY
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 0.0 in stage 11.0 (TID 209, localhost, executor driver, partition 0, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 0.0 in stage 11.0 (TID 209)
2022-02-09 13:09:19 DEBUG BlockManager:58 - Getting local block broadcast_21
2022-02-09 13:09:19 DEBUG BlockManager:58 - Level for block broadcast_21 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 0-1
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 209 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@408d78b2
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 209 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@408d78b2
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 0.0 in stage 11.0 (TID 209). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 1.0 in stage 11.0 (TID 210, localhost, executor driver, partition 1, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 1.0 in stage 11.0 (TID 210)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 0.0 in stage 11.0 (TID 209) in 17 ms on localhost (executor driver) (1/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 1-2
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 210 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5241aa34
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 210 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5241aa34
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 1.0 in stage 11.0 (TID 210). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 2.0 in stage 11.0 (TID 211, localhost, executor driver, partition 2, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 2.0 in stage 11.0 (TID 211)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 1.0 in stage 11.0 (TID 210) in 16 ms on localhost (executor driver) (2/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 2-3
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 211 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@27c33d99
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 211 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@27c33d99
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 2.0 in stage 11.0 (TID 211). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 3.0 in stage 11.0 (TID 212, localhost, executor driver, partition 3, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 3.0 in stage 11.0 (TID 212)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 2.0 in stage 11.0 (TID 211) in 16 ms on localhost (executor driver) (3/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 3-4
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 212 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2c9ab79e
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 212 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2c9ab79e
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 3.0 in stage 11.0 (TID 212). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 4.0 in stage 11.0 (TID 213, localhost, executor driver, partition 4, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 4.0 in stage 11.0 (TID 213)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 3.0 in stage 11.0 (TID 212) in 15 ms on localhost (executor driver) (4/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 4-5
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 213 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6834b5f2
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 213 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6834b5f2
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 4.0 in stage 11.0 (TID 213). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 5.0 in stage 11.0 (TID 214, localhost, executor driver, partition 5, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 4.0 in stage 11.0 (TID 213) in 16 ms on localhost (executor driver) (5/200)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 5.0 in stage 11.0 (TID 214)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 5-6
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(330)
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 330
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 330
2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 214 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@25a9fe2a
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(315)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 315
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 315
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(331)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 331
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 331
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(297)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 297
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 297
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(298)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 298
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 298
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(333)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 333
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 333
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(327)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 327
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 327
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(338)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 338
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 338
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(318)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 318
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 318
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(339)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 339
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 339
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(325)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 325
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 325
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(321)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 321
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 321
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(334)
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 334
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 334
2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 214 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@25a9fe2a
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(296)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 296
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 296
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(323)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 323
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 323
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(306)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 306
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 306
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(324)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 324
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 324
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(332)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 332
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 332
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(326)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 326
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 326
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(302)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 302
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 302
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(317)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 317
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 317
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(320)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 320
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 320
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(303)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 303
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 303
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(312)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 312
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 312
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(300)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 300
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 300
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(311)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 311
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 311
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(314)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 314
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 314
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(344)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 344
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 344
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(319)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 319
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 319
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(313)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 313
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 313
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(309)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 309
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 309
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(343)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 343
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 343
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(304)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 304
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 304
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(341)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 341
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 341
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(299)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 299
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 299
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(316)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 316
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 316
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(295)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 295
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 295
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(335)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 335
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 335
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanBroadcast(20)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning broadcast 20
2022-02-09 13:09:19 DEBUG TorrentBroadcast:58 - Unpersisting TorrentBroadcast 20
2022-02-09 13:09:19 DEBUG BlockManagerSlaveEndpoint:58 - removing broadcast 20
2022-02-09 13:09:19 DEBUG BlockManager:58 - Removing broadcast 20
2022-02-09 13:09:19 DEBUG BlockManager:58 - Removing block broadcast_20_piece0
2022-02-09 13:09:19 DEBUG MemoryStore:58 - Block broadcast_20_piece0 of size 14543 dropped from memory (free 2062686515)
2022-02-09 13:09:19 INFO  BlockManagerInfo:54 - Removed broadcast_20_piece0 on Clairvoyant-324.mshome.net:52097 in memory (size: 14.2 KB, free: 1970.3 MB)
2022-02-09 13:09:19 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_20_piece0
2022-02-09 13:09:19 DEBUG BlockManager:58 - Told master about block broadcast_20_piece0
2022-02-09 13:09:19 DEBUG BlockManager:58 - Removing block broadcast_20
2022-02-09 13:09:19 DEBUG MemoryStore:58 - Block broadcast_20 of size 31320 dropped from memory (free 2062717835)
2022-02-09 13:09:19 DEBUG BlockManagerSlaveEndpoint:58 - Done removing broadcast 20, response is 0
2022-02-09 13:09:19 DEBUG BlockManagerSlaveEndpoint:58 - Sent response: 0 to Clairvoyant-324.mshome.net:52082
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaned broadcast 20
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(340)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 340
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 5.0 in stage 11.0 (TID 214). 4440 bytes result sent to driver
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 340
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(329)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 329
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 329
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(337)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 337
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 337
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(310)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 310
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 310
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(307)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 307
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 307
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(301)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 301
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 301
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(342)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 342
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 342
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(336)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 336
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 336
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(328)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 328
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 328
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(322)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 322
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 322
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(305)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 305
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 305
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Got cleaning task CleanAccum(308)
2022-02-09 13:09:19 DEBUG ContextCleaner:58 - Cleaning accumulator 308
2022-02-09 13:09:19 INFO  ContextCleaner:54 - Cleaned accumulator 308
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 6.0 in stage 11.0 (TID 215, localhost, executor driver, partition 6, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 6.0 in stage 11.0 (TID 215)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 5.0 in stage 11.0 (TID 214) in 32 ms on localhost (executor driver) (6/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 6-7
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 215 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6f0a4519
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 215 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6f0a4519
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 6.0 in stage 11.0 (TID 215). 4311 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 7.0 in stage 11.0 (TID 216, localhost, executor driver, partition 7, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 7.0 in stage 11.0 (TID 216)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 6.0 in stage 11.0 (TID 215) in 16 ms on localhost (executor driver) (7/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 7-8
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 216 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4c5773e6
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 216 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4c5773e6
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 7.0 in stage 11.0 (TID 216). 4354 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 8.0 in stage 11.0 (TID 217, localhost, executor driver, partition 8, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 8.0 in stage 11.0 (TID 217)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 7.0 in stage 11.0 (TID 216) in 1 ms on localhost (executor driver) (8/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 8-9
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 217 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4aeb9ad7
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 217 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4aeb9ad7
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 8.0 in stage 11.0 (TID 217). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 9.0 in stage 11.0 (TID 218, localhost, executor driver, partition 9, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 9.0 in stage 11.0 (TID 218)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 8.0 in stage 11.0 (TID 217) in 16 ms on localhost (executor driver) (9/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 9-10
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 218 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@25f8ee83
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 218 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@25f8ee83
2022-02-09 13:09:19 INFO  Executor:54 - Finished task 9.0 in stage 11.0 (TID 218). 4397 bytes result sent to driver
2022-02-09 13:09:19 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Starting task 10.0 in stage 11.0 (TID 219, localhost, executor driver, partition 10, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:19 INFO  Executor:54 - Running task 10.0 in stage 11.0 (TID 219)
2022-02-09 13:09:19 INFO  TaskSetManager:54 - Finished task 9.0 in stage 11.0 (TID 218) in 16 ms on localhost (executor driver) (10/200)
2022-02-09 13:09:19 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:19 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:19 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 10-11
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:19 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:19 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:224 - Task 219 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4d6b33c6
2022-02-09 13:09:19 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:19 DEBUG TaskMemoryManager:233 - Task 219 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4d6b33c6
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 10.0 in stage 11.0 (TID 219). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 11.0 in stage 11.0 (TID 220, localhost, executor driver, partition 11, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 11.0 in stage 11.0 (TID 220)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 10.0 in stage 11.0 (TID 219) in 16 ms on localhost (executor driver) (11/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 11-12
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 220 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@34220173
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 220 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@34220173
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 11.0 in stage 11.0 (TID 220). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 12.0 in stage 11.0 (TID 221, localhost, executor driver, partition 12, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 12.0 in stage 11.0 (TID 221)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 11.0 in stage 11.0 (TID 220) in 0 ms on localhost (executor driver) (12/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 12-13
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 221 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6ec87aa6
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 221 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6ec87aa6
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 12.0 in stage 11.0 (TID 221). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 13.0 in stage 11.0 (TID 222, localhost, executor driver, partition 13, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 13.0 in stage 11.0 (TID 222)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 12.0 in stage 11.0 (TID 221) in 15 ms on localhost (executor driver) (13/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 13-14
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 222 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6cf92eb7
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 222 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6cf92eb7
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 13.0 in stage 11.0 (TID 222). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 14.0 in stage 11.0 (TID 223, localhost, executor driver, partition 14, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 13.0 in stage 11.0 (TID 222) in 16 ms on localhost (executor driver) (14/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 14.0 in stage 11.0 (TID 223)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 14-15
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 223 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@27ac78a2
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 223 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@27ac78a2
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 14.0 in stage 11.0 (TID 223). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 15.0 in stage 11.0 (TID 224, localhost, executor driver, partition 15, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 15.0 in stage 11.0 (TID 224)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 14.0 in stage 11.0 (TID 223) in 16 ms on localhost (executor driver) (15/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 15-16
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 224 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2239b63d
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 224 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2239b63d
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 15.0 in stage 11.0 (TID 224). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 16.0 in stage 11.0 (TID 225, localhost, executor driver, partition 16, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 16.0 in stage 11.0 (TID 225)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 15.0 in stage 11.0 (TID 224) in 16 ms on localhost (executor driver) (16/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 16-17
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 225 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@15b256a0
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 225 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@15b256a0
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 16.0 in stage 11.0 (TID 225). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 17.0 in stage 11.0 (TID 226, localhost, executor driver, partition 17, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 17.0 in stage 11.0 (TID 226)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 16.0 in stage 11.0 (TID 225) in 15 ms on localhost (executor driver) (17/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 17-18
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 226 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@58ba8709
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 226 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@58ba8709
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 17.0 in stage 11.0 (TID 226). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 18.0 in stage 11.0 (TID 227, localhost, executor driver, partition 18, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 18.0 in stage 11.0 (TID 227)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 17.0 in stage 11.0 (TID 226) in 16 ms on localhost (executor driver) (18/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 18-19
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 227 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@b87a636
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 227 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@b87a636
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 18.0 in stage 11.0 (TID 227). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 19.0 in stage 11.0 (TID 228, localhost, executor driver, partition 19, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 19.0 in stage 11.0 (TID 228)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 18.0 in stage 11.0 (TID 227) in 16 ms on localhost (executor driver) (19/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 19-20
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 228 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2392b7c3
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 228 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2392b7c3
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 19.0 in stage 11.0 (TID 228). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 20.0 in stage 11.0 (TID 229, localhost, executor driver, partition 20, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 20.0 in stage 11.0 (TID 229)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 19.0 in stage 11.0 (TID 228) in 0 ms on localhost (executor driver) (20/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 20-21
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 229 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4cf5fdf4
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 229 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4cf5fdf4
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 20.0 in stage 11.0 (TID 229). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 21.0 in stage 11.0 (TID 230, localhost, executor driver, partition 21, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 20.0 in stage 11.0 (TID 229) in 17 ms on localhost (executor driver) (21/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 21.0 in stage 11.0 (TID 230)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 21-22
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 230 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3d3ee389
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 230 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3d3ee389
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 21.0 in stage 11.0 (TID 230). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 22.0 in stage 11.0 (TID 231, localhost, executor driver, partition 22, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 22.0 in stage 11.0 (TID 231)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 21.0 in stage 11.0 (TID 230) in 15 ms on localhost (executor driver) (22/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 22-23
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 231 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1bd48fc2
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 231 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1bd48fc2
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 22.0 in stage 11.0 (TID 231). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 23.0 in stage 11.0 (TID 232, localhost, executor driver, partition 23, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 23.0 in stage 11.0 (TID 232)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 22.0 in stage 11.0 (TID 231) in 16 ms on localhost (executor driver) (23/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 23-24
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 232 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@21e99a2
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 232 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@21e99a2
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 23.0 in stage 11.0 (TID 232). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 24.0 in stage 11.0 (TID 233, localhost, executor driver, partition 24, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 24.0 in stage 11.0 (TID 233)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 23.0 in stage 11.0 (TID 232) in 16 ms on localhost (executor driver) (24/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 24-25
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 233 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@415122f3
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 233 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@415122f3
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 24.0 in stage 11.0 (TID 233). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 25.0 in stage 11.0 (TID 234, localhost, executor driver, partition 25, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 25.0 in stage 11.0 (TID 234)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 24.0 in stage 11.0 (TID 233) in 0 ms on localhost (executor driver) (25/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 25-26
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 234 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4b16d514
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 234 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4b16d514
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 25.0 in stage 11.0 (TID 234). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 26.0 in stage 11.0 (TID 235, localhost, executor driver, partition 26, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 26.0 in stage 11.0 (TID 235)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 25.0 in stage 11.0 (TID 234) in 16 ms on localhost (executor driver) (26/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 26-27
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 235 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@56916d1d
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 235 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@56916d1d
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 26.0 in stage 11.0 (TID 235). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 27.0 in stage 11.0 (TID 236, localhost, executor driver, partition 27, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 27.0 in stage 11.0 (TID 236)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 26.0 in stage 11.0 (TID 235) in 16 ms on localhost (executor driver) (27/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 27-28
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 236 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@761ca678
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 236 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@761ca678
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 27.0 in stage 11.0 (TID 236). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 28.0 in stage 11.0 (TID 237, localhost, executor driver, partition 28, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 28.0 in stage 11.0 (TID 237)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 27.0 in stage 11.0 (TID 236) in 15 ms on localhost (executor driver) (28/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 28-29
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 237 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@a66a926
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 237 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@a66a926
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 28.0 in stage 11.0 (TID 237). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 29.0 in stage 11.0 (TID 238, localhost, executor driver, partition 29, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 29.0 in stage 11.0 (TID 238)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 28.0 in stage 11.0 (TID 237) in 16 ms on localhost (executor driver) (29/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 29-30
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 238 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@161adefa
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 238 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@161adefa
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 29.0 in stage 11.0 (TID 238). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 30.0 in stage 11.0 (TID 239, localhost, executor driver, partition 30, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 30.0 in stage 11.0 (TID 239)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 29.0 in stage 11.0 (TID 238) in 0 ms on localhost (executor driver) (30/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 30-31
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 239 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1a6f6678
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 239 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1a6f6678
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 30.0 in stage 11.0 (TID 239). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 31.0 in stage 11.0 (TID 240, localhost, executor driver, partition 31, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 31.0 in stage 11.0 (TID 240)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 30.0 in stage 11.0 (TID 239) in 16 ms on localhost (executor driver) (31/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 31-32
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 240 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@26494b6b
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 240 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@26494b6b
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 31.0 in stage 11.0 (TID 240). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 32.0 in stage 11.0 (TID 241, localhost, executor driver, partition 32, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 32.0 in stage 11.0 (TID 241)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 31.0 in stage 11.0 (TID 240) in 16 ms on localhost (executor driver) (32/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 32-33
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 241 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@68b1b3b2
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 241 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@68b1b3b2
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 32.0 in stage 11.0 (TID 241). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 33.0 in stage 11.0 (TID 242, localhost, executor driver, partition 33, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 33.0 in stage 11.0 (TID 242)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 32.0 in stage 11.0 (TID 241) in 15 ms on localhost (executor driver) (33/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 33-34
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 242 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@704f4c75
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 242 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@704f4c75
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 33.0 in stage 11.0 (TID 242). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 34.0 in stage 11.0 (TID 243, localhost, executor driver, partition 34, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 33.0 in stage 11.0 (TID 242) in 16 ms on localhost (executor driver) (34/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 34.0 in stage 11.0 (TID 243)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 34-35
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 243 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3e7ee6b8
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 243 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3e7ee6b8
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 34.0 in stage 11.0 (TID 243). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 35.0 in stage 11.0 (TID 244, localhost, executor driver, partition 35, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 34.0 in stage 11.0 (TID 243) in 16 ms on localhost (executor driver) (35/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 35.0 in stage 11.0 (TID 244)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 35-36
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 244 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@159566bf
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 244 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@159566bf
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 35.0 in stage 11.0 (TID 244). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 36.0 in stage 11.0 (TID 245, localhost, executor driver, partition 36, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 36.0 in stage 11.0 (TID 245)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 35.0 in stage 11.0 (TID 244) in 16 ms on localhost (executor driver) (36/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 36-37
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 245 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3dc2c476
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 245 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3dc2c476
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 36.0 in stage 11.0 (TID 245). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 37.0 in stage 11.0 (TID 246, localhost, executor driver, partition 37, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 36.0 in stage 11.0 (TID 245) in 0 ms on localhost (executor driver) (37/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 37.0 in stage 11.0 (TID 246)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 37-38
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 246 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@68c71ccc
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 246 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@68c71ccc
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 37.0 in stage 11.0 (TID 246). 4440 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 38.0 in stage 11.0 (TID 247, localhost, executor driver, partition 38, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 37.0 in stage 11.0 (TID 246) in 17 ms on localhost (executor driver) (38/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 38.0 in stage 11.0 (TID 247)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 38-39
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 247 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7dd7e120
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 247 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7dd7e120
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 38.0 in stage 11.0 (TID 247). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 39.0 in stage 11.0 (TID 248, localhost, executor driver, partition 39, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 38.0 in stage 11.0 (TID 247) in 16 ms on localhost (executor driver) (39/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 39.0 in stage 11.0 (TID 248)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 39-40
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 248 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4d9d95ef
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 248 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4d9d95ef
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 39.0 in stage 11.0 (TID 248). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 40.0 in stage 11.0 (TID 249, localhost, executor driver, partition 40, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 40.0 in stage 11.0 (TID 249)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 39.0 in stage 11.0 (TID 248) in 16 ms on localhost (executor driver) (40/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 40-41
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 249 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4572e46c
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 249 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4572e46c
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 40.0 in stage 11.0 (TID 249). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 41.0 in stage 11.0 (TID 250, localhost, executor driver, partition 41, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 41.0 in stage 11.0 (TID 250)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 40.0 in stage 11.0 (TID 249) in 16 ms on localhost (executor driver) (41/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 41-42
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 250 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7383fa06
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 250 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7383fa06
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 41.0 in stage 11.0 (TID 250). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 42.0 in stage 11.0 (TID 251, localhost, executor driver, partition 42, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 42.0 in stage 11.0 (TID 251)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 41.0 in stage 11.0 (TID 250) in 15 ms on localhost (executor driver) (42/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 42-43
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 251 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4b6d8e59
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 251 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4b6d8e59
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 42.0 in stage 11.0 (TID 251). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 43.0 in stage 11.0 (TID 252, localhost, executor driver, partition 43, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 43.0 in stage 11.0 (TID 252)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 42.0 in stage 11.0 (TID 251) in 16 ms on localhost (executor driver) (43/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 43-44
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 252 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@31415533
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 252 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@31415533
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 43.0 in stage 11.0 (TID 252). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 44.0 in stage 11.0 (TID 253, localhost, executor driver, partition 44, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 44.0 in stage 11.0 (TID 253)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 43.0 in stage 11.0 (TID 252) in 16 ms on localhost (executor driver) (44/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 44-45
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 253 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@26ff4556
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 253 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@26ff4556
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 44.0 in stage 11.0 (TID 253). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 45.0 in stage 11.0 (TID 254, localhost, executor driver, partition 45, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 45.0 in stage 11.0 (TID 254)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 44.0 in stage 11.0 (TID 253) in 15 ms on localhost (executor driver) (45/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 45-46
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 254 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@65838c11
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 254 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@65838c11
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 45.0 in stage 11.0 (TID 254). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 46.0 in stage 11.0 (TID 255, localhost, executor driver, partition 46, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 46.0 in stage 11.0 (TID 255)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 45.0 in stage 11.0 (TID 254) in 16 ms on localhost (executor driver) (46/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 46-47
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 255 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3455d92
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 255 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3455d92
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 46.0 in stage 11.0 (TID 255). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 47.0 in stage 11.0 (TID 256, localhost, executor driver, partition 47, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 47.0 in stage 11.0 (TID 256)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 46.0 in stage 11.0 (TID 255) in 16 ms on localhost (executor driver) (47/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 47-48
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 256 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6e422153
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 256 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6e422153
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 47.0 in stage 11.0 (TID 256). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 48.0 in stage 11.0 (TID 257, localhost, executor driver, partition 48, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 47.0 in stage 11.0 (TID 256) in 16 ms on localhost (executor driver) (48/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 48.0 in stage 11.0 (TID 257)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 48-49
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 257 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@31bd8d9a
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 257 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@31bd8d9a
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 48.0 in stage 11.0 (TID 257). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 49.0 in stage 11.0 (TID 258, localhost, executor driver, partition 49, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 48.0 in stage 11.0 (TID 257) in 16 ms on localhost (executor driver) (49/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 49.0 in stage 11.0 (TID 258)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 49-50
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 258 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@46c49cbf
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 258 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@46c49cbf
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 49.0 in stage 11.0 (TID 258). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 50.0 in stage 11.0 (TID 259, localhost, executor driver, partition 50, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 49.0 in stage 11.0 (TID 258) in 15 ms on localhost (executor driver) (50/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 50.0 in stage 11.0 (TID 259)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 50-51
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 259 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@206e04cd
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 259 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@206e04cd
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 50.0 in stage 11.0 (TID 259). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 51.0 in stage 11.0 (TID 260, localhost, executor driver, partition 51, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 50.0 in stage 11.0 (TID 259) in 0 ms on localhost (executor driver) (51/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 51.0 in stage 11.0 (TID 260)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 51-52
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 260 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5ff97627
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 260 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5ff97627
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 51.0 in stage 11.0 (TID 260). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 52.0 in stage 11.0 (TID 261, localhost, executor driver, partition 52, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 51.0 in stage 11.0 (TID 260) in 16 ms on localhost (executor driver) (52/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 52.0 in stage 11.0 (TID 261)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 52-53
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 261 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6021bea
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 261 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6021bea
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 52.0 in stage 11.0 (TID 261). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 53.0 in stage 11.0 (TID 262, localhost, executor driver, partition 53, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 53.0 in stage 11.0 (TID 262)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 52.0 in stage 11.0 (TID 261) in 16 ms on localhost (executor driver) (53/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 53-54
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 262 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@43ea9d4f
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 262 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@43ea9d4f
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 53.0 in stage 11.0 (TID 262). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 54.0 in stage 11.0 (TID 263, localhost, executor driver, partition 54, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 54.0 in stage 11.0 (TID 263)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 53.0 in stage 11.0 (TID 262) in 16 ms on localhost (executor driver) (54/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 54-55
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 263 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3bd55153
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 263 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3bd55153
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 54.0 in stage 11.0 (TID 263). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 55.0 in stage 11.0 (TID 264, localhost, executor driver, partition 55, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 55.0 in stage 11.0 (TID 264)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 54.0 in stage 11.0 (TID 263) in 17 ms on localhost (executor driver) (55/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 55-56
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 264 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@61c09859
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 264 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@61c09859
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 55.0 in stage 11.0 (TID 264). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 56.0 in stage 11.0 (TID 265, localhost, executor driver, partition 56, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 56.0 in stage 11.0 (TID 265)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 55.0 in stage 11.0 (TID 264) in 1 ms on localhost (executor driver) (56/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 56-57
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 265 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@22e3abfa
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 265 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@22e3abfa
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 56.0 in stage 11.0 (TID 265). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 57.0 in stage 11.0 (TID 266, localhost, executor driver, partition 57, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 57.0 in stage 11.0 (TID 266)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 56.0 in stage 11.0 (TID 265) in 17 ms on localhost (executor driver) (57/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 57-58
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 266 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@35062560
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 266 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@35062560
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 57.0 in stage 11.0 (TID 266). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 58.0 in stage 11.0 (TID 267, localhost, executor driver, partition 58, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 58.0 in stage 11.0 (TID 267)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 57.0 in stage 11.0 (TID 266) in 16 ms on localhost (executor driver) (58/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 58-59
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 267 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6dc3fe97
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 267 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6dc3fe97
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 58.0 in stage 11.0 (TID 267). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 59.0 in stage 11.0 (TID 268, localhost, executor driver, partition 59, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 59.0 in stage 11.0 (TID 268)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 58.0 in stage 11.0 (TID 267) in 16 ms on localhost (executor driver) (59/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 59-60
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 268 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6e7dd43
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 268 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6e7dd43
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 59.0 in stage 11.0 (TID 268). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 60.0 in stage 11.0 (TID 269, localhost, executor driver, partition 60, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 60.0 in stage 11.0 (TID 269)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 59.0 in stage 11.0 (TID 268) in 0 ms on localhost (executor driver) (60/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 60-61
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 269 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@39596409
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 269 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@39596409
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 60.0 in stage 11.0 (TID 269). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 61.0 in stage 11.0 (TID 270, localhost, executor driver, partition 61, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 61.0 in stage 11.0 (TID 270)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 60.0 in stage 11.0 (TID 269) in 16 ms on localhost (executor driver) (61/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 61-62
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 270 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3eb2954a
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 270 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3eb2954a
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 61.0 in stage 11.0 (TID 270). 4440 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 62.0 in stage 11.0 (TID 271, localhost, executor driver, partition 62, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 62.0 in stage 11.0 (TID 271)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 61.0 in stage 11.0 (TID 270) in 16 ms on localhost (executor driver) (62/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 62-63
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 271 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5ae0a38e
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 271 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5ae0a38e
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 62.0 in stage 11.0 (TID 271). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 63.0 in stage 11.0 (TID 272, localhost, executor driver, partition 63, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 63.0 in stage 11.0 (TID 272)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 62.0 in stage 11.0 (TID 271) in 16 ms on localhost (executor driver) (63/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 63-64
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 272 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@799fb036
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 272 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@799fb036
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 63.0 in stage 11.0 (TID 272). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 64.0 in stage 11.0 (TID 273, localhost, executor driver, partition 64, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 64.0 in stage 11.0 (TID 273)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 63.0 in stage 11.0 (TID 272) in 0 ms on localhost (executor driver) (64/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 64-65
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 273 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1ba232d7
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 273 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1ba232d7
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 64.0 in stage 11.0 (TID 273). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 65.0 in stage 11.0 (TID 274, localhost, executor driver, partition 65, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 65.0 in stage 11.0 (TID 274)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 64.0 in stage 11.0 (TID 273) in 16 ms on localhost (executor driver) (65/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 65-66
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 274 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@35f2ce5c
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 274 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@35f2ce5c
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 65.0 in stage 11.0 (TID 274). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 66.0 in stage 11.0 (TID 275, localhost, executor driver, partition 66, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 65.0 in stage 11.0 (TID 274) in 16 ms on localhost (executor driver) (66/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 66.0 in stage 11.0 (TID 275)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 66-67
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 275 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7f89fd81
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 275 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7f89fd81
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 66.0 in stage 11.0 (TID 275). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 67.0 in stage 11.0 (TID 276, localhost, executor driver, partition 67, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 66.0 in stage 11.0 (TID 275) in 16 ms on localhost (executor driver) (67/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 67.0 in stage 11.0 (TID 276)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 67-68
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 276 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@41fea88a
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 276 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@41fea88a
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 67.0 in stage 11.0 (TID 276). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 68.0 in stage 11.0 (TID 277, localhost, executor driver, partition 68, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 68.0 in stage 11.0 (TID 277)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 67.0 in stage 11.0 (TID 276) in 15 ms on localhost (executor driver) (68/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 68-69
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 277 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7f510372
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 277 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7f510372
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 68.0 in stage 11.0 (TID 277). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 69.0 in stage 11.0 (TID 278, localhost, executor driver, partition 69, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 68.0 in stage 11.0 (TID 277) in 0 ms on localhost (executor driver) (69/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 69.0 in stage 11.0 (TID 278)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 69-70
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 278 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6c65153e
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 278 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6c65153e
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 69.0 in stage 11.0 (TID 278). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 70.0 in stage 11.0 (TID 279, localhost, executor driver, partition 70, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 69.0 in stage 11.0 (TID 278) in 16 ms on localhost (executor driver) (70/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 70.0 in stage 11.0 (TID 279)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 70-71
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 279 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1ce1c100
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 279 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1ce1c100
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 70.0 in stage 11.0 (TID 279). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 71.0 in stage 11.0 (TID 280, localhost, executor driver, partition 71, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 71.0 in stage 11.0 (TID 280)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 70.0 in stage 11.0 (TID 279) in 16 ms on localhost (executor driver) (71/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 71-72
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 280 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@56275150
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 280 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@56275150
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 71.0 in stage 11.0 (TID 280). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 72.0 in stage 11.0 (TID 281, localhost, executor driver, partition 72, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 71.0 in stage 11.0 (TID 280) in 0 ms on localhost (executor driver) (72/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 72.0 in stage 11.0 (TID 281)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 72-73
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 281 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@522b6903
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 281 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@522b6903
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 72.0 in stage 11.0 (TID 281). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 73.0 in stage 11.0 (TID 282, localhost, executor driver, partition 73, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 73.0 in stage 11.0 (TID 282)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 72.0 in stage 11.0 (TID 281) in 16 ms on localhost (executor driver) (73/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 73-74
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 282 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3fa4fe8c
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 282 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3fa4fe8c
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 73.0 in stage 11.0 (TID 282). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 74.0 in stage 11.0 (TID 283, localhost, executor driver, partition 74, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 74.0 in stage 11.0 (TID 283)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 73.0 in stage 11.0 (TID 282) in 15 ms on localhost (executor driver) (74/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 74-75
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 283 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@667ecc39
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 283 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@667ecc39
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 74.0 in stage 11.0 (TID 283). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 75.0 in stage 11.0 (TID 284, localhost, executor driver, partition 75, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 75.0 in stage 11.0 (TID 284)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 74.0 in stage 11.0 (TID 283) in 17 ms on localhost (executor driver) (75/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 75-76
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 284 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5d74f34e
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 284 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5d74f34e
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 75.0 in stage 11.0 (TID 284). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 76.0 in stage 11.0 (TID 285, localhost, executor driver, partition 76, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 76.0 in stage 11.0 (TID 285)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 75.0 in stage 11.0 (TID 284) in 16 ms on localhost (executor driver) (76/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 76-77
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 285 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7f9fb549
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 285 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7f9fb549
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 76.0 in stage 11.0 (TID 285). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 77.0 in stage 11.0 (TID 286, localhost, executor driver, partition 77, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 77.0 in stage 11.0 (TID 286)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 76.0 in stage 11.0 (TID 285) in 0 ms on localhost (executor driver) (77/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 77-78
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 286 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6c23c078
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 286 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6c23c078
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 77.0 in stage 11.0 (TID 286). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 78.0 in stage 11.0 (TID 287, localhost, executor driver, partition 78, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 77.0 in stage 11.0 (TID 286) in 16 ms on localhost (executor driver) (78/200)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 78.0 in stage 11.0 (TID 287)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 78-79
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 287 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@502a4af8
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 287 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@502a4af8
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 78.0 in stage 11.0 (TID 287). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 79.0 in stage 11.0 (TID 288, localhost, executor driver, partition 79, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 79.0 in stage 11.0 (TID 288)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 78.0 in stage 11.0 (TID 287) in 16 ms on localhost (executor driver) (79/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 79-80
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 288 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@42758e5d
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 288 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@42758e5d
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 79.0 in stage 11.0 (TID 288). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 80.0 in stage 11.0 (TID 289, localhost, executor driver, partition 80, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 80.0 in stage 11.0 (TID 289)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 79.0 in stage 11.0 (TID 288) in 16 ms on localhost (executor driver) (80/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 80-81
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 289 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7df59753
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 289 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7df59753
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 80.0 in stage 11.0 (TID 289). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 81.0 in stage 11.0 (TID 290, localhost, executor driver, partition 81, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 81.0 in stage 11.0 (TID 290)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 80.0 in stage 11.0 (TID 289) in 16 ms on localhost (executor driver) (81/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 81-82
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 290 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@74a723e9
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 290 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@74a723e9
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 81.0 in stage 11.0 (TID 290). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 82.0 in stage 11.0 (TID 291, localhost, executor driver, partition 82, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 82.0 in stage 11.0 (TID 291)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 81.0 in stage 11.0 (TID 290) in 0 ms on localhost (executor driver) (82/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 82-83
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 291 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@a1f95d6
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 291 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@a1f95d6
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 82.0 in stage 11.0 (TID 291). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 83.0 in stage 11.0 (TID 292, localhost, executor driver, partition 83, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 83.0 in stage 11.0 (TID 292)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 82.0 in stage 11.0 (TID 291) in 15 ms on localhost (executor driver) (83/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 83-84
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 292 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@333c6bf4
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 292 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@333c6bf4
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 83.0 in stage 11.0 (TID 292). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 84.0 in stage 11.0 (TID 293, localhost, executor driver, partition 84, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 84.0 in stage 11.0 (TID 293)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 83.0 in stage 11.0 (TID 292) in 16 ms on localhost (executor driver) (84/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 84-85
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 293 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5997a2a9
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 293 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5997a2a9
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 84.0 in stage 11.0 (TID 293). 4311 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 85.0 in stage 11.0 (TID 294, localhost, executor driver, partition 85, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 85.0 in stage 11.0 (TID 294)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 84.0 in stage 11.0 (TID 293) in 0 ms on localhost (executor driver) (85/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 85-86
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 294 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@232fd9d
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 294 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@232fd9d
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 85.0 in stage 11.0 (TID 294). 4397 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 86.0 in stage 11.0 (TID 295, localhost, executor driver, partition 86, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 86.0 in stage 11.0 (TID 295)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 85.0 in stage 11.0 (TID 294) in 16 ms on localhost (executor driver) (86/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 86-87
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 295 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@938d2b0
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 295 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@938d2b0
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 86.0 in stage 11.0 (TID 295). 4440 bytes result sent to driver
2022-02-09 13:09:20 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Starting task 87.0 in stage 11.0 (TID 296, localhost, executor driver, partition 87, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:20 INFO  Executor:54 - Running task 87.0 in stage 11.0 (TID 296)
2022-02-09 13:09:20 INFO  TaskSetManager:54 - Finished task 86.0 in stage 11.0 (TID 295) in 21 ms on localhost (executor driver) (87/200)
2022-02-09 13:09:20 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:20 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:20 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 87-88
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:20 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 8 ms
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:20 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  8 ms
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:224 - Task 296 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@223d2294
2022-02-09 13:09:20 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:20 DEBUG TaskMemoryManager:233 - Task 296 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@223d2294
2022-02-09 13:09:20 INFO  Executor:54 - Finished task 87.0 in stage 11.0 (TID 296). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 88.0 in stage 11.0 (TID 297, localhost, executor driver, partition 88, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 88.0 in stage 11.0 (TID 297)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 87.0 in stage 11.0 (TID 296) in 16 ms on localhost (executor driver) (88/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 88-89
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 297 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@276254c1
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 297 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@276254c1
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 88.0 in stage 11.0 (TID 297). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 89.0 in stage 11.0 (TID 298, localhost, executor driver, partition 89, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 89.0 in stage 11.0 (TID 298)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 88.0 in stage 11.0 (TID 297) in 8 ms on localhost (executor driver) (89/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 89-90
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 298 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5f229b10
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 298 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5f229b10
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 89.0 in stage 11.0 (TID 298). 4440 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 90.0 in stage 11.0 (TID 299, localhost, executor driver, partition 90, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 89.0 in stage 11.0 (TID 298) in 14 ms on localhost (executor driver) (90/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 90.0 in stage 11.0 (TID 299)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 90-91
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 299 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7ec60c96
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 299 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7ec60c96
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 90.0 in stage 11.0 (TID 299). 4354 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 91.0 in stage 11.0 (TID 300, localhost, executor driver, partition 91, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 90.0 in stage 11.0 (TID 299) in 9 ms on localhost (executor driver) (91/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 91.0 in stage 11.0 (TID 300)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 91-92
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 300 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7737938
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 300 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7737938
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 91.0 in stage 11.0 (TID 300). 4440 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 92.0 in stage 11.0 (TID 301, localhost, executor driver, partition 92, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 91.0 in stage 11.0 (TID 300) in 17 ms on localhost (executor driver) (92/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 92.0 in stage 11.0 (TID 301)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 92-93
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 301 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@49ac7840
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 301 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@49ac7840
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 92.0 in stage 11.0 (TID 301). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 93.0 in stage 11.0 (TID 302, localhost, executor driver, partition 93, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 92.0 in stage 11.0 (TID 301) in 0 ms on localhost (executor driver) (93/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 93.0 in stage 11.0 (TID 302)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 93-94
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 1 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  1 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 302 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@37c2b77a
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 302 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@37c2b77a
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 93.0 in stage 11.0 (TID 302). 4440 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 94.0 in stage 11.0 (TID 303, localhost, executor driver, partition 94, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 93.0 in stage 11.0 (TID 302) in 17 ms on localhost (executor driver) (94/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 94.0 in stage 11.0 (TID 303)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 94-95
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 303 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1f7305b6
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 303 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1f7305b6
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 94.0 in stage 11.0 (TID 303). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 95.0 in stage 11.0 (TID 304, localhost, executor driver, partition 95, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 95.0 in stage 11.0 (TID 304)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 94.0 in stage 11.0 (TID 303) in 15 ms on localhost (executor driver) (95/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 95-96
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 304 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@42b35307
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 304 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@42b35307
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 95.0 in stage 11.0 (TID 304). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 96.0 in stage 11.0 (TID 305, localhost, executor driver, partition 96, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 96.0 in stage 11.0 (TID 305)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 95.0 in stage 11.0 (TID 304) in 16 ms on localhost (executor driver) (96/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 96-97
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 305 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@464de392
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 305 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@464de392
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 96.0 in stage 11.0 (TID 305). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 98.0 in stage 11.0 (TID 306, localhost, executor driver, partition 98, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 96.0 in stage 11.0 (TID 305) in 0 ms on localhost (executor driver) (97/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 98.0 in stage 11.0 (TID 306)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 98-99
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 306 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@36ff1864
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 306 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@36ff1864
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 98.0 in stage 11.0 (TID 306). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 99.0 in stage 11.0 (TID 307, localhost, executor driver, partition 99, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 99.0 in stage 11.0 (TID 307)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 98.0 in stage 11.0 (TID 306) in 16 ms on localhost (executor driver) (98/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 99-100
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 307 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5859aa99
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 307 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5859aa99
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 99.0 in stage 11.0 (TID 307). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 100.0 in stage 11.0 (TID 308, localhost, executor driver, partition 100, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 100.0 in stage 11.0 (TID 308)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 99.0 in stage 11.0 (TID 307) in 17 ms on localhost (executor driver) (99/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 100-101
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 308 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3ea655a3
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 308 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3ea655a3
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 100.0 in stage 11.0 (TID 308). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 101.0 in stage 11.0 (TID 309, localhost, executor driver, partition 101, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 101.0 in stage 11.0 (TID 309)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 100.0 in stage 11.0 (TID 308) in 0 ms on localhost (executor driver) (100/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 101-102
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 309 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@159aa989
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 309 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@159aa989
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 101.0 in stage 11.0 (TID 309). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 102.0 in stage 11.0 (TID 310, localhost, executor driver, partition 102, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 102.0 in stage 11.0 (TID 310)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 101.0 in stage 11.0 (TID 309) in 16 ms on localhost (executor driver) (101/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 102-103
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 310 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@40b6d204
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 310 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@40b6d204
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 102.0 in stage 11.0 (TID 310). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 103.0 in stage 11.0 (TID 311, localhost, executor driver, partition 103, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 103.0 in stage 11.0 (TID 311)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 102.0 in stage 11.0 (TID 310) in 15 ms on localhost (executor driver) (102/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 103-104
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 311 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6d77df1
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 311 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6d77df1
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 103.0 in stage 11.0 (TID 311). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 104.0 in stage 11.0 (TID 312, localhost, executor driver, partition 104, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 104.0 in stage 11.0 (TID 312)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 103.0 in stage 11.0 (TID 311) in 0 ms on localhost (executor driver) (103/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 104-105
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 312 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3c18da2f
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 312 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3c18da2f
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 104.0 in stage 11.0 (TID 312). 4354 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 105.0 in stage 11.0 (TID 313, localhost, executor driver, partition 105, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 105.0 in stage 11.0 (TID 313)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 104.0 in stage 11.0 (TID 312) in 16 ms on localhost (executor driver) (104/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 105-106
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 313 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3b4be405
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 313 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3b4be405
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 105.0 in stage 11.0 (TID 313). 4354 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 106.0 in stage 11.0 (TID 314, localhost, executor driver, partition 106, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 106.0 in stage 11.0 (TID 314)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 105.0 in stage 11.0 (TID 313) in 16 ms on localhost (executor driver) (105/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 106-107
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 314 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7673bbed
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 314 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7673bbed
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 106.0 in stage 11.0 (TID 314). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 107.0 in stage 11.0 (TID 315, localhost, executor driver, partition 107, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 107.0 in stage 11.0 (TID 315)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 106.0 in stage 11.0 (TID 314) in 0 ms on localhost (executor driver) (106/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 107-108
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 315 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1524cd66
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 315 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1524cd66
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 107.0 in stage 11.0 (TID 315). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 109.0 in stage 11.0 (TID 316, localhost, executor driver, partition 109, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 109.0 in stage 11.0 (TID 316)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 107.0 in stage 11.0 (TID 315) in 16 ms on localhost (executor driver) (107/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 109-110
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 316 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@379af2bc
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 316 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@379af2bc
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 109.0 in stage 11.0 (TID 316). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 110.0 in stage 11.0 (TID 317, localhost, executor driver, partition 110, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 110.0 in stage 11.0 (TID 317)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 109.0 in stage 11.0 (TID 316) in 15 ms on localhost (executor driver) (108/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 110-111
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 317 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@10ec01a7
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 317 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@10ec01a7
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 110.0 in stage 11.0 (TID 317). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 111.0 in stage 11.0 (TID 318, localhost, executor driver, partition 111, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 111.0 in stage 11.0 (TID 318)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 110.0 in stage 11.0 (TID 317) in 16 ms on localhost (executor driver) (109/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 111-112
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 318 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@45b034f7
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 318 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@45b034f7
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 111.0 in stage 11.0 (TID 318). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 112.0 in stage 11.0 (TID 319, localhost, executor driver, partition 112, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 112.0 in stage 11.0 (TID 319)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 111.0 in stage 11.0 (TID 318) in 16 ms on localhost (executor driver) (110/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 112-113
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 319 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2481b37f
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 319 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2481b37f
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 112.0 in stage 11.0 (TID 319). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 113.0 in stage 11.0 (TID 320, localhost, executor driver, partition 113, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 113.0 in stage 11.0 (TID 320)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 112.0 in stage 11.0 (TID 319) in 20 ms on localhost (executor driver) (111/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 113-114
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 320 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@473169e2
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 320 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@473169e2
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 113.0 in stage 11.0 (TID 320). 4354 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 114.0 in stage 11.0 (TID 321, localhost, executor driver, partition 114, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 114.0 in stage 11.0 (TID 321)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 113.0 in stage 11.0 (TID 320) in 5 ms on localhost (executor driver) (112/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 114-115
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 321 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@706287bb
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 321 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@706287bb
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 114.0 in stage 11.0 (TID 321). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 115.0 in stage 11.0 (TID 322, localhost, executor driver, partition 115, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 115.0 in stage 11.0 (TID 322)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 114.0 in stage 11.0 (TID 321) in 16 ms on localhost (executor driver) (113/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 115-116
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 322 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2240c626
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 322 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2240c626
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 115.0 in stage 11.0 (TID 322). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 117.0 in stage 11.0 (TID 323, localhost, executor driver, partition 117, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 117.0 in stage 11.0 (TID 323)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 115.0 in stage 11.0 (TID 322) in 16 ms on localhost (executor driver) (114/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 117-118
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 323 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@36c80ec5
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 323 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@36c80ec5
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 117.0 in stage 11.0 (TID 323). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 118.0 in stage 11.0 (TID 324, localhost, executor driver, partition 118, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 118.0 in stage 11.0 (TID 324)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 117.0 in stage 11.0 (TID 323) in 0 ms on localhost (executor driver) (115/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 118-119
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 324 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@52655e98
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 324 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@52655e98
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 118.0 in stage 11.0 (TID 324). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 119.0 in stage 11.0 (TID 325, localhost, executor driver, partition 119, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 119.0 in stage 11.0 (TID 325)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 118.0 in stage 11.0 (TID 324) in 15 ms on localhost (executor driver) (116/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 119-120
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 325 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@49e82d45
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 325 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@49e82d45
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 119.0 in stage 11.0 (TID 325). 4354 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 120.0 in stage 11.0 (TID 326, localhost, executor driver, partition 120, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 120.0 in stage 11.0 (TID 326)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 119.0 in stage 11.0 (TID 325) in 16 ms on localhost (executor driver) (117/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 120-121
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 326 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@17f2ceef
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 326 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@17f2ceef
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 120.0 in stage 11.0 (TID 326). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 121.0 in stage 11.0 (TID 327, localhost, executor driver, partition 121, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 121.0 in stage 11.0 (TID 327)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 120.0 in stage 11.0 (TID 326) in 16 ms on localhost (executor driver) (118/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 121-122
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 327 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@656e475e
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 327 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@656e475e
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 121.0 in stage 11.0 (TID 327). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 122.0 in stage 11.0 (TID 328, localhost, executor driver, partition 122, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 122.0 in stage 11.0 (TID 328)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 121.0 in stage 11.0 (TID 327) in 16 ms on localhost (executor driver) (119/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 122-123
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 328 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@40fce533
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 328 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@40fce533
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 122.0 in stage 11.0 (TID 328). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 123.0 in stage 11.0 (TID 329, localhost, executor driver, partition 123, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 123.0 in stage 11.0 (TID 329)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 122.0 in stage 11.0 (TID 328) in 16 ms on localhost (executor driver) (120/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 123-124
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 329 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@40b020a1
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 329 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@40b020a1
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 123.0 in stage 11.0 (TID 329). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 124.0 in stage 11.0 (TID 330, localhost, executor driver, partition 124, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 124.0 in stage 11.0 (TID 330)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 123.0 in stage 11.0 (TID 329) in 16 ms on localhost (executor driver) (121/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 124-125
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 330 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@51beaaa
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 330 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@51beaaa
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 124.0 in stage 11.0 (TID 330). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 125.0 in stage 11.0 (TID 331, localhost, executor driver, partition 125, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 124.0 in stage 11.0 (TID 330) in 15 ms on localhost (executor driver) (122/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 125.0 in stage 11.0 (TID 331)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 125-126
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 331 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@8d5b4e8
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 331 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@8d5b4e8
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 125.0 in stage 11.0 (TID 331). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 126.0 in stage 11.0 (TID 332, localhost, executor driver, partition 126, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 126.0 in stage 11.0 (TID 332)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 125.0 in stage 11.0 (TID 331) in 17 ms on localhost (executor driver) (123/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 126-127
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 332 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5cb9884c
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 332 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5cb9884c
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 126.0 in stage 11.0 (TID 332). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 127.0 in stage 11.0 (TID 333, localhost, executor driver, partition 127, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 127.0 in stage 11.0 (TID 333)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 126.0 in stage 11.0 (TID 332) in 16 ms on localhost (executor driver) (124/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 127-128
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 333 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@406cd1b0
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 333 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@406cd1b0
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 127.0 in stage 11.0 (TID 333). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 128.0 in stage 11.0 (TID 334, localhost, executor driver, partition 128, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 128.0 in stage 11.0 (TID 334)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 127.0 in stage 11.0 (TID 333) in 16 ms on localhost (executor driver) (125/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 128-129
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 334 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2c5b087c
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 334 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2c5b087c
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 128.0 in stage 11.0 (TID 334). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 129.0 in stage 11.0 (TID 335, localhost, executor driver, partition 129, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 129.0 in stage 11.0 (TID 335)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 128.0 in stage 11.0 (TID 334) in 16 ms on localhost (executor driver) (126/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 129-130
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 335 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1d8550d7
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 335 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1d8550d7
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 129.0 in stage 11.0 (TID 335). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 130.0 in stage 11.0 (TID 336, localhost, executor driver, partition 130, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 130.0 in stage 11.0 (TID 336)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 129.0 in stage 11.0 (TID 335) in 0 ms on localhost (executor driver) (127/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 130-131
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 336 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@39c04e37
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 336 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@39c04e37
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 130.0 in stage 11.0 (TID 336). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 131.0 in stage 11.0 (TID 337, localhost, executor driver, partition 131, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 131.0 in stage 11.0 (TID 337)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 130.0 in stage 11.0 (TID 336) in 16 ms on localhost (executor driver) (128/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 131-132
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 337 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@56549f4c
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 337 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@56549f4c
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 131.0 in stage 11.0 (TID 337). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 132.0 in stage 11.0 (TID 338, localhost, executor driver, partition 132, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 132.0 in stage 11.0 (TID 338)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 131.0 in stage 11.0 (TID 337) in 15 ms on localhost (executor driver) (129/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 132-133
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 338 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@14fdaf12
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 338 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@14fdaf12
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 132.0 in stage 11.0 (TID 338). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 133.0 in stage 11.0 (TID 339, localhost, executor driver, partition 133, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 133.0 in stage 11.0 (TID 339)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 132.0 in stage 11.0 (TID 338) in 16 ms on localhost (executor driver) (130/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 133-134
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 339 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4cd36f49
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 339 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4cd36f49
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 133.0 in stage 11.0 (TID 339). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 135.0 in stage 11.0 (TID 340, localhost, executor driver, partition 135, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 133.0 in stage 11.0 (TID 339) in 17 ms on localhost (executor driver) (131/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 135.0 in stage 11.0 (TID 340)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 135-136
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 340 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@285471dc
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 340 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@285471dc
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 135.0 in stage 11.0 (TID 340). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 136.0 in stage 11.0 (TID 341, localhost, executor driver, partition 136, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 136.0 in stage 11.0 (TID 341)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 135.0 in stage 11.0 (TID 340) in 16 ms on localhost (executor driver) (132/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 136-137
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 341 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5d918c2d
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 341 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5d918c2d
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 136.0 in stage 11.0 (TID 341). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 137.0 in stage 11.0 (TID 342, localhost, executor driver, partition 137, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 137.0 in stage 11.0 (TID 342)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 136.0 in stage 11.0 (TID 341) in 16 ms on localhost (executor driver) (133/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 137-138
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 342 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@78c054a9
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 342 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@78c054a9
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 137.0 in stage 11.0 (TID 342). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 138.0 in stage 11.0 (TID 343, localhost, executor driver, partition 138, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 138.0 in stage 11.0 (TID 343)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 137.0 in stage 11.0 (TID 342) in 16 ms on localhost (executor driver) (134/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 138-139
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 343 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@61565672
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 343 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@61565672
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 138.0 in stage 11.0 (TID 343). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 139.0 in stage 11.0 (TID 344, localhost, executor driver, partition 139, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 139.0 in stage 11.0 (TID 344)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 138.0 in stage 11.0 (TID 343) in 16 ms on localhost (executor driver) (135/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 139-140
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 344 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@e7c90a5
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 344 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@e7c90a5
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 139.0 in stage 11.0 (TID 344). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 140.0 in stage 11.0 (TID 345, localhost, executor driver, partition 140, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 140.0 in stage 11.0 (TID 345)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 139.0 in stage 11.0 (TID 344) in 16 ms on localhost (executor driver) (136/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 140-141
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 345 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@28d32f27
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 345 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@28d32f27
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 140.0 in stage 11.0 (TID 345). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 141.0 in stage 11.0 (TID 346, localhost, executor driver, partition 141, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 141.0 in stage 11.0 (TID 346)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 140.0 in stage 11.0 (TID 345) in 16 ms on localhost (executor driver) (137/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 141-142
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 346 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2834bc33
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 346 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2834bc33
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 141.0 in stage 11.0 (TID 346). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 142.0 in stage 11.0 (TID 347, localhost, executor driver, partition 142, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 141.0 in stage 11.0 (TID 346) in 6 ms on localhost (executor driver) (138/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 142.0 in stage 11.0 (TID 347)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 142-143
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 347 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4e4b079e
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 347 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4e4b079e
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 142.0 in stage 11.0 (TID 347). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 143.0 in stage 11.0 (TID 348, localhost, executor driver, partition 143, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 142.0 in stage 11.0 (TID 347) in 16 ms on localhost (executor driver) (139/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 143.0 in stage 11.0 (TID 348)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 143-144
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 348 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@402d711c
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 348 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@402d711c
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 143.0 in stage 11.0 (TID 348). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 144.0 in stage 11.0 (TID 349, localhost, executor driver, partition 144, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 143.0 in stage 11.0 (TID 348) in 16 ms on localhost (executor driver) (140/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 144.0 in stage 11.0 (TID 349)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 144-145
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 349 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3dd4e689
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 349 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3dd4e689
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 144.0 in stage 11.0 (TID 349). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 145.0 in stage 11.0 (TID 350, localhost, executor driver, partition 145, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 145.0 in stage 11.0 (TID 350)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 144.0 in stage 11.0 (TID 349) in 16 ms on localhost (executor driver) (141/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 145-146
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 350 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3eb9bee9
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 350 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3eb9bee9
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 145.0 in stage 11.0 (TID 350). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 146.0 in stage 11.0 (TID 351, localhost, executor driver, partition 146, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 146.0 in stage 11.0 (TID 351)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 145.0 in stage 11.0 (TID 350) in 17 ms on localhost (executor driver) (142/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 146-147
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 351 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@557f6dfd
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 351 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@557f6dfd
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 146.0 in stage 11.0 (TID 351). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 147.0 in stage 11.0 (TID 352, localhost, executor driver, partition 147, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 147.0 in stage 11.0 (TID 352)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 146.0 in stage 11.0 (TID 351) in 16 ms on localhost (executor driver) (143/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 147-148
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 352 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@515f3fc3
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 352 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@515f3fc3
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 147.0 in stage 11.0 (TID 352). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 148.0 in stage 11.0 (TID 353, localhost, executor driver, partition 148, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 147.0 in stage 11.0 (TID 352) in 0 ms on localhost (executor driver) (144/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 148.0 in stage 11.0 (TID 353)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 148-149
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 353 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@579df7ab
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 353 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@579df7ab
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 148.0 in stage 11.0 (TID 353). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 149.0 in stage 11.0 (TID 354, localhost, executor driver, partition 149, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 149.0 in stage 11.0 (TID 354)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 148.0 in stage 11.0 (TID 353) in 15 ms on localhost (executor driver) (145/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 149-150
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 354 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6a05fb10
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 354 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6a05fb10
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 149.0 in stage 11.0 (TID 354). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 150.0 in stage 11.0 (TID 355, localhost, executor driver, partition 150, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 150.0 in stage 11.0 (TID 355)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 149.0 in stage 11.0 (TID 354) in 16 ms on localhost (executor driver) (146/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 150-151
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 355 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1c5bad2d
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 355 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1c5bad2d
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 150.0 in stage 11.0 (TID 355). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 151.0 in stage 11.0 (TID 356, localhost, executor driver, partition 151, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 151.0 in stage 11.0 (TID 356)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 150.0 in stage 11.0 (TID 355) in 16 ms on localhost (executor driver) (147/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 151-152
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 356 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@281f9525
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 356 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@281f9525
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 151.0 in stage 11.0 (TID 356). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 152.0 in stage 11.0 (TID 357, localhost, executor driver, partition 152, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 152.0 in stage 11.0 (TID 357)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 151.0 in stage 11.0 (TID 356) in 0 ms on localhost (executor driver) (148/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 152-153
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 357 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@248e54dc
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 357 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@248e54dc
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 152.0 in stage 11.0 (TID 357). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 153.0 in stage 11.0 (TID 358, localhost, executor driver, partition 153, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 152.0 in stage 11.0 (TID 357) in 15 ms on localhost (executor driver) (149/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 153.0 in stage 11.0 (TID 358)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 153-154
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 358 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@17b5f727
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 358 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@17b5f727
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 153.0 in stage 11.0 (TID 358). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 154.0 in stage 11.0 (TID 359, localhost, executor driver, partition 154, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 153.0 in stage 11.0 (TID 358) in 16 ms on localhost (executor driver) (150/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 154.0 in stage 11.0 (TID 359)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 154-155
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 359 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5a4bc0b0
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 359 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5a4bc0b0
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 154.0 in stage 11.0 (TID 359). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 155.0 in stage 11.0 (TID 360, localhost, executor driver, partition 155, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 154.0 in stage 11.0 (TID 359) in 0 ms on localhost (executor driver) (151/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 155.0 in stage 11.0 (TID 360)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 155-156
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 360 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@719176a9
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 360 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@719176a9
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 155.0 in stage 11.0 (TID 360). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 157.0 in stage 11.0 (TID 361, localhost, executor driver, partition 157, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 155.0 in stage 11.0 (TID 360) in 16 ms on localhost (executor driver) (152/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 157.0 in stage 11.0 (TID 361)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 157-158
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 361 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@67a36449
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 361 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@67a36449
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 157.0 in stage 11.0 (TID 361). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 158.0 in stage 11.0 (TID 362, localhost, executor driver, partition 158, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 157.0 in stage 11.0 (TID 361) in 16 ms on localhost (executor driver) (153/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 158.0 in stage 11.0 (TID 362)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 158-159
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 362 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4101228c
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 362 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4101228c
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 158.0 in stage 11.0 (TID 362). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 159.0 in stage 11.0 (TID 363, localhost, executor driver, partition 159, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 158.0 in stage 11.0 (TID 362) in 0 ms on localhost (executor driver) (154/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 159.0 in stage 11.0 (TID 363)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 159-160
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 363 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@e15b729
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 363 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@e15b729
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 159.0 in stage 11.0 (TID 363). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 160.0 in stage 11.0 (TID 364, localhost, executor driver, partition 160, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 159.0 in stage 11.0 (TID 363) in 15 ms on localhost (executor driver) (155/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 160.0 in stage 11.0 (TID 364)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 160-161
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 364 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1ff32593
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 364 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1ff32593
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 160.0 in stage 11.0 (TID 364). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 161.0 in stage 11.0 (TID 365, localhost, executor driver, partition 161, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 160.0 in stage 11.0 (TID 364) in 16 ms on localhost (executor driver) (156/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 161.0 in stage 11.0 (TID 365)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 161-162
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 365 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@77bce299
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 365 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@77bce299
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 161.0 in stage 11.0 (TID 365). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 162.0 in stage 11.0 (TID 366, localhost, executor driver, partition 162, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 161.0 in stage 11.0 (TID 365) in 16 ms on localhost (executor driver) (157/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 162.0 in stage 11.0 (TID 366)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 162-163
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 366 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@37297de4
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 366 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@37297de4
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 162.0 in stage 11.0 (TID 366). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 163.0 in stage 11.0 (TID 367, localhost, executor driver, partition 163, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 163.0 in stage 11.0 (TID 367)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 162.0 in stage 11.0 (TID 366) in 16 ms on localhost (executor driver) (158/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 163-164
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 367 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@75ed08e5
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 367 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@75ed08e5
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 163.0 in stage 11.0 (TID 367). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 164.0 in stage 11.0 (TID 368, localhost, executor driver, partition 164, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 163.0 in stage 11.0 (TID 367) in 17 ms on localhost (executor driver) (159/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 164.0 in stage 11.0 (TID 368)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 164-165
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 368 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@241bcfc4
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 368 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@241bcfc4
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 164.0 in stage 11.0 (TID 368). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 165.0 in stage 11.0 (TID 369, localhost, executor driver, partition 165, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 165.0 in stage 11.0 (TID 369)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 164.0 in stage 11.0 (TID 368) in 15 ms on localhost (executor driver) (160/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 165-166
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 369 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4d8ffaa1
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 369 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4d8ffaa1
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 165.0 in stage 11.0 (TID 369). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 166.0 in stage 11.0 (TID 370, localhost, executor driver, partition 166, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 166.0 in stage 11.0 (TID 370)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 165.0 in stage 11.0 (TID 369) in 16 ms on localhost (executor driver) (161/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 166-167
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 370 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7b363b82
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 370 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7b363b82
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 166.0 in stage 11.0 (TID 370). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 167.0 in stage 11.0 (TID 371, localhost, executor driver, partition 167, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 166.0 in stage 11.0 (TID 370) in 16 ms on localhost (executor driver) (162/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 167.0 in stage 11.0 (TID 371)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 167-168
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 371 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@29c07b40
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 371 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@29c07b40
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 167.0 in stage 11.0 (TID 371). 4311 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 168.0 in stage 11.0 (TID 372, localhost, executor driver, partition 168, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 167.0 in stage 11.0 (TID 371) in 0 ms on localhost (executor driver) (163/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 168.0 in stage 11.0 (TID 372)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 168-169
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 372 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@47132b28
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 372 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@47132b28
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 168.0 in stage 11.0 (TID 372). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 169.0 in stage 11.0 (TID 373, localhost, executor driver, partition 169, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 169.0 in stage 11.0 (TID 373)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 168.0 in stage 11.0 (TID 372) in 15 ms on localhost (executor driver) (164/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 169-170
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 373 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@ed2bccc
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 373 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@ed2bccc
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 169.0 in stage 11.0 (TID 373). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 170.0 in stage 11.0 (TID 374, localhost, executor driver, partition 170, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 170.0 in stage 11.0 (TID 374)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 169.0 in stage 11.0 (TID 373) in 16 ms on localhost (executor driver) (165/200)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 170-171
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:224 - Task 374 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@56b20582
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:21 DEBUG TaskMemoryManager:233 - Task 374 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@56b20582
2022-02-09 13:09:21 INFO  Executor:54 - Finished task 170.0 in stage 11.0 (TID 374). 4397 bytes result sent to driver
2022-02-09 13:09:21 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Starting task 171.0 in stage 11.0 (TID 375, localhost, executor driver, partition 171, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:21 INFO  TaskSetManager:54 - Finished task 170.0 in stage 11.0 (TID 374) in 16 ms on localhost (executor driver) (166/200)
2022-02-09 13:09:21 INFO  Executor:54 - Running task 171.0 in stage 11.0 (TID 375)
2022-02-09 13:09:21 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:21 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:21 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 171-172
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:21 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:21 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:21 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 375 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@7ea461a0
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 375 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@7ea461a0
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 171.0 in stage 11.0 (TID 375). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 172.0 in stage 11.0 (TID 376, localhost, executor driver, partition 172, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 172.0 in stage 11.0 (TID 376)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 171.0 in stage 11.0 (TID 375) in 15 ms on localhost (executor driver) (167/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 172-173
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 376 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@69e2224a
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 376 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@69e2224a
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 172.0 in stage 11.0 (TID 376). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 173.0 in stage 11.0 (TID 377, localhost, executor driver, partition 173, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 173.0 in stage 11.0 (TID 377)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 172.0 in stage 11.0 (TID 376) in 16 ms on localhost (executor driver) (168/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 173-174
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 377 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3ecc5da9
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 377 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3ecc5da9
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 173.0 in stage 11.0 (TID 377). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 174.0 in stage 11.0 (TID 378, localhost, executor driver, partition 174, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 174.0 in stage 11.0 (TID 378)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 173.0 in stage 11.0 (TID 377) in 0 ms on localhost (executor driver) (169/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 174-175
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 378 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@8c9ea21
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 378 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@8c9ea21
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 174.0 in stage 11.0 (TID 378). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 175.0 in stage 11.0 (TID 379, localhost, executor driver, partition 175, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 175.0 in stage 11.0 (TID 379)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 174.0 in stage 11.0 (TID 378) in 16 ms on localhost (executor driver) (170/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 175-176
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 379 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@9ba0ecc
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 379 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@9ba0ecc
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 175.0 in stage 11.0 (TID 379). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 176.0 in stage 11.0 (TID 380, localhost, executor driver, partition 176, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 175.0 in stage 11.0 (TID 379) in 16 ms on localhost (executor driver) (171/200)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 176.0 in stage 11.0 (TID 380)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 176-177
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 380 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2ddbcd90
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 380 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2ddbcd90
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 176.0 in stage 11.0 (TID 380). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 177.0 in stage 11.0 (TID 381, localhost, executor driver, partition 177, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 177.0 in stage 11.0 (TID 381)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 176.0 in stage 11.0 (TID 380) in 0 ms on localhost (executor driver) (172/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 177-178
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 381 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@6e51bfb
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 381 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@6e51bfb
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 177.0 in stage 11.0 (TID 381). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 178.0 in stage 11.0 (TID 382, localhost, executor driver, partition 178, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 178.0 in stage 11.0 (TID 382)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 177.0 in stage 11.0 (TID 381) in 15 ms on localhost (executor driver) (173/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 178-179
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 382 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@cbd184d
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 382 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@cbd184d
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 178.0 in stage 11.0 (TID 382). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 179.0 in stage 11.0 (TID 383, localhost, executor driver, partition 179, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 179.0 in stage 11.0 (TID 383)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 178.0 in stage 11.0 (TID 382) in 16 ms on localhost (executor driver) (174/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 179-180
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 383 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@4c51ed1
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 383 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@4c51ed1
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 179.0 in stage 11.0 (TID 383). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 180.0 in stage 11.0 (TID 384, localhost, executor driver, partition 180, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 180.0 in stage 11.0 (TID 384)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 179.0 in stage 11.0 (TID 383) in 16 ms on localhost (executor driver) (175/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 180-181
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 384 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@31c5a4d6
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 384 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@31c5a4d6
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 180.0 in stage 11.0 (TID 384). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 181.0 in stage 11.0 (TID 385, localhost, executor driver, partition 181, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 180.0 in stage 11.0 (TID 384) in 17 ms on localhost (executor driver) (176/200)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 181.0 in stage 11.0 (TID 385)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 181-182
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 385 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@87cb3a2
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 385 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@87cb3a2
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 181.0 in stage 11.0 (TID 385). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 182.0 in stage 11.0 (TID 386, localhost, executor driver, partition 182, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 181.0 in stage 11.0 (TID 385) in 0 ms on localhost (executor driver) (177/200)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 182.0 in stage 11.0 (TID 386)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 182-183
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 386 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2fd0c1db
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 386 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2fd0c1db
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 182.0 in stage 11.0 (TID 386). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 183.0 in stage 11.0 (TID 387, localhost, executor driver, partition 183, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 183.0 in stage 11.0 (TID 387)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 182.0 in stage 11.0 (TID 386) in 16 ms on localhost (executor driver) (178/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 183-184
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 387 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@ec43ff6
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 387 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@ec43ff6
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 183.0 in stage 11.0 (TID 387). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 184.0 in stage 11.0 (TID 388, localhost, executor driver, partition 184, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 184.0 in stage 11.0 (TID 388)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 183.0 in stage 11.0 (TID 387) in 16 ms on localhost (executor driver) (179/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 184-185
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 388 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@42165aec
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 388 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@42165aec
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 184.0 in stage 11.0 (TID 388). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 185.0 in stage 11.0 (TID 389, localhost, executor driver, partition 185, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 185.0 in stage 11.0 (TID 389)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 184.0 in stage 11.0 (TID 388) in 16 ms on localhost (executor driver) (180/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 185-186
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 389 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3fa0a2d6
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 389 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3fa0a2d6
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 185.0 in stage 11.0 (TID 389). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 186.0 in stage 11.0 (TID 390, localhost, executor driver, partition 186, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 186.0 in stage 11.0 (TID 390)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 185.0 in stage 11.0 (TID 389) in 0 ms on localhost (executor driver) (181/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 186-187
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 16 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  16 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 390 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@10e93b86
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 390 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@10e93b86
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 186.0 in stage 11.0 (TID 390). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 187.0 in stage 11.0 (TID 391, localhost, executor driver, partition 187, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 187.0 in stage 11.0 (TID 391)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 186.0 in stage 11.0 (TID 390) in 16 ms on localhost (executor driver) (182/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 187-188
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 391 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@76a3a92f
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 391 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@76a3a92f
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 187.0 in stage 11.0 (TID 391). 4354 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 188.0 in stage 11.0 (TID 392, localhost, executor driver, partition 188, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 187.0 in stage 11.0 (TID 391) in 16 ms on localhost (executor driver) (183/200)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 188.0 in stage 11.0 (TID 392)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 188-189
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 392 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@425a65f4
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 392 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@425a65f4
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 188.0 in stage 11.0 (TID 392). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 189.0 in stage 11.0 (TID 393, localhost, executor driver, partition 189, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 188.0 in stage 11.0 (TID 392) in 16 ms on localhost (executor driver) (184/200)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 189.0 in stage 11.0 (TID 393)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 189-190
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 393 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@2838992e
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 393 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@2838992e
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 189.0 in stage 11.0 (TID 393). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 190.0 in stage 11.0 (TID 394, localhost, executor driver, partition 190, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 190.0 in stage 11.0 (TID 394)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 189.0 in stage 11.0 (TID 393) in 0 ms on localhost (executor driver) (185/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 190-191
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 394 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3246062e
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 394 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3246062e
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 190.0 in stage 11.0 (TID 394). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 191.0 in stage 11.0 (TID 395, localhost, executor driver, partition 191, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 191.0 in stage 11.0 (TID 395)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 190.0 in stage 11.0 (TID 394) in 16 ms on localhost (executor driver) (186/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 191-192
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 395 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@50aac3eb
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 395 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@50aac3eb
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 191.0 in stage 11.0 (TID 395). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 192.0 in stage 11.0 (TID 396, localhost, executor driver, partition 192, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 192.0 in stage 11.0 (TID 396)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 191.0 in stage 11.0 (TID 395) in 16 ms on localhost (executor driver) (187/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 192-193
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 396 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5c12cdb3
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 396 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5c12cdb3
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 192.0 in stage 11.0 (TID 396). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 193.0 in stage 11.0 (TID 397, localhost, executor driver, partition 193, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 193.0 in stage 11.0 (TID 397)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 192.0 in stage 11.0 (TID 396) in 16 ms on localhost (executor driver) (188/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 193-194
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 397 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@50c57d0e
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 397 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@50c57d0e
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 193.0 in stage 11.0 (TID 397). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 194.0 in stage 11.0 (TID 398, localhost, executor driver, partition 194, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 194.0 in stage 11.0 (TID 398)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 193.0 in stage 11.0 (TID 397) in 0 ms on localhost (executor driver) (189/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 194-195
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 398 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@375d4855
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 398 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@375d4855
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 194.0 in stage 11.0 (TID 398). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 195.0 in stage 11.0 (TID 399, localhost, executor driver, partition 195, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 195.0 in stage 11.0 (TID 399)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 194.0 in stage 11.0 (TID 398) in 15 ms on localhost (executor driver) (190/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 195-196
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 399 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@438e0086
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 399 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@438e0086
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 195.0 in stage 11.0 (TID 399). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 196.0 in stage 11.0 (TID 400, localhost, executor driver, partition 196, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 196.0 in stage 11.0 (TID 400)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 195.0 in stage 11.0 (TID 399) in 16 ms on localhost (executor driver) (191/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 196-197
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 400 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@bdf426b
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 400 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@bdf426b
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 196.0 in stage 11.0 (TID 400). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 198.0 in stage 11.0 (TID 401, localhost, executor driver, partition 198, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 198.0 in stage 11.0 (TID 401)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 196.0 in stage 11.0 (TID 400) in 17 ms on localhost (executor driver) (192/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 198-199
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 401 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@75101b6
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 401 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@75101b6
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 198.0 in stage 11.0 (TID 401). 4397 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 199.0 in stage 11.0 (TID 402, localhost, executor driver, partition 199, PROCESS_LOCAL, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 199.0 in stage 11.0 (TID 402)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 198.0 in stage 11.0 (TID 401) in 16 ms on localhost (executor driver) (193/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 199-200
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 0 non-empty blocks including 0 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: 
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 402 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@5cc30b67
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 402 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@5cc30b67
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 199.0 in stage 11.0 (TID 402). 4311 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 DEBUG TaskSetManager:58 - No tasks for locality level NO_PREF, so moving to locality level ANY
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 97.0 in stage 11.0 (TID 403, localhost, executor driver, partition 97, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 199.0 in stage 11.0 (TID 402) in 15 ms on localhost (executor driver) (194/200)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 97.0 in stage 11.0 (TID 403)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 97-98
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_97
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 403 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@215df7b2
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 403 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@215df7b2
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 403 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@215df7b2
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 403 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@215df7b2
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 97.0 in stage 11.0 (TID 403). 4526 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 108.0 in stage 11.0 (TID 404, localhost, executor driver, partition 108, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 108.0 in stage 11.0 (TID 404)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 97.0 in stage 11.0 (TID 403) in 16 ms on localhost (executor driver) (195/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 108-109
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_108
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 404 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@1a778408
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 404 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@1a778408
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 404 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@1a778408
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 404 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@1a778408
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 108.0 in stage 11.0 (TID 404). 4526 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 116.0 in stage 11.0 (TID 405, localhost, executor driver, partition 116, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 116.0 in stage 11.0 (TID 405)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 108.0 in stage 11.0 (TID 404) in 16 ms on localhost (executor driver) (196/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 116-117
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_116
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 405 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@ec3f335
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 405 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@ec3f335
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 405 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@ec3f335
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 405 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@ec3f335
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 116.0 in stage 11.0 (TID 405). 4526 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 134.0 in stage 11.0 (TID 406, localhost, executor driver, partition 134, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 134.0 in stage 11.0 (TID 406)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 116.0 in stage 11.0 (TID 405) in 32 ms on localhost (executor driver) (197/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 134-135
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_134
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 406 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@10fff164
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 406 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@10fff164
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 406 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@10fff164
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 406 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@10fff164
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 134.0 in stage 11.0 (TID 406). 4526 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 156.0 in stage 11.0 (TID 407, localhost, executor driver, partition 156, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 156.0 in stage 11.0 (TID 407)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 134.0 in stage 11.0 (TID 406) in 16 ms on localhost (executor driver) (198/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 156-157
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_156
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 407 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@3f5fd2f9
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 407 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@3f5fd2f9
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 407 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@3f5fd2f9
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 407 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@3f5fd2f9
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 156.0 in stage 11.0 (TID 407). 4526 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 197.0 in stage 11.0 (TID 408, localhost, executor driver, partition 197, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 197.0 in stage 11.0 (TID 408)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 156.0 in stage 11.0 (TID 407) in 15 ms on localhost (executor driver) (199/200)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 0, partitions 197-198
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_0_0_197
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for input[0, int, true],input[1, string, true]:
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(2, 32);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_0 = i.isNullAt(0);
/* 032 */     int value_0 = isNull_0 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     if (isNull_0) {
/* 035 */       mutableStateArray_0[0].setNullAt(0);
/* 036 */     } else {
/* 037 */       mutableStateArray_0[0].write(0, value_0);
/* 038 */     }
/* 039 */
/* 040 */     boolean isNull_1 = i.isNullAt(1);
/* 041 */     UTF8String value_1 = isNull_1 ?
/* 042 */     null : (i.getUTF8String(1));
/* 043 */     if (isNull_1) {
/* 044 */       mutableStateArray_0[0].setNullAt(1);
/* 045 */     } else {
/* 046 */       mutableStateArray_0[0].write(1, value_1);
/* 047 */     }
/* 048 */     return (mutableStateArray_0[0].getRow());
/* 049 */   }
/* 050 */
/* 051 */
/* 052 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 408 acquired 256.0 KB for org.apache.spark.unsafe.map.BytesToBytesMap@54e90150
2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for :
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(0, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */     return (mutableStateArray_0[0].getRow());
/* 028 */   }
/* 029 */
/* 030 */
/* 031 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 408 acquired 64.0 MB for org.apache.spark.unsafe.map.BytesToBytesMap@54e90150
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 408 release 256.0 KB from org.apache.spark.unsafe.map.BytesToBytesMap@54e90150
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 408 release 64.0 MB from org.apache.spark.unsafe.map.BytesToBytesMap@54e90150
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 197.0 in stage 11.0 (TID 408). 4526 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_11.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 197.0 in stage 11.0 (TID 408) in 16 ms on localhost (executor driver) (200/200)
2022-02-09 13:09:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 INFO  DAGScheduler:54 - ShuffleMapStage 11 (count at UseCase5Test.java:25) finished in 2.645 s
2022-02-09 13:09:22 INFO  DAGScheduler:54 - looking for newly runnable stages
2022-02-09 13:09:22 INFO  DAGScheduler:54 - running: Set()
2022-02-09 13:09:22 INFO  DAGScheduler:54 - waiting: Set(ShuffleMapStage 12, ResultStage 13)
2022-02-09 13:09:22 INFO  DAGScheduler:54 - failed: Set()
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Increasing epoch to 2
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - submitStage(ShuffleMapStage 12 (name=count at UseCase5Test.java:25;jobs=9))
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:22 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 12 (MapPartitionsRDD[47] at count at UseCase5Test.java:25), which has no missing parents
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - submitMissingTasks(ShuffleMapStage 12)
2022-02-09 13:09:22 INFO  MemoryStore:54 - Block broadcast_22 stored as values in memory (estimated size 32.7 KB, free 1967.1 MB)
2022-02-09 13:09:22 DEBUG BlockManager:58 - Put block broadcast_22 locally took  0 ms
2022-02-09 13:09:22 DEBUG BlockManager:58 - Putting block broadcast_22 without replication took  0 ms
2022-02-09 13:09:22 INFO  MemoryStore:54 - Block broadcast_22_piece0 stored as bytes in memory (estimated size 15.3 KB, free 1967.1 MB)
2022-02-09 13:09:22 INFO  BlockManagerInfo:54 - Added broadcast_22_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 15.3 KB, free: 1970.3 MB)
2022-02-09 13:09:22 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_22_piece0
2022-02-09 13:09:22 DEBUG BlockManager:58 - Told master about block broadcast_22_piece0
2022-02-09 13:09:22 DEBUG BlockManager:58 - Put block broadcast_22_piece0 locally took  0 ms
2022-02-09 13:09:22 DEBUG BlockManager:58 - Putting block broadcast_22_piece0 without replication took  0 ms
2022-02-09 13:09:22 INFO  SparkContext:54 - Created broadcast 22 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:22 INFO  DAGScheduler:54 - Submitting 6 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[47] at count at UseCase5Test.java:25) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5))
2022-02-09 13:09:22 INFO  TaskSchedulerImpl:54 - Adding task set 12.0 with 6 tasks
2022-02-09 13:09:22 DEBUG TaskSetManager:58 - Epoch for TaskSet 12.0: 2
2022-02-09 13:09:22 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 12.0: ANY
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 12.0 (TID 409, localhost, executor driver, partition 0, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 0.0 in stage 12.0 (TID 409)
2022-02-09 13:09:22 DEBUG BlockManager:58 - Getting local block broadcast_22
2022-02-09 13:09:22 DEBUG BlockManager:58 - Level for block broadcast_22 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 1, partitions 0-1
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_1_134_0
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 DEBUG CodeGenerator:58 - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 INFO  CodeGenerator:54 - Code generated in 8.9364 ms
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 409 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@471643ec
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 409 acquired 64.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@471643ec
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 409 release 64.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@471643ec
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 409 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@471643ec
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 0.0 in stage 12.0 (TID 409). 5497 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 1.0 in stage 12.0 (TID 410, localhost, executor driver, partition 1, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 1.0 in stage 12.0 (TID 410)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 12.0 (TID 409) in 78 ms on localhost (executor driver) (1/6)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 1, partitions 1-2
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_1_97_1
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 410 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16d6a5b
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 410 acquired 64.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16d6a5b
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 410 release 64.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16d6a5b
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 410 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@16d6a5b
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 1.0 in stage 12.0 (TID 410). 5411 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 2.0 in stage 12.0 (TID 411, localhost, executor driver, partition 2, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 2.0 in stage 12.0 (TID 411)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 1.0 in stage 12.0 (TID 410) in 16 ms on localhost (executor driver) (2/6)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 1, partitions 2-3
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_1_156_2
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 411 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4b27fcd
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 411 acquired 64.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4b27fcd
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 411 release 64.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4b27fcd
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 411 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@4b27fcd
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 2.0 in stage 12.0 (TID 411). 5411 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 3.0 in stage 12.0 (TID 412, localhost, executor driver, partition 3, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 3.0 in stage 12.0 (TID 412)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 2.0 in stage 12.0 (TID 411) in 16 ms on localhost (executor driver) (3/6)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 1, partitions 3-4
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_1_197_3
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 412 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1c887cb1
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 412 acquired 64.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1c887cb1
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 412 release 64.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1c887cb1
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 412 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@1c887cb1
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 3.0 in stage 12.0 (TID 412). 5497 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 4.0 in stage 12.0 (TID 413, localhost, executor driver, partition 4, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 4.0 in stage 12.0 (TID 413)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 3.0 in stage 12.0 (TID 412) in 31 ms on localhost (executor driver) (4/6)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 1, partitions 4-5
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_1_116_4
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 413 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@10df2ad4
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 413 acquired 64.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@10df2ad4
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 413 release 64.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@10df2ad4
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 413 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@10df2ad4
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 4.0 in stage 12.0 (TID 413). 5497 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 5.0 in stage 12.0 (TID 414, localhost, executor driver, partition 5, ANY, 7756 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 5.0 in stage 12.0 (TID 414)
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 4.0 in stage 12.0 (TID 413) in 32 ms on localhost (executor driver) (5/6)
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 1, partitions 5-6
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_1_108_5
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 DEBUG GenerateOrdering:58 - Generated Ordering by input[0, int, true] ASC NULLS FIRST:
/* 001 */ public SpecificOrdering generate(Object[] references) {
/* 002 */   return new SpecificOrdering(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificOrdering extends org.apache.spark.sql.catalyst.expressions.codegen.BaseOrdering {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */
/* 009 */
/* 010 */   public SpecificOrdering(Object[] references) {
/* 011 */     this.references = references;
/* 012 */
/* 013 */   }
/* 014 */
/* 015 */   public int compare(InternalRow a, InternalRow b) {
/* 016 */
/* 017 */     InternalRow i = null;
/* 018 */
/* 019 */     i = a;
/* 020 */     boolean isNullA_0;
/* 021 */     int primitiveA_0;
/* 022 */     {
/* 023 */       boolean isNull_0 = i.isNullAt(0);
/* 024 */       int value_0 = isNull_0 ?
/* 025 */       -1 : (i.getInt(0));
/* 026 */       isNullA_0 = isNull_0;
/* 027 */       primitiveA_0 = value_0;
/* 028 */     }
/* 029 */     i = b;
/* 030 */     boolean isNullB_0;
/* 031 */     int primitiveB_0;
/* 032 */     {
/* 033 */       boolean isNull_0 = i.isNullAt(0);
/* 034 */       int value_0 = isNull_0 ?
/* 035 */       -1 : (i.getInt(0));
/* 036 */       isNullB_0 = isNull_0;
/* 037 */       primitiveB_0 = value_0;
/* 038 */     }
/* 039 */     if (isNullA_0 && isNullB_0) {
/* 040 */       // Nothing
/* 041 */     } else if (isNullA_0) {
/* 042 */       return -1;
/* 043 */     } else if (isNullB_0) {
/* 044 */       return 1;
/* 045 */     } else {
/* 046 */       int comp = (primitiveA_0 > primitiveB_0 ? 1 : primitiveA_0 < primitiveB_0 ? -1 : 0);
/* 047 */       if (comp != 0) {
/* 048 */         return comp;
/* 049 */       }
/* 050 */     }
/* 051 */
/* 052 */
/* 053 */     return 0;
/* 054 */   }
/* 055 */
/* 056 */
/* 057 */ }

2022-02-09 13:09:22 DEBUG GenerateUnsafeProjection:58 - code for sortprefix(input[0, int, true] ASC NULLS FIRST):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 009 */
/* 010 */   public SpecificUnsafeProjection(Object[] references) {
/* 011 */     this.references = references;
/* 012 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 013 */
/* 014 */   }
/* 015 */
/* 016 */   public void initialize(int partitionIndex) {
/* 017 */
/* 018 */   }
/* 019 */
/* 020 */   // Scala.Function1 need this
/* 021 */   public java.lang.Object apply(java.lang.Object row) {
/* 022 */     return apply((InternalRow) row);
/* 023 */   }
/* 024 */
/* 025 */   public UnsafeRow apply(InternalRow i) {
/* 026 */     mutableStateArray_0[0].reset();
/* 027 */
/* 028 */
/* 029 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 030 */
/* 031 */     boolean isNull_1 = i.isNullAt(0);
/* 032 */     int value_1 = isNull_1 ?
/* 033 */     -1 : (i.getInt(0));
/* 034 */     long value_0 = 0L;
/* 035 */     boolean isNull_0 = isNull_1;
/* 036 */     if (!isNull_1) {
/* 037 */       value_0 = (long) value_1;
/* 038 */     }
/* 039 */     if (isNull_0) {
/* 040 */       mutableStateArray_0[0].setNullAt(0);
/* 041 */     } else {
/* 042 */       mutableStateArray_0[0].write(0, value_0);
/* 043 */     }
/* 044 */     return (mutableStateArray_0[0].getRow());
/* 045 */   }
/* 046 */
/* 047 */
/* 048 */ }

2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 414 acquired 64.0 KB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5751bf5
2022-02-09 13:09:22 DEBUG TaskMemoryManager:224 - Task 414 acquired 64.0 MB for org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5751bf5
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 414 release 64.0 MB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5751bf5
2022-02-09 13:09:22 DEBUG TaskMemoryManager:233 - Task 414 release 64.0 KB from org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter@5751bf5
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 5.0 in stage 12.0 (TID 414). 5411 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_12.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 5.0 in stage 12.0 (TID 414) in 17 ms on localhost (executor driver) (6/6)
2022-02-09 13:09:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 12.0, whose tasks have all completed, from pool 
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - ShuffleMapTask finished on driver
2022-02-09 13:09:22 INFO  DAGScheduler:54 - ShuffleMapStage 12 (count at UseCase5Test.java:25) finished in 0.207 s
2022-02-09 13:09:22 INFO  DAGScheduler:54 - looking for newly runnable stages
2022-02-09 13:09:22 INFO  DAGScheduler:54 - running: Set()
2022-02-09 13:09:22 INFO  DAGScheduler:54 - waiting: Set(ResultStage 13)
2022-02-09 13:09:22 INFO  DAGScheduler:54 - failed: Set()
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Increasing epoch to 3
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - submitStage(ResultStage 13 (name=count at UseCase5Test.java:25;jobs=9))
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - missing: List()
2022-02-09 13:09:22 INFO  DAGScheduler:54 - Submitting ResultStage 13 (MapPartitionsRDD[50] at count at UseCase5Test.java:25), which has no missing parents
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - submitMissingTasks(ResultStage 13)
2022-02-09 13:09:22 INFO  MemoryStore:54 - Block broadcast_23 stored as values in memory (estimated size 7.3 KB, free 1967.1 MB)
2022-02-09 13:09:22 DEBUG BlockManager:58 - Put block broadcast_23 locally took  1 ms
2022-02-09 13:09:22 DEBUG BlockManager:58 - Putting block broadcast_23 without replication took  1 ms
2022-02-09 13:09:22 INFO  MemoryStore:54 - Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.9 KB, free 1967.1 MB)
2022-02-09 13:09:22 INFO  BlockManagerInfo:54 - Added broadcast_23_piece0 in memory on Clairvoyant-324.mshome.net:52097 (size: 3.9 KB, free: 1970.3 MB)
2022-02-09 13:09:22 DEBUG BlockManagerMaster:58 - Updated info of block broadcast_23_piece0
2022-02-09 13:09:22 DEBUG BlockManager:58 - Told master about block broadcast_23_piece0
2022-02-09 13:09:22 DEBUG BlockManager:58 - Put block broadcast_23_piece0 locally took  1 ms
2022-02-09 13:09:22 DEBUG BlockManager:58 - Putting block broadcast_23_piece0 without replication took  1 ms
2022-02-09 13:09:22 INFO  SparkContext:54 - Created broadcast 23 from broadcast at DAGScheduler.scala:1184
2022-02-09 13:09:22 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at count at UseCase5Test.java:25) (first 15 tasks are for partitions Vector(0))
2022-02-09 13:09:22 INFO  TaskSchedulerImpl:54 - Adding task set 13.0 with 1 tasks
2022-02-09 13:09:22 DEBUG TaskSetManager:58 - Epoch for TaskSet 13.0: 3
2022-02-09 13:09:22 DEBUG TaskSetManager:58 - Valid locality levels for TaskSet 13.0: ANY
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_13.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Starting task 0.0 in stage 13.0 (TID 415, localhost, executor driver, partition 0, ANY, 7767 bytes)
2022-02-09 13:09:22 INFO  Executor:54 - Running task 0.0 in stage 13.0 (TID 415)
2022-02-09 13:09:22 DEBUG BlockManager:58 - Getting local block broadcast_23
2022-02-09 13:09:22 DEBUG BlockManager:58 - Level for block broadcast_23 is StorageLevel(disk, memory, deserialized, 1 replicas)
2022-02-09 13:09:22 DEBUG MapOutputTrackerMaster:58 - Fetching outputs for shuffle 2, partitions 0-1
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - maxBytesInFlight: 50331648, targetRequestSize: 10066329, maxBlocksInFlightPerAddress: 2147483647
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Getting 6 non-empty blocks including 6 local blocks and 0 remote blocks
2022-02-09 13:09:22 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 0 ms
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Start fetching local blocks: shuffle_2_0_0, shuffle_2_1_0, shuffle_2_2_0, shuffle_2_3_0, shuffle_2_4_0, shuffle_2_5_0
2022-02-09 13:09:22 DEBUG ShuffleBlockFetcherIterator:58 - Got local blocks in  0 ms
2022-02-09 13:09:22 INFO  Executor:54 - Finished task 0.0 in stage 13.0 (TID 415). 1610 bytes result sent to driver
2022-02-09 13:09:22 DEBUG TaskSchedulerImpl:58 - parentName: , name: TaskSet_13.0, runningTasks: 0
2022-02-09 13:09:22 INFO  TaskSetManager:54 - Finished task 0.0 in stage 13.0 (TID 415) in 0 ms on localhost (executor driver) (1/1)
2022-02-09 13:09:22 INFO  TaskSchedulerImpl:54 - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2022-02-09 13:09:22 INFO  DAGScheduler:54 - ResultStage 13 (count at UseCase5Test.java:25) finished in 0.004 s
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - After removal of stage 11, remaining stages = 3
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - After removal of stage 13, remaining stages = 2
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - After removal of stage 10, remaining stages = 1
2022-02-09 13:09:22 DEBUG DAGScheduler:58 - After removal of stage 12, remaining stages = 0
2022-02-09 13:09:22 INFO  DAGScheduler:54 - Job 9 finished: count at UseCase5Test.java:25, took 2.873968 s
2022-02-09 13:09:22 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping Server@4de025bf{STARTED}[9.4.z-SNAPSHOT]
2022-02-09 13:09:22 DEBUG Server:433 - doStop Server@4de025bf{STOPPING}[9.4.z-SNAPSHOT]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran SparkUI-31-acceptor-0@5bbc9f97-ServerConnector@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040} in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=3,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG AbstractHandlerContainer:167 - Graceful shutdown Server@4de025bf{STOPPING}[9.4.z-SNAPSHOT] by 
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping Spark@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping SelectorManager@Spark@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@7957dc72{STARTED} id=3 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$CloseConnections@5c8318ab on ManagedSelector@7957dc72{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@7957dc72{STOPPING} id=3 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$CloseConnections@5c8318ab
2022-02-09 13:09:22 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@7957dc72{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc waiting with 0 keys
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$StopSelector@7d0ec916 on ManagedSelector@7957dc72{STOPPING} id=3 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@7957dc72{STOPPING} id=3 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@47b862fc processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$StopSelector@7d0ec916
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/PRODUCING/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.697+05:30
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@1734f68 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@7544a1e4/SelectorProducer@70e0accd/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=4,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.697+05:30
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@7957dc72{STOPPED} id=3 keys=-1 selected=-1 updates=0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@1e11bc55{STARTED} id=2 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$CloseConnections@2812443e on ManagedSelector@1e11bc55{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@1e11bc55{STOPPING} id=2 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$CloseConnections@2812443e
2022-02-09 13:09:22 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@1e11bc55{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$StopSelector@5cc67f99 on ManagedSelector@1e11bc55{STOPPING} id=2 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 waiting with 0 keys
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@1e11bc55{STOPPING} id=2 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@27ceeeb3 processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$StopSelector@5cc67f99
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/PRODUCING/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.712+05:30
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@5ea502e0 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@24f43aa3/SelectorProducer@63fd4873/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=5,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.712+05:30
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@1e11bc55{STOPPED} id=2 keys=-1 selected=-1 updates=0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@2ef8a8c3{STARTED} id=1 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$CloseConnections@184462ea on ManagedSelector@2ef8a8c3{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@2ef8a8c3{STOPPING} id=1 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$CloseConnections@184462ea
2022-02-09 13:09:22 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@2ef8a8c3{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 waiting with 0 keys
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$StopSelector@13095e8d on ManagedSelector@2ef8a8c3{STOPPING} id=1 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@2ef8a8c3{STOPPING} id=1 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@73c9cd11 processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$StopSelector@13095e8d
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@f8908f6/SelectorProducer@3e587920/PRODUCING/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.712+05:30
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@600b0b7 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@f8908f6/SelectorProducer@3e587920/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=6,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.712+05:30
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@2ef8a8c3{STOPPED} id=1 keys=-1 selected=-1 updates=0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ManagedSelector@750fe12e{STARTED} id=0 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$CloseConnections@2980db66 on ManagedSelector@750fe12e{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@750fe12e{STOPPING} id=0 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$CloseConnections@2980db66
2022-02-09 13:09:22 DEBUG ManagedSelector:996 - Closing 0 connections on ManagedSelector@750fe12e{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG ManagedSelector:605 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 waiting with 0 keys
2022-02-09 13:09:22 DEBUG ManagedSelector:286 - Queued change lazy=false org.spark_project.jetty.io.ManagedSelector$StopSelector@46554378 on ManagedSelector@750fe12e{STOPPING} id=0 keys=0 selected=0 updates=0
2022-02-09 13:09:22 DEBUG ManagedSelector:304 - Wakeup on submit ManagedSelector@750fe12e{STOPPING} id=0 keys=0 selected=0 updates=1
2022-02-09 13:09:22 DEBUG ManagedSelector:194 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 woken with none selected
2022-02-09 13:09:22 DEBUG ManagedSelector:612 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 woken up from select, 0/0/0 selected
2022-02-09 13:09:22 DEBUG ManagedSelector:628 - Selector sun.nio.ch.WindowsSelectorImpl@3d344652 processing 0 keys, 1 updates
2022-02-09 13:09:22 DEBUG ManagedSelector:558 - updateable 1
2022-02-09 13:09:22 DEBUG ManagedSelector:567 - update org.spark_project.jetty.io.ManagedSelector$StopSelector@46554378
2022-02-09 13:09:22 DEBUG ManagedSelector:587 - updates 0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/PRODUCING/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.712+05:30
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.io.ManagedSelector$$Lambda$28/1340057206@82c57b3 in QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED EatWhatYouKill@5bd73d1a/SelectorProducer@384fc774/IDLE/p=false/QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=7,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}][pc=0,pic=0,pec=0,epc=0]@2022-02-09T13:09:22.712+05:30
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ManagedSelector@750fe12e{STOPPED} id=0 keys=-1 selected=-1 updates=0
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED SelectorManager@Spark@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping HttpConnectionFactory@52350abb[HTTP/1.1]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED HttpConnectionFactory@52350abb[HTTP/1.1]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ScheduledExecutorScheduler@41394595{STARTED}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ScheduledExecutorScheduler@41394595{STOPPED}
2022-02-09 13:09:22 INFO  AbstractConnector:381 - Stopped Spark@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED Spark@fff25f1{HTTP/1.1, (http/1.1)}{0.0.0.0:4040}
2022-02-09 13:09:22 DEBUG AbstractHandler:107 - stopping Server@4de025bf{STOPPING}[9.4.z-SNAPSHOT]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ContextHandlerCollection@740abb5{STARTED}
2022-02-09 13:09:22 DEBUG AbstractHandler:107 - stopping ContextHandlerCollection@740abb5{STOPPING}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ContextHandlerCollection@740abb5{STOPPED}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ErrorHandler@3ec11999{STARTED}
2022-02-09 13:09:22 DEBUG AbstractHandler:107 - stopping ErrorHandler@3ec11999{STOPPING}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ErrorHandler@3ec11999{STOPPED}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping QueuedThreadPool[SparkUI]@307765b4{STARTED,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:224 - Stopping QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=8<=200,i=8,r=-1,q=0}[ReservedThreadExecutor@58c540cf{s=0/8,p=0}]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:212 - stopping ReservedThreadExecutor@58c540cf{s=0/8,p=0}
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED ReservedThreadExecutor@58c540cf{s=-1/8,p=0}
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-32,5,main] for 14999
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1035 - run org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-32,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-30,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-31,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-34,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-33,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-33,5,main] for 14998
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-28,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-27,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1038 - ran org.spark_project.jetty.util.thread.QueuedThreadPool$$Lambda$4/1228963996@70fb998d in QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-34,5,] for 14997
2022-02-09 13:09:22 DEBUG QueuedThreadPool:1065 - Thread[SparkUI-29,5,main] exited for QueuedThreadPool[SparkUI]@307765b4{STOPPING,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG QueuedThreadPool:317 - Waiting for Thread[SparkUI-29,5,main] for 14997
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED QueuedThreadPool[SparkUI]@307765b4{STOPPED,8<=0<=200,i=8,r=-1,q=0}[NO_TRY]
2022-02-09 13:09:22 DEBUG AbstractLifeCycle:224 - STOPPED Server@4de025bf{STOPPED}[9.4.z-SNAPSHOT]
2022-02-09 13:09:22 INFO  SparkUI:54 - Stopped Spark web UI at http://Clairvoyant-324.mshome.net:4040
2022-02-09 13:09:22 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2022-02-09 13:09:23 INFO  MemoryStore:54 - MemoryStore cleared
2022-02-09 13:09:23 INFO  BlockManager:54 - BlockManager stopped
2022-02-09 13:09:23 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2022-02-09 13:09:23 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2022-02-09 13:09:23 INFO  SparkContext:54 - Successfully stopped SparkContext
2022-02-09 13:09:23 INFO  ShutdownHookManager:54 - Shutdown hook called
2022-02-09 13:09:23 INFO  ShutdownHookManager:54 - Deleting directory C:\Users\Anukul Thalkar\AppData\Local\Temp\spark-401aa3b4-5736-4e04-9557-097f91c55014
